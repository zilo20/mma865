<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>Assignment1_865_Q2_ZitaLo</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Individual-Assignment----Q2.-Sentiment-Analysis-via-ML-Based-Approach">Individual Assignment  - Q2. Sentiment Analysis via ML-Based Approach<a class="anchor-link" href="#Individual-Assignment----Q2.-Sentiment-Analysis-via-ML-Based-Approach">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[230]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Name: Zita Lo</span>
<span class="c1"># Student Number: 20196119</span>
<span class="c1"># Program: MMA</span>
<span class="c1"># Cohort: Winter 2021</span>
<span class="c1"># Course Number: MMA 865</span>
<span class="c1"># Date: October 17, 2020</span>


<span class="c1"># Answer to Question 2 - Task 1</span>

<span class="c1"># Support response to Question 2 - Task 3: </span>
<span class="c1"># ---- &quot;Export Incorrect Prediction Results (sentiment_test data)&quot; section</span>
<span class="c1"># ---- &quot;Further exploration on Sentiment_Test Data&quot; section </span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[231]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Import packages</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[232]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The scikit-learn version is </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The scikit-learn version is 0.23.1.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Load-in-data">Load in data<a class="anchor-link" href="#Load-in-data">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[234]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># load in csv file. Display info about the data and show first 5 instances.</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;sentiment_train.csv&quot;</span><span class="p">)</span>

<span class="c1"># Set display width = 100.</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 2400 entries, 0 to 2399
Data columns (total 2 columns):
 #   Column    Non-Null Count  Dtype 
---  ------    --------------  ----- 
 0   Sentence  2400 non-null   object
 1   Polarity  2400 non-null   int64 
dtypes: int64(1), object(1)
memory usage: 37.6+ KB
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[234]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sentence</th>
      <th>Polarity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Wow... Loved this place.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Crust is not good.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Not tasty and the texture was just nasty.</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>The selection on the menu was great and so were the prices.</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[235]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Split data into train and test set ratio 0.85 : 0.15.</span>
<span class="c1"># Define &quot;Polarity&quot; feature as the target variable.</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Sentence&#39;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Polarity&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Preprocessing-and-Feature-Engineering">Preprocessing and Feature Engineering<a class="anchor-link" href="#Preprocessing-and-Feature-Engineering">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[236]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Preprocessing</span>

<span class="c1"># Import packages for preprocessing steps including removing stopwords, lemmatizing process, regular expression operations, etc.</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">unidecode</span>
<span class="kn">import</span> <span class="nn">textstat</span>
<span class="kn">import</span> <span class="nn">string</span>  

<span class="c1"># Define variable for WordNetLammatizer().</span>
<span class="n">lemmer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>

<span class="c1"># Define function for preprocessor. Input is a single document, as a single string.</span>
<span class="c1"># Output should be a single document, as a single string.</span>

<span class="k">def</span> <span class="nf">my_preprocess</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    
    <span class="c1"># Lowercase</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>   
 
    <span class="c1"># Substitute single characters with single space</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+[a-z]\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
    
    <span class="c1"># Substitute starting single characters with single space</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;^[a-z]\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> 
    
    <span class="c1"># Substitute digits with single space</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\d+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
    
    <span class="c1"># Substitute isn&#39;t, ain&#39;t, wasn&#39;t, didn&#39;t... with &quot;not&quot; to avoid &quot;&#39;&#39;&quot; got removed in the cleaning process</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;isn&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;is not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;ain&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;am not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;wasn&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;was not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;didn&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;did not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;don&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;do not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;wouldn&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;would not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;shouldn&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;should not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;can&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;can not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;couldn&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;could not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;won&#39;t&quot;</span><span class="p">,</span><span class="s2">&quot;will not&quot;</span><span class="p">,</span><span class="n">doc</span><span class="p">)</span>
    
    <span class="c1"># Substitute non word characters with single space</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\W+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span>
    
    <span class="c1"># Substitute multiple spaces with single space</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">I</span><span class="p">)</span>
    
    <span class="c1"># Lemmatize each word</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">lemmer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">split</span><span class="p">()])</span>

    <span class="k">return</span> <span class="n">doc</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[237]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Define functions for additional features in the document.</span>
<span class="c1"># They will later be put into the Pipeline and called via the FunctionTransformer() function.</span>
<span class="c1"># Each one takes an entier corpus (as a list of documents), and should return</span>
<span class="c1"># an array of feature values (one for each document in the corpus). </span>

<span class="c1"># Import a few popular lexicon packages e.g. textblob, afinn, nltk.sentiment.vader.</span>
<span class="kn">from</span> <span class="nn">textblob</span> <span class="kn">import</span> <span class="n">TextBlob</span>
<span class="kn">from</span> <span class="nn">nltk.sentiment.vader</span> <span class="kn">import</span> <span class="n">SentimentIntensityAnalyzer</span>
<span class="kn">from</span> <span class="nn">afinn</span> <span class="kn">import</span> <span class="n">Afinn</span>

<span class="c1"># Count length</span>
<span class="k">def</span> <span class="nf">doc_length</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Count number of words present in the text</span>
<span class="k">def</span> <span class="nf">lexicon_count</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">textstat</span><span class="o">.</span><span class="n">lexicon_count</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Get number of punctuation and sum them up</span>
<span class="k">def</span> <span class="nf">_get_punc</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">([</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">punc_count</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">_get_punc</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Get number of upper case and sum them up</span>
<span class="k">def</span> <span class="nf">_get_caps</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">isupper</span><span class="p">()])</span>

<span class="k">def</span> <span class="nf">capital_count</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">_get_caps</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Count number of exclamation marks</span>
<span class="k">def</span> <span class="nf">num_exclamation_marks</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;!&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Count number of question marks</span>
<span class="k">def</span> <span class="nf">num_question_marks</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;?&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Return boolean value if &quot;not&quot; exists or not</span>
<span class="k">def</span> <span class="nf">has_not</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">bool</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="s2">&quot;not&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()))</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
 
<span class="c1"># Return sentiment polarity value from TextBlob lexicon</span>
<span class="k">def</span> <span class="nf">sentiment_polar</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">TextBlob</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span><span class="o">.</span><span class="n">sentiment</span><span class="o">.</span><span class="n">polarity</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Return sentiment positive score value from nltk vader lexicon</span>
<span class="k">def</span> <span class="nf">sid_pos</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">doc</span><span class="p">)[</span><span class="s1">&#39;pos&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 

<span class="c1"># Return sentiment compound score value from nltk vader lexicon</span>
<span class="k">def</span> <span class="nf">sid_compound</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">doc</span><span class="p">)[</span><span class="s1">&#39;compound&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 

<span class="c1"># Return sentiment score value from Afinn lexicon</span>
<span class="k">def</span> <span class="nf">afn</span><span class="p">(</span><span class="n">corpus</span><span class="p">):</span>
    <span class="n">afn</span> <span class="o">=</span> <span class="n">Afinn</span><span class="p">(</span><span class="n">emoticons</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">afn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[238]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Calculate the class weights and check whether data has any class imbalance issue.</span>
<span class="c1"># Data turns out quite equaly distibuted for &quot;Polarity&quot;.</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">neg</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Polarity&#39;</span><span class="p">])</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">neg</span> <span class="o">+</span> <span class="n">pos</span>
<span class="n">weight_for_0</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">neg</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">total</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span> 
<span class="n">weight_for_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">pos</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">total</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span>

<span class="n">class_weight</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">weight_for_0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="n">weight_for_1</span><span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weight for class 0: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_for_0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weight for class 1: </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">weight_for_1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Weight for class 0: 0.99
Weight for class 1: 1.01
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Construct-the-Pipeline">Construct the Pipeline<a class="anchor-link" href="#Construct-the-Pipeline">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[239]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">FeatureUnion</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span><span class="p">,</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">stop_words</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Need to preprocess the stopwords, because scikit learn&#39;s TfidfVectorizer</span>
<span class="c1"># removes stopwords _after_ preprocessing.</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">my_preprocess</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="o">.</span><span class="n">ENGLISH_STOP_WORDS</span><span class="p">]</span>

<span class="c1"># This vectorizer will be used to create the BOW features.</span>
<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">my_preprocess</span><span class="p">,</span> 
                             <span class="n">max_features</span> <span class="o">=</span> <span class="mi">1500</span><span class="p">,</span> 
                             <span class="n">ngram_range</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
                             <span class="n">stop_words</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
                             <span class="n">strip_accents</span><span class="o">=</span><span class="s2">&quot;unicode&quot;</span><span class="p">,</span> 
                             <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># This vectorizer will be used to preprocess the text before topic modeling.</span>
<span class="n">vectorizer2</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">=</span><span class="n">my_preprocess</span><span class="p">,</span> 
                             <span class="n">max_features</span> <span class="o">=</span> <span class="mi">1500</span><span class="p">,</span> 
                             <span class="n">ngram_range</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
                             <span class="n">stop_words</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
                             <span class="n">strip_accents</span><span class="o">=</span><span class="s2">&quot;unicode&quot;</span><span class="p">,</span> 
                             <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Topic modelling NMF</span>
<span class="n">nmf</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;nndsvda&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;mu&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Algorithms - Random Forest (LR), Multi-layer Perceptron (MLP), ExtraTreeClassifier (ET), Logistic Regression (LR), and</span>
<span class="c1"># support vector machine (SVM)</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">223</span><span class="p">)</span>
<span class="n">mlp</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">et</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">)</span>

<span class="c1"># Use FeatureUnion() to put all features together as preprocessing step.</span>
<span class="n">feature_processing</span> <span class="o">=</span>  <span class="n">FeatureUnion</span><span class="p">([</span> 
    <span class="p">(</span><span class="s1">&#39;bow&#39;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;cv&#39;</span><span class="p">,</span> <span class="n">vectorizer</span><span class="p">),</span> <span class="p">])),</span>
    <span class="p">(</span><span class="s1">&#39;topics&#39;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;cv&#39;</span><span class="p">,</span> <span class="n">vectorizer2</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;nmf&#39;</span><span class="p">,</span> <span class="n">nmf</span><span class="p">),])),</span>
    <span class="p">(</span><span class="s1">&#39;length&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">doc_length</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;words&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">lexicon_count</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;punc_count&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">punc_count</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;capital_count&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">capital_count</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>  
    <span class="p">(</span><span class="s1">&#39;num_exclamation_marks&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">num_exclamation_marks</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>  
    <span class="p">(</span><span class="s1">&#39;num_question_marks&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">num_question_marks</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">&#39;has_not&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">has_not</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>    
    <span class="p">(</span><span class="s1">&#39;afn&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">afn</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span> 
    <span class="p">(</span><span class="s1">&#39;sentiment_polar&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">sentiment_polar</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span>    
    <span class="p">(</span><span class="s1">&#39;sid_pos&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">sid_pos</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span> 
    <span class="p">(</span><span class="s1">&#39;sid_compound&#39;</span><span class="p">,</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">sid_compound</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span> 
<span class="p">])</span>


<span class="c1"># Use standard scaler to scale data</span>
<span class="n">steps</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;features&#39;</span><span class="p">,</span> <span class="n">feature_processing</span><span class="p">),(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">False</span><span class="p">))]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[240]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Define the pipeline with feature processing, scaling, and them run model.</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;features&#39;</span><span class="p">,</span> <span class="n">feature_processing</span><span class="p">),(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">False</span><span class="p">)),</span> <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">et</span><span class="p">)])</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># ExtraTreeClassifier (ET) is chosen as the final optimal model. Currently &quot;ET&quot; is set as default under &quot;which_clf&quot; variable.</span>
<span class="c1"># To switch to other algorithm, simply changed the &quot;which_clf&quot; variable to &quot;RF&quot;, &quot;MLP&quot;, &quot;LR&quot; or &quot;SVM&quot;.</span>
<span class="c1"># All these algorithms (ExtraTreeClassifier (ET), Random Forest (LR), Multi-layer Perceptron (MLP), Logistic Regression (LR), </span>
<span class="c1"># support vector machine (SVM) have been tuned. The best parameters are listed and commented out in each section.</span>

<span class="n">which_clf</span> <span class="o">=</span> <span class="s2">&quot;ET&quot;</span>

<span class="k">if</span> <span class="n">which_clf</span> <span class="o">==</span> <span class="s2">&quot;RF&quot;</span><span class="p">:</span>

    <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">rf</span><span class="p">))</span>

    <span class="c1"># Hypertuning for more than 3 hours (185.4 mins)</span>
    <span class="c1">#Best parameter (CV scy_train0.849):</span>
    <span class="c1">#{&#39;clf__class_weight&#39;: None, </span>
    <span class="c1">#&#39;clf__criterion&#39;: &#39;entropy&#39;, </span>
    <span class="c1">#&#39;clf__n_estimators&#39;: 100, </span>
    <span class="c1">#&#39;features__bow__cv__max_features&#39;: 3000, </span>
    <span class="c1">#&#39;features__bow__cv__preprocessor&#39;: &lt;function my_preprocess at 0x000001F725CB4D38&gt;,</span>
    <span class="c1">#&#39;features__bow__cv__use_idf&#39;: False, </span>
    <span class="c1">#&#39;features__topics__cv__stop_words&#39;: &#39;english&#39;,</span>
    <span class="c1">#&#39;features__topics__nmf__n_components&#39;: 200}</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;features__bow__cv__preprocessor&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">my_preprocess</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span><span class="mi">3000</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__use_idf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__cv__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;english&#39;</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__nmf__n_components&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">75</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">400</span><span class="p">],</span>
        <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
        <span class="s1">&#39;clf__class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>
        <span class="s1">&#39;clf__criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
    <span class="p">}</span>
    
<span class="k">elif</span> <span class="n">which_clf</span> <span class="o">==</span> <span class="s2">&quot;MLP&quot;</span><span class="p">:</span>
    
    <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">mlp</span><span class="p">))</span>
  
    <span class="c1">#Best parameter (CV scy_train0.804):</span>
    <span class="c1">#{&#39;clf__hidden_layer_sizes&#39;: (50, 50), </span>
    <span class="c1">#&#39;clf__solver&#39;: &#39;adam&#39;, </span>
    <span class="c1">#&#39;features__bow__cv__max_features&#39;: 3000, </span>
    <span class="c1">#&#39;features__bow__cv__min_df&#39;: 0, </span>
    <span class="c1">#&#39;features__bow__cv__preprocessor&#39;: &lt;function my_preprocess at 0x000001BA2DA97D38&gt;, </span>
    <span class="c1">#&#39;features__bow__cv__use_idf&#39;: False, </span>
    <span class="c1">#&#39;features__topics__cv__stop_words&#39;: &#39;english&#39;, </span>
    <span class="c1">#&#39;features__topics__nmf__n_components&#39;: 300}</span>
    
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;features__bow__cv__preprocessor&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">my_preprocess</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3000</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__min_df&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__use_idf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__cv__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;english&quot;</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__nmf__n_components&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">300</span><span class="p">],</span>
        <span class="s1">&#39;clf__solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;adam&quot;</span><span class="p">],</span>         
        <span class="s1">&#39;clf__hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">100</span><span class="p">,</span> <span class="p">),</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">)],</span>
    <span class="p">}</span>

<span class="k">elif</span> <span class="n">which_clf</span> <span class="o">==</span> <span class="s2">&quot;ET&quot;</span><span class="p">:</span>
    
    <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">et</span><span class="p">))</span>
    
    <span class="c1">#Best parameter (CV scy_train0.852):</span>
    <span class="c1">#{&#39;clf__class_weight&#39;: None, </span>
    <span class="c1">#&#39;clf__criterion&#39;: &#39;entropy&#39;, </span>
    <span class="c1">#&#39;clf__n_estimators&#39;: 200, </span>
    <span class="c1">#&#39;features__bow__cv__max_features&#39;: 3000, </span>
    <span class="c1">#&#39;features__bow__cv__preprocessor&#39;: &lt;function my_preprocess at 0x0000027D52AA1678&gt;,</span>
    <span class="c1">#&#39;features__bow__cv__use_idf&#39;: False,</span>
    <span class="c1">#&#39;features__topics__cv__max_features&#39;: 1500,</span>
    <span class="c1">#&#39;features__topics__cv__stop_words&#39;:stop_words,</span>
    <span class="c1">#&#39;features__topics__nmf__n_components&#39;: 200</span>
    
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;features__bow__cv__preprocessor&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">my_preprocess</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3000</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__use_idf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__cv__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1500</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__cv__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stop_words</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__nmf__n_components&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">200</span><span class="p">],</span>
        <span class="s1">&#39;clf__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">200</span><span class="p">],</span>
        <span class="s1">&#39;clf__class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>   
        <span class="s1">&#39;clf__criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
        
    <span class="p">}</span>
    
<span class="k">elif</span> <span class="n">which_clf</span> <span class="o">==</span> <span class="s2">&quot;LR&quot;</span><span class="p">:</span>
    
    <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>
    <span class="c1">#Best parameter (CV scy_train0.839):</span>
    <span class="c1">#{&#39;clf__C&#39;: 100, &#39;clf__solver&#39;: &#39;lbfgs&#39;, </span>
    <span class="c1">#&#39;features__bow__cv__max_features&#39;: 3000, </span>
    <span class="c1">#&#39;features__bow__cv__preprocessor&#39;: &lt;function my_preprocess at 0x00000257B9123DC8&gt;, </span>
    <span class="c1">#&#39;features__bow__cv__use_idf&#39;: False, </span>
    <span class="c1">#&#39;features__topics__cv__stop_words&#39;: stop_words,</span>
    <span class="c1">#&#39;features__topics__nmf__n_components&#39;: 300</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;features__bow__cv__preprocessor&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">my_preprocess</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3000</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__use_idf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__cv__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stop_words</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__nmf__n_components&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">300</span><span class="p">],</span>        
        <span class="s1">&#39;clf__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span>         
        <span class="s1">&#39;clf__solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">],</span>
    <span class="p">}</span>

<span class="k">elif</span> <span class="n">which_clf</span> <span class="o">==</span> <span class="s2">&quot;SVM&quot;</span><span class="p">:</span>
    
    <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">svm</span><span class="p">))</span>    
    <span class="c1">#Best parameter (CV scy_train0.829):</span>
    <span class="c1">#{&#39;clf__class_weight&#39;: None, </span>
    <span class="c1">#&#39;clf__kernel&#39;: &#39;linear&#39;, </span>
    <span class="c1">#&#39;features__bow__cv__max_features&#39;: 3000, </span>
    <span class="c1">#&#39;features__bow__cv__preprocessor&#39;: &lt;function my_preprocess at 0x000001BA2F0FC828&gt;,</span>
    <span class="c1">#&#39;features__bow__cv__use_idf&#39;: True, </span>
    <span class="c1">#&#39;features__topics__cv__stop_words&#39;: None, </span>
    <span class="c1">#&#39;features__topics__nmf__n_components&#39;: 400}   </span>
 
    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;features__bow__cv__preprocessor&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">my_preprocess</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3000</span><span class="p">],</span>
        <span class="s1">&#39;features__bow__cv__use_idf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__cv__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>
        <span class="s1">&#39;features__topics__nmf__n_components&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">400</span><span class="p">],</span>
        <span class="s1">&#39;clf__kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span>
        <span class="s1">&#39;clf__class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>
    <span class="p">}</span>
    
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>

<span class="c1"># Use GridSearchCV() for cross validation and hyper-parameters tuning</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_micro&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Fit-Model">Fit Model<a class="anchor-link" href="#Fit-Model">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[241]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">search</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 2 candidates, totalling 6 fits
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done   6 out of   6 | elapsed:  2.6min finished
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[242]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Print best parameters</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameter (CV scy_train</span><span class="si">%0.3f</span><span class="s2">):&quot;</span> <span class="o">%</span> <span class="n">search</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Best parameter (CV scy_train0.852):
{&#39;clf__class_weight&#39;: None, &#39;clf__criterion&#39;: &#39;entropy&#39;, &#39;clf__n_estimators&#39;: 200, &#39;features__bow__cv__max_features&#39;: 3000, &#39;features__bow__cv__preprocessor&#39;: &lt;function my_preprocess at 0x0000021D3F1211F8&gt;, &#39;features__bow__cv__stop_words&#39;: None, &#39;features__bow__cv__use_idf&#39;: False, &#39;features__topics__cv__max_features&#39;: 1500, &#39;features__topics__cv__stop_words&#39;: [&#39;several&#39;, &#39;hereafter&#39;, &#39;the&#39;, &#39;nobody&#39;, &#39;neither&#39;, &#39;ever&#39;, &#39;somewhere&#39;, &#39;become&#39;, &#39;she&#39;, &#39;twelve&#39;, &#39;amoungst&#39;, &#39;also&#39;, &#39;now&#39;, &#39;should&#39;, &#39;therein&#39;, &#39;down&#39;, &#39;seems&#39;, &#39;must&#39;, &#39;cannot&#39;, &#39;per&#39;, &#39;re&#39;, &#39;found&#39;, &#39;noone&#39;, &#39;of&#39;, &#39;too&#39;, &#39;whether&#39;, &#39;together&#39;, &#39;itself&#39;, &#39;my&#39;, &#39;every&#39;, &#39;any&#39;, &#39;fifty&#39;, &#39;seeming&#39;, &#39;already&#39;, &#39;ltd&#39;, &#39;wherein&#39;, &#39;everything&#39;, &#39;out&#39;, &#39;an&#39;, &#39;meanwhile&#39;, &#39;but&#39;, &#39;why&#39;, &#39;hereby&#39;, &#39;although&#39;, &#39;first&#39;, &#39;here&#39;, &#39;are&#39;, &#39;such&#39;, &#39;thereafter&#39;, &#39;anyhow&#39;, &#39;then&#39;, &#39;what&#39;, &#39;hasnt&#39;, &#39;never&#39;, &#39;they&#39;, &#39;nothing&#39;, &#39;whole&#39;, &#39;wherever&#39;, &#39;themselves&#39;, &#39;whoever&#39;, &#39;anyone&#39;, &#39;thin&#39;, &#39;becoming&#39;, &#39;may&#39;, &#39;which&#39;, &#39;inc&#39;, &#39;sincere&#39;, &#39;if&#39;, &#39;mostly&#39;, &#39;amongst&#39;, &#39;nine&#39;, &#39;amount&#39;, &#39;own&#39;, &#39;these&#39;, &#39;beforehand&#39;, &#39;off&#39;, &#39;ourselves&#39;, &#39;whatever&#39;, &#39;few&#39;, &#39;wa&#39;, &#39;will&#39;, &#39;toward&#39;, &#39;thence&#39;, &#39;no&#39;, &#39;forty&#39;, &#39;anything&#39;, &#39;former&#39;, &#39;whither&#39;, &#39;give&#39;, &#39;very&#39;, &#39;while&#39;, &#39;by&#39;, &#39;un&#39;, &#39;i&#39;, &#39;whereby&#39;, &#39;whereafter&#39;, &#39;during&#39;, &#39;third&#39;, &#39;hereupon&#39;, &#39;up&#39;, &#39;than&#39;, &#39;besides&#39;, &#39;name&#39;, &#39;though&#39;, &#39;without&#39;, &#39;get&#39;, &#39;their&#39;, &#39;me&#39;, &#39;whom&#39;, &#39;someone&#39;, &#39;back&#39;, &#39;nevertheless&#39;, &#39;myself&#39;, &#39;ten&#39;, &#39;herself&#39;, &#39;interest&#39;, &#39;when&#39;, &#39;please&#39;, &#39;formerly&#39;, &#39;fill&#39;, &#39;sometime&#39;, &#39;there&#39;, &#39;same&#39;, &#39;one&#39;, &#39;this&#39;, &#39;even&#39;, &#39;could&#39;, &#39;couldnt&#39;, &#39;is&#39;, &#39;below&#39;, &#39;along&#39;, &#39;others&#39;, &#39;everywhere&#39;, &#39;his&#39;, &#39;sometimes&#39;, &#39;side&#39;, &#39;who&#39;, &#39;four&#39;, &#39;fire&#39;, &#39;can&#39;, &#39;fifteen&#39;, &#39;de&#39;, &#39;a&#39;, &#39;nowhere&#39;, &#39;would&#39;, &#39;ie&#39;, &#39;hers&#39;, &#39;top&#39;, &#39;latterly&#39;, &#39;system&#39;, &#39;you&#39;, &#39;to&#39;, &#39;or&#39;, &#39;do&#39;, &#39;had&#39;, &#39;eleven&#39;, &#39;in&#39;, &#39;keep&#39;, &#39;yet&#39;, &#39;another&#39;, &#39;thus&#39;, &#39;else&#39;, &#39;full&#39;, &#39;whose&#39;, &#39;rather&#39;, &#39;that&#39;, &#39;further&#39;, &#39;enough&#39;, &#39;seem&#39;, &#39;all&#39;, &#39;due&#39;, &#39;we&#39;, &#39;before&#39;, &#39;indeed&#39;, &#39;often&#39;, &#39;it&#39;, &#39;latter&#39;, &#39;hundred&#39;, &#39;beside&#39;, &#39;whenever&#39;, &#39;cant&#39;, &#39;go&#39;, &#39;yours&#39;, &#39;everyone&#39;, &#39;it&#39;, &#39;behind&#39;, &#39;more&#39;, &#39;and&#39;, &#39;where&#39;, &#39;from&#39;, &#39;eg&#39;, &#39;each&#39;, &#39;those&#39;, &#39;part&#39;, &#39;against&#39;, &#39;over&#39;, &#39;been&#39;, &#39;hence&#39;, &#39;twenty&#39;, &#39;so&#39;, &#39;describe&#39;, &#39;much&#39;, &#39;among&#39;, &#39;still&#39;, &#39;anywhere&#39;, &#39;a&#39;, &#39;whereupon&#39;, &#39;have&#39;, &#39;within&#39;, &#39;five&#39;, &#39;between&#39;, &#39;co&#39;, &#39;until&#39;, &#39;were&#39;, &#39;thru&#39;, &#39;thick&#39;, &#39;le&#39;, &#39;above&#39;, &#39;becomes&#39;, &#39;them&#39;, &#39;made&#39;, &#39;perhaps&#39;, &#39;something&#39;, &#39;otherwise&#39;, &#39;many&#39;, &#39;ha&#39;, &#39;since&#39;, &#39;con&#39;, &#39;therefore&#39;, &#39;none&#39;, &#39;however&#39;, &#39;be&#39;, &#39;except&#39;, &#39;whereas&#39;, &#39;some&#39;, &#39;your&#39;, &#39;herein&#39;, &#39;done&#39;, &#39;he&#39;, &#39;how&#39;, &#39;most&#39;, &#39;for&#39;, &#39;last&#39;, &#39;somehow&#39;, &#39;at&#39;, &#39;both&#39;, &#39;upon&#39;, &#39;sixty&#39;, &#39;mine&#39;, &#39;under&#39;, &#39;once&#39;, &#39;am&#39;, &#39;with&#39;, &#39;almost&#39;, &#39;whence&#39;, &#39;after&#39;, &#39;thereupon&#39;, &#39;across&#39;, &#39;always&#39;, &#39;throughout&#39;, &#39;him&#39;, &#39;anyway&#39;, &#39;onto&#39;, &#39;on&#39;, &#39;being&#39;, &#39;etc&#39;, &#39;towards&#39;, &#39;three&#39;, &#39;moreover&#39;, &#39;see&#39;, &#39;call&#39;, &#39;front&#39;, &#39;not&#39;, &#39;afterwards&#39;, &#39;our&#39;, &#39;two&#39;, &#39;beyond&#39;, &#39;next&#39;, &#39;nor&#39;, &#39;her&#39;, &#39;eight&#39;, &#39;thereby&#39;, &#39;find&#39;, &#39;either&#39;, &#39;detail&#39;, &#39;via&#39;, &#39;serious&#39;, &#39;bill&#39;, &#39;well&#39;, &#39;about&#39;, &#39;take&#39;, &#39;six&#39;, &#39;might&#39;, &#39;move&#39;, &#39;u&#39;, &#39;seemed&#39;, &#39;other&#39;, &#39;empty&#39;, &#39;himself&#39;, &#39;put&#39;, &#39;elsewhere&#39;, &#39;into&#39;, &#39;alone&#39;, &#39;bottom&#39;, &#39;show&#39;, &#39;least&#39;, &#39;around&#39;, &#39;became&#39;, &#39;through&#39;, &#39;again&#39;, &#39;mill&#39;, &#39;yourselves&#39;, &#39;because&#39;, &#39;yourself&#39;, &#39;ours&#39;, &#39;namely&#39;, &#39;cry&#39;, &#39;only&#39;], &#39;features__topics__nmf__n_components&#39;: 200}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[243]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Print out the results of hyperparmater tuning</span>

<span class="k">def</span> <span class="nf">cv_results_to_df</span><span class="p">(</span><span class="n">cv_results</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]))</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_score_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;mean_score_time&#39;</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_train_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;mean_train_score&#39;</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;std_train_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;std_train_score&#39;</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;rank_test_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;rank_test_score&#39;</span><span class="p">]</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">cv_results_to_df</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">results</span>

<span class="c1"># Export to csv (comment out below line to allow export)</span>
<span class="c1">#results.to_csv(&#39;results2.csv&#39;, index=False)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[243]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>clf__class_weight</th>
      <th>clf__criterion</th>
      <th>clf__n_estimators</th>
      <th>features__bow__cv__max_features</th>
      <th>features__bow__cv__preprocessor</th>
      <th>features__bow__cv__stop_words</th>
      <th>features__bow__cv__use_idf</th>
      <th>features__topics__cv__max_features</th>
      <th>features__topics__cv__stop_words</th>
      <th>features__topics__nmf__n_components</th>
      <th>mean_fit_time</th>
      <th>mean_score_time</th>
      <th>mean_train_score</th>
      <th>std_train_score</th>
      <th>mean_test_score</th>
      <th>std_test_score</th>
      <th>rank_test_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>None</td>
      <td>entropy</td>
      <td>200</td>
      <td>3000</td>
      <td>&lt;function my_preprocess at 0x0000021D3F1211F8&gt;</td>
      <td>None</td>
      <td>False</td>
      <td>1500</td>
      <td>[several, hereafter, the, nobody, neither, ever, somewhere, become, she, twelve, amoungst, also,...</td>
      <td>200</td>
      <td>28.856713</td>
      <td>10.860554</td>
      <td>0.99951</td>
      <td>0.000693</td>
      <td>0.851961</td>
      <td>0.001834</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>None</td>
      <td>entropy</td>
      <td>200</td>
      <td>3000</td>
      <td>&lt;function my_preprocess at 0x0000021D3F1211F8&gt;</td>
      <td>[several, hereafter, the, nobody, neither, ever, somewhere, become, she, twelve, amoungst, also,...</td>
      <td>False</td>
      <td>1500</td>
      <td>[several, hereafter, the, nobody, neither, ever, somewhere, become, she, twelve, amoungst, also,...</td>
      <td>200</td>
      <td>36.657278</td>
      <td>15.255821</td>
      <td>0.99951</td>
      <td>0.000693</td>
      <td>0.847549</td>
      <td>0.007995</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Estimate-Model-Performance">Estimate Model Performance<a class="anchor-link" href="#Estimate-Model-Performance">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[244]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Get references to the objects from the pipeline with the *best* hyperparameter settings,</span>
<span class="c1"># in order to explore those objects at a later time.</span>


<span class="c1"># The pipeline with the best performance.</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span>

<span class="c1"># Get the feature processing pipeline, which can be used later.</span>
<span class="n">feature_processing_obj</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span>

<span class="c1"># Find the vectorizer objects, NMF objects, and classifier objects.</span>
<span class="n">pipevect</span><span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">transformer_list</span><span class="p">)</span>
<span class="n">vectorizer_obj</span> <span class="o">=</span> <span class="n">pipevect</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;bow&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;cv&#39;</span><span class="p">]</span>
<span class="n">vectorizer_obj2</span> <span class="o">=</span> <span class="n">pipevect</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;topics&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;cv&#39;</span><span class="p">]</span>
<span class="n">nmf_obj</span> <span class="o">=</span> <span class="n">pipevect</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;topics&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;nmf&#39;</span><span class="p">]</span>
<span class="n">clf_obj</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;clf&#39;</span><span class="p">]</span>

<span class="c1"># Confirm vocabSize setting. Should match the output.</span>
<span class="nb">len</span><span class="p">(</span><span class="n">vectorizer_obj</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[244]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1926</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[245]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Performance metrics of the model.</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="n">features_val</span> <span class="o">=</span> <span class="n">feature_processing_obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>

<span class="n">pred_val</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">pred_val</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">F1 Score = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">pred_val</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">pred_val</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion matrix:
[[176  16]
 [ 31 137]]

F1 Score = 0.86944

Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.92      0.88       192
           1       0.90      0.82      0.85       168

    accuracy                           0.87       360
   macro avg       0.87      0.87      0.87       360
weighted avg       0.87      0.87      0.87       360

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Evaluate-Performance-on-Test-Data">Evaluate Performance on Test Data<a class="anchor-link" href="#Evaluate-Performance-on-Test-Data">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[246]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Performance metrics of the model on sentiment_test data.</span>

<span class="c1"># load in test data and predict.</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sentiment_test.csv&#39;</span><span class="p">)</span>

<span class="n">features_test</span> <span class="o">=</span> <span class="n">feature_processing_obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;Sentence&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="n">pred_test</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;Sentence&#39;</span><span class="p">])</span>

<span class="c1"># load in test data and define target vairable.</span>
<span class="n">solutions_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;sentiment_test.csv&#39;</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">solutions_df</span><span class="p">[</span><span class="s1">&#39;Polarity&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">F1 Score = </span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;micro&quot;</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Confusion matrix:
[[263  24]
 [ 78 235]]

F1 Score = 0.83000

Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.92      0.84       287
           1       0.91      0.75      0.82       313

    accuracy                           0.83       600
   macro avg       0.84      0.83      0.83       600
weighted avg       0.84      0.83      0.83       600

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Export-Test-Data-Prediction-Results">Export Test Data Prediction Results<a class="anchor-link" href="#Export-Test-Data-Prediction-Results">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[247]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Output the predictions to a csv file.</span>

<span class="c1"># Create a final data frame with three columns &quot;Sentence&quot;, &quot;Polarity&quot;, &quot;Predicted&quot;</span>
<span class="n">df_test_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Sentence&#39;</span><span class="p">:</span> <span class="n">test_df</span><span class="o">.</span><span class="n">Sentence</span><span class="p">,</span> <span class="s1">&#39;Polarity&#39;</span><span class="p">:</span> <span class="n">test_df</span><span class="o">.</span><span class="n">Polarity</span><span class="p">,</span> <span class="s1">&#39;Predicted&#39;</span><span class="p">:</span> <span class="n">pred_test</span><span class="p">})</span>

<span class="c1"># Create a new column &quot;Validation&quot; to compare the actual vs prediction</span>
<span class="n">df_test_pred</span><span class="p">[</span><span class="s1">&#39;Validation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

<span class="c1"># loop through each instance to compare &quot;Polarity&quot; and &quot;Predicted&quot;</span>
<span class="n">row</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_test_pred</span><span class="p">)):</span>    
    <span class="k">if</span> <span class="p">(</span><span class="n">df_test_pred</span><span class="p">[</span><span class="s1">&#39;Polarity&#39;</span><span class="p">][</span><span class="n">row</span><span class="p">]</span> <span class="o">==</span> <span class="n">df_test_pred</span><span class="p">[</span><span class="s1">&#39;Predicted&#39;</span><span class="p">][</span><span class="n">row</span><span class="p">]):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;Correct&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;Incorrect&#39;</span>
    <span class="n">df_test_pred</span><span class="p">[</span><span class="s1">&#39;Validation&#39;</span><span class="p">][</span><span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
    <span class="n">row</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># View first 20 and last 20 rows of data frame. Set display width = 100.</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">df_test_pred</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="n">df_test_pred</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>

<span class="c1"># Export to csv. Uncomment to create the file.    </span>
<span class="c1">#df_test_pred.to_csv(&quot;sentiment_test_predicted.csv&quot;)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[247]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sentence</th>
      <th>Polarity</th>
      <th>Predicted</th>
      <th>Validation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A good commentary of today's love and undoubtedly a film worth seeing.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>1</th>
      <td>For people who are first timers in film making, I think they did an excellent job!!</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>2</th>
      <td>It was very popular when I was in the cinema, a good house and very good reactions and plenty of...</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>3</th>
      <td>It's a feel-good film and that's how I felt when I came out of the cinema!</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>4</th>
      <td>It has northern humour and positive about the community it represents.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>5</th>
      <td>I rather enjoyed it.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>6</th>
      <td>I liked it.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>7</th>
      <td>I couldn't take them seriously.</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>8</th>
      <td>It really created a unique feeling though.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Vivian Schilling did an excellent job with the script.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>10</th>
      <td>A world better than 95% of the garbage in the theatres today.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Her role was played well.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Not too screamy not to masculine but just right.</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
    <tr>
      <th>13</th>
      <td>The camera really likes her in this movie.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>14</th>
      <td>I would have casted her in that role after ready the script.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[247]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sentence</th>
      <th>Polarity</th>
      <th>Predicted</th>
      <th>Validation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>585</th>
      <td>Still it's quite interesting and entertaining to follow.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>586</th>
      <td>;) Recommend with confidence!</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>587</th>
      <td>This movie is well-balanced with comedy and drama and I thoroughly enjoyed myself.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>588</th>
      <td>It was a riot to see Hugo Weaving play a sex-obsessed gay real estate salesman who uses his clie...</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
    <tr>
      <th>589</th>
      <td>:) Anyway, the plot flowed smoothly and the male-bonding scenes were a hoot.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>590</th>
      <td>The opening sequence of this gem is a classic, and the cat n mouse games that follow are a delig...</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>591</th>
      <td>Fans of the genre will be in heaven.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>592</th>
      <td>Lange had become a great actress.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>593</th>
      <td>It looked like a wonderful story.</td>
      <td>1</td>
      <td>1</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>594</th>
      <td>I never walked out of a movie faster.</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>595</th>
      <td>I just got bored watching Jessice Lange take her clothes off!</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>596</th>
      <td>Unfortunately, any virtue in this film's production work was lost on a regrettable script.</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>597</th>
      <td>In a word, it is embarrassing.</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>598</th>
      <td>Exceptionally bad!</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
    <tr>
      <th>599</th>
      <td>All in all its an insult to one's intelligence and a huge waste of money.</td>
      <td>0</td>
      <td>0</td>
      <td>Correct</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Export-Incorrect-Prediction-Results-(sentiment_test-data)">Export Incorrect Prediction Results (sentiment_test data)<a class="anchor-link" href="#Export-Incorrect-Prediction-Results-(sentiment_test-data)">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[248]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Select the predictions that are incorrect.</span>
<span class="c1"># Export to a separate csv. This file will be used for responding on Q2 Task 3.</span>

<span class="n">incorrect_pred</span> <span class="o">=</span> <span class="n">df_test_pred</span><span class="p">[</span><span class="n">df_test_pred</span><span class="o">.</span><span class="n">Validation</span> <span class="o">==</span> <span class="s2">&quot;Incorrect&quot;</span><span class="p">]</span>
<span class="n">incorrect_pred</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># Uncomment below to export to a separate csv.</span>
<span class="c1"># incorrect_pred.to_csv(&quot;incorrect_pred.csv&quot;)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[248]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sentence</th>
      <th>Polarity</th>
      <th>Predicted</th>
      <th>Validation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12</th>
      <td>Not too screamy not to masculine but just right.</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
    <tr>
      <th>36</th>
      <td>The soundtrack wasn't terrible, either.</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Still, it was the SETS that got a big "10" on my "oy-vey" scale.</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
    <tr>
      <th>43</th>
      <td>The last 15 minutes of movie are also not bad as well.</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
    <tr>
      <th>48</th>
      <td>My 8/10 score is mostly for the plot.</td>
      <td>1</td>
      <td>0</td>
      <td>Incorrect</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Explore-the-Model-Further">Explore the Model Further<a class="anchor-link" href="#Explore-the-Model-Further">&#182;</a></h1><p>Understanding what the model learned.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Print-Topics">Print Topics<a class="anchor-link" href="#Print-Topics">&#182;</a></h2><p>Print the top words for each of the NMF topics</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[249]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_top_words</span> <span class="o">=</span> <span class="mi">12</span>
<span class="k">def</span> <span class="nf">get_top_words</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">topic_idx</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">H</span><span class="p">):</span>
        <span class="n">top_words</span> <span class="o">=</span> <span class="p">[(</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">topic</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="o">-</span><span class="n">n_top_words</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">top_words</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> 

<span class="n">top_words</span> <span class="o">=</span> <span class="n">get_top_words</span><span class="p">(</span><span class="n">nmf_obj</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">vectorizer_obj2</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="n">top_words</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[249]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>great</td>
      <td>great food</td>
      <td>great product</td>
      <td>great service</td>
      <td>food great</td>
      <td>director</td>
      <td>choice</td>
      <td>great price</td>
      <td>great place</td>
      <td>great film</td>
      <td>working</td>
      <td>really great</td>
    </tr>
    <tr>
      <th>1</th>
      <td>good</td>
      <td>food good</td>
      <td>good quality</td>
      <td>good product</td>
      <td>good food</td>
      <td>good price</td>
      <td>good service</td>
      <td>stuff</td>
      <td>really good</td>
      <td>good thing</td>
      <td>good time</td>
      <td>good phone</td>
    </tr>
    <tr>
      <th>2</th>
      <td>service</td>
      <td>customer</td>
      <td>customer service</td>
      <td>great service</td>
      <td>fast</td>
      <td>food service</td>
      <td>friendly</td>
      <td>service food</td>
      <td>good service</td>
      <td>unreliable</td>
      <td>mobile</td>
      <td>cooked</td>
    </tr>
    <tr>
      <th>3</th>
      <td>phone</td>
      <td>new</td>
      <td>phone ve</td>
      <td>sturdy</td>
      <td>ve</td>
      <td>cell phone</td>
      <td>cell</td>
      <td>good phone</td>
      <td>motorola</td>
      <td>hand</td>
      <td>phone great</td>
      <td>nokia</td>
    </tr>
    <tr>
      <th>4</th>
      <td>place</td>
      <td>recommend place</td>
      <td>love place</td>
      <td>phoenix</td>
      <td>authentic</td>
      <td>lot</td>
      <td>great place</td>
      <td>town</td>
      <td>clean</td>
      <td>place eat</td>
      <td>impressive</td>
      <td>hope</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>195</th>
      <td>returning</td>
      <td>changing</td>
      <td>probably</td>
      <td>phone</td>
      <td>zero star</td>
      <td>forget</td>
      <td>funny</td>
      <td>fun</td>
      <td>fry</td>
      <td>friendly staff</td>
      <td>friendly</td>
      <td>friend</td>
    </tr>
    <tr>
      <th>196</th>
      <td>liked</td>
      <td>white</td>
      <td>patio</td>
      <td>movie</td>
      <td>year ago</td>
      <td>verizon</td>
      <td>ago</td>
      <td>delish</td>
      <td>non</td>
      <td>parent</td>
      <td>choice</td>
      <td>especially</td>
    </tr>
    <tr>
      <th>197</th>
      <td>script</td>
      <td>direction</td>
      <td>worse</td>
      <td>problem</td>
      <td>acting</td>
      <td>bad</td>
      <td>horrible</td>
      <td>make</td>
      <td>food average</td>
      <td>form</td>
      <td>fun</td>
      <td>fry</td>
    </tr>
    <tr>
      <th>198</th>
      <td>kid</td>
      <td>annoying</td>
      <td>nasty</td>
      <td>play</td>
      <td>area</td>
      <td>hilarious</td>
      <td>watch</td>
      <td>cover</td>
      <td>girl</td>
      <td>option</td>
      <td>hit</td>
      <td>parent</td>
    </tr>
    <tr>
      <th>199</th>
      <td>buyer</td>
      <td>money</td>
      <td>right</td>
      <td>forced</td>
      <td>fun</td>
      <td>fry</td>
      <td>friendly staff</td>
      <td>friendly</td>
      <td>friend</td>
      <td>fried</td>
      <td>fresh</td>
      <td>free</td>
    </tr>
  </tbody>
</table>
<p>200 rows  12 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Print-Feature-Importances">Print Feature Importances<a class="anchor-link" href="#Print-Feature-Importances">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[250]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">topic_feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;topic </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nmf_obj</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)]</span>

<span class="n">stat_feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">transformer_list</span> <span class="k">if</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;topics&#39;</span><span class="p">,</span> <span class="s1">&#39;bow&#39;</span><span class="p">]]</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="n">vectorizer_obj</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span> <span class="o">+</span> <span class="n">topic_feature_names</span> <span class="o">+</span> <span class="n">stat_feature_names</span>
<span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>

<span class="n">feature_importances</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">clf_obj</span><span class="p">,</span> <span class="s1">&#39;feature_importances_&#39;</span><span class="p">):</span>
    <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">clf_obj</span><span class="o">.</span><span class="n">feature_importances_</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[250]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>2137</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[251]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">features_train</span> <span class="o">=</span> <span class="n">feature_processing_obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>

<span class="k">if</span> <span class="n">feature_importances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No Feature importances! Skipping.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">features_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">ssum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">avg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">avg_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">avg_neg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">ssum</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">features_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">avg</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">features_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">avg_pos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">features_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">avg_neg</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">features_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">et</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span>
    <span class="n">imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> <span class="s1">&#39;imp&#39;</span><span class="p">:</span> <span class="n">feature_importances</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span> <span class="n">ssum</span><span class="p">,</span> <span class="s1">&#39;avg&#39;</span><span class="p">:</span> <span class="n">avg</span><span class="p">,</span> <span class="s1">&#39;avg_neg&#39;</span><span class="p">:</span> <span class="n">avg_neg</span><span class="p">,</span> <span class="s1">&#39;avg_pos&#39;</span><span class="p">:</span> <span class="n">avg_pos</span><span class="p">})</span>
    <span class="n">imp</span> <span class="o">=</span> <span class="n">imp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;imp&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">imp</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">imp</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1">#imp.to_csv(&#39;importances.csv&#39;, index=False)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[251]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>imp</th>
      <th>sum</th>
      <th>avg</th>
      <th>avg_neg</th>
      <th>avg_pos</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.087217</td>
      <td>300.616700</td>
      <td>0.147361</td>
      <td>-0.166900</td>
      <td>0.462240</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.061807</td>
      <td>319.436854</td>
      <td>0.156587</td>
      <td>-0.109893</td>
      <td>0.423590</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.058776</td>
      <td>398.151000</td>
      <td>0.195172</td>
      <td>0.058933</td>
      <td>0.331678</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.043533</td>
      <td>2237.000000</td>
      <td>1.096569</td>
      <td>-0.579824</td>
      <td>2.776251</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.019577</td>
      <td>238.000000</td>
      <td>0.116667</td>
      <td>0.193928</td>
      <td>0.039254</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.017353</td>
      <td>100.647117</td>
      <td>0.049337</td>
      <td>0.083068</td>
      <td>0.015540</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.014197</td>
      <td>56.951240</td>
      <td>0.027917</td>
      <td>0.000834</td>
      <td>0.055054</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.010093</td>
      <td>14.919174</td>
      <td>0.007313</td>
      <td>0.000261</td>
      <td>0.014379</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>0.006625</td>
      <td>22250.000000</td>
      <td>10.906863</td>
      <td>11.387855</td>
      <td>10.424926</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>0.006148</td>
      <td>121677.000000</td>
      <td>59.645588</td>
      <td>61.666014</td>
      <td>57.621197</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.005744</td>
      <td>53.344873</td>
      <td>0.026149</td>
      <td>0.010418</td>
      <td>0.041911</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.004979</td>
      <td>8.263980</td>
      <td>0.004051</td>
      <td>0.008080</td>
      <td>0.000014</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.004406</td>
      <td>17.783197</td>
      <td>0.008717</td>
      <td>0.015959</td>
      <td>0.001461</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.004364</td>
      <td>183.737899</td>
      <td>0.090068</td>
      <td>0.073920</td>
      <td>0.106247</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.004189</td>
      <td>15.407313</td>
      <td>0.007553</td>
      <td>0.003612</td>
      <td>0.011501</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>0.004057</td>
      <td>4163.000000</td>
      <td>2.040686</td>
      <td>2.105779</td>
      <td>1.975466</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.003769</td>
      <td>15.793601</td>
      <td>0.007742</td>
      <td>0.015469</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.003573</td>
      <td>13.070491</td>
      <td>0.006407</td>
      <td>0.000423</td>
      <td>0.012403</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.003466</td>
      <td>123.234186</td>
      <td>0.060409</td>
      <td>0.049745</td>
      <td>0.071094</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>0.003451</td>
      <td>4142.000000</td>
      <td>2.030392</td>
      <td>2.219393</td>
      <td>1.841021</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[251]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>imp</th>
      <th>sum</th>
      <th>avg</th>
      <th>avg_neg</th>
      <th>avg_pos</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>62</th>
      <td>and food</td>
      <td>6.128079e-07</td>
      <td>1.233394</td>
      <td>0.000605</td>
      <td>0.000000</td>
      <td>0.001210</td>
    </tr>
    <tr>
      <th>241</th>
      <td>bunch of</td>
      <td>5.764693e-07</td>
      <td>0.728818</td>
      <td>0.000357</td>
      <td>0.000541</td>
      <td>0.000173</td>
    </tr>
    <tr>
      <th>214</th>
      <td>biscuit</td>
      <td>2.324298e-07</td>
      <td>1.024377</td>
      <td>0.000502</td>
      <td>0.000231</td>
      <td>0.000774</td>
    </tr>
    <tr>
      <th>1445</th>
      <td>terrific</td>
      <td>2.085302e-07</td>
      <td>0.822836</td>
      <td>0.000403</td>
      <td>0.000000</td>
      <td>0.000807</td>
    </tr>
    <tr>
      <th>780</th>
      <td>is perfect</td>
      <td>1.012414e-07</td>
      <td>0.993901</td>
      <td>0.000487</td>
      <td>0.000000</td>
      <td>0.000975</td>
    </tr>
    <tr>
      <th>615</th>
      <td>great deal</td>
      <td>9.751969e-08</td>
      <td>0.887990</td>
      <td>0.000435</td>
      <td>0.000000</td>
      <td>0.000871</td>
    </tr>
    <tr>
      <th>64</th>
      <td>and friendly</td>
      <td>9.143774e-08</td>
      <td>0.856606</td>
      <td>0.000420</td>
      <td>0.000000</td>
      <td>0.000841</td>
    </tr>
    <tr>
      <th>1393</th>
      <td>staff are</td>
      <td>0.000000e+00</td>
      <td>0.771312</td>
      <td>0.000378</td>
      <td>0.000188</td>
      <td>0.000568</td>
    </tr>
    <tr>
      <th>1992</th>
      <td>topic 66</td>
      <td>0.000000e+00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1989</th>
      <td>topic 63</td>
      <td>0.000000e+00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Further-explanation-on-Sentiment_Train-Data">Further explanation on Sentiment_Train Data<a class="anchor-link" href="#Further-explanation-on-Sentiment_Train-Data">&#182;</a></h1><p>Explain all predictions that were incorrect of a tree-based model.</p>
<p>Note: It will crash when using non tree-based model e.g., MLPClassifier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[252]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">feature_importances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No Feature importances! Skipping.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>

    <span class="kn">from</span> <span class="nn">treeinterpreter</span> <span class="kn">import</span> <span class="n">treeinterpreter</span> <span class="k">as</span> <span class="n">ti</span>

    <span class="n">prediction</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">contributions</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clf_obj</span><span class="p">,</span> <span class="n">features_val</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features_val</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">y_val</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">pred_val</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Instance </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="n">X_val</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bias (trainset mean) </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Truth </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_val</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prediction</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature contributions:&quot;</span><span class="p">)</span>
        <span class="n">con</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span> 
                                 <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">features_val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">A1</span><span class="p">,</span>
                                 <span class="s1">&#39;neg contr&#39;</span><span class="p">:</span> <span class="n">contributions</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span>
                                 <span class="s1">&#39;pos contr&#39;</span><span class="p">:</span> <span class="n">contributions</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
                                 <span class="s1">&#39;abs contr&#39;</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">contributions</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">])})</span>

        <span class="n">con</span> <span class="o">=</span> <span class="n">con</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;abs contr&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">con</span><span class="p">[</span><span class="s1">&#39;pos cumulative&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">con</span><span class="p">[</span><span class="s1">&#39;pos contr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">+</span> <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">con</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Instance 1
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;It fits so securely that the ear hook does not even need to be used and the sound is better directed through your ear canal.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.445 0.555]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.122051</td>
      <td>0.122051</td>
      <td>0.122051</td>
      <td>0.621561</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.070000e-01</td>
      <td>0.067199</td>
      <td>-0.067199</td>
      <td>0.067199</td>
      <td>0.554362</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.198000e-01</td>
      <td>-0.048036</td>
      <td>0.048036</td>
      <td>0.048036</td>
      <td>0.602398</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.041185</td>
      <td>-0.041185</td>
      <td>0.041185</td>
      <td>0.561213</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.333333e-01</td>
      <td>-0.015501</td>
      <td>0.015501</td>
      <td>0.015501</td>
      <td>0.576715</td>
    </tr>
    <tr>
      <th>1960</th>
      <td>topic 34</td>
      <td>2.798374e-01</td>
      <td>0.008250</td>
      <td>-0.008250</td>
      <td>0.008250</td>
      <td>0.568465</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007952</td>
      <td>-0.007952</td>
      <td>0.007952</td>
      <td>0.560513</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.170931e-75</td>
      <td>0.007620</td>
      <td>-0.007620</td>
      <td>0.007620</td>
      <td>0.552892</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.767767e-01</td>
      <td>-0.007077</td>
      <td>0.007077</td>
      <td>0.007077</td>
      <td>0.559970</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.006924</td>
      <td>-0.006924</td>
      <td>0.006924</td>
      <td>0.553046</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005948</td>
      <td>-0.005948</td>
      <td>0.005948</td>
      <td>0.547098</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>1.767767e-01</td>
      <td>0.005315</td>
      <td>-0.005315</td>
      <td>0.005315</td>
      <td>0.541783</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.054003e-199</td>
      <td>0.004090</td>
      <td>-0.004090</td>
      <td>0.004090</td>
      <td>0.537693</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004013</td>
      <td>-0.004013</td>
      <td>0.004013</td>
      <td>0.533680</td>
    </tr>
    <tr>
      <th>1963</th>
      <td>topic 37</td>
      <td>1.082547e-01</td>
      <td>0.003652</td>
      <td>-0.003652</td>
      <td>0.003652</td>
      <td>0.530028</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.240000e+02</td>
      <td>0.003444</td>
      <td>-0.003444</td>
      <td>0.003444</td>
      <td>0.526585</td>
    </tr>
    <tr>
      <th>1706</th>
      <td>used</td>
      <td>1.767767e-01</td>
      <td>0.003435</td>
      <td>-0.003435</td>
      <td>0.003435</td>
      <td>0.523150</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003288</td>
      <td>0.003288</td>
      <td>0.003288</td>
      <td>0.526437</td>
    </tr>
    <tr>
      <th>1978</th>
      <td>topic 52</td>
      <td>1.365429e-01</td>
      <td>-0.003152</td>
      <td>0.003152</td>
      <td>0.003152</td>
      <td>0.529590</td>
    </tr>
    <tr>
      <th>512</th>
      <td>fit</td>
      <td>1.767767e-01</td>
      <td>-0.002954</td>
      <td>0.002954</td>
      <td>0.002954</td>
      <td>0.532544</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002929</td>
      <td>-0.002929</td>
      <td>0.002929</td>
      <td>0.529614</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.002799</td>
      <td>-0.002799</td>
      <td>0.002799</td>
      <td>0.526815</td>
    </tr>
    <tr>
      <th>1031</th>
      <td>not even</td>
      <td>1.767767e-01</td>
      <td>-0.002776</td>
      <td>0.002776</td>
      <td>0.002776</td>
      <td>0.529592</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002744</td>
      <td>-0.002744</td>
      <td>0.002744</td>
      <td>0.526847</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002674</td>
      <td>0.002674</td>
      <td>0.002674</td>
      <td>0.529521</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002671</td>
      <td>0.002671</td>
      <td>0.002671</td>
      <td>0.532191</td>
    </tr>
    <tr>
      <th>206</th>
      <td>better</td>
      <td>1.767767e-01</td>
      <td>0.002578</td>
      <td>-0.002578</td>
      <td>0.002578</td>
      <td>0.529613</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002562</td>
      <td>0.002562</td>
      <td>0.002562</td>
      <td>0.532176</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.618888e-240</td>
      <td>-0.002537</td>
      <td>0.002537</td>
      <td>0.002537</td>
      <td>0.534713</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002485</td>
      <td>0.002485</td>
      <td>0.002485</td>
      <td>0.537198</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 25
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Be sure to order dessert, even if you need to pack it to-go - the tiramisu and cannoli are both to die for.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.865 0.135]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-3.000000e+00</td>
      <td>0.181563</td>
      <td>-0.181563</td>
      <td>0.181563</td>
      <td>0.317947</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-3.818000e-01</td>
      <td>0.091521</td>
      <td>-0.091521</td>
      <td>0.091521</td>
      <td>0.226426</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>8.800000e-02</td>
      <td>0.067152</td>
      <td>-0.067152</td>
      <td>0.067152</td>
      <td>0.159274</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.000000e-01</td>
      <td>-0.032416</td>
      <td>0.032416</td>
      <td>0.032416</td>
      <td>0.191690</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.021791</td>
      <td>0.021791</td>
      <td>0.021791</td>
      <td>0.213480</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016646</td>
      <td>0.016646</td>
      <td>0.016646</td>
      <td>0.230127</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009296</td>
      <td>-0.009296</td>
      <td>0.009296</td>
      <td>0.220831</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.704390e-41</td>
      <td>0.006464</td>
      <td>-0.006464</td>
      <td>0.006464</td>
      <td>0.214368</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005740</td>
      <td>-0.005740</td>
      <td>0.005740</td>
      <td>0.208627</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.070000e+02</td>
      <td>0.005054</td>
      <td>-0.005054</td>
      <td>0.005054</td>
      <td>0.203573</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004645</td>
      <td>-0.004645</td>
      <td>0.004645</td>
      <td>0.198928</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>0.000000e+00</td>
      <td>0.004200</td>
      <td>-0.004200</td>
      <td>0.004200</td>
      <td>0.194728</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004031</td>
      <td>-0.004031</td>
      <td>0.004031</td>
      <td>0.190698</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>1.714986e-01</td>
      <td>-0.003966</td>
      <td>0.003966</td>
      <td>0.003966</td>
      <td>0.194664</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>0.003949</td>
      <td>-0.003949</td>
      <td>0.003949</td>
      <td>0.190715</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>6.859943e-01</td>
      <td>0.003694</td>
      <td>-0.003694</td>
      <td>0.003694</td>
      <td>0.187022</td>
    </tr>
    <tr>
      <th>2080</th>
      <td>topic 154</td>
      <td>0.000000e+00</td>
      <td>0.003480</td>
      <td>-0.003480</td>
      <td>0.003480</td>
      <td>0.183542</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>1.714986e-01</td>
      <td>0.003387</td>
      <td>-0.003387</td>
      <td>0.003387</td>
      <td>0.180155</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003196</td>
      <td>0.003196</td>
      <td>0.003196</td>
      <td>0.183351</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002942</td>
      <td>0.002942</td>
      <td>0.002942</td>
      <td>0.186293</td>
    </tr>
    <tr>
      <th>589</th>
      <td>go</td>
      <td>1.714986e-01</td>
      <td>0.002887</td>
      <td>-0.002887</td>
      <td>0.002887</td>
      <td>0.183405</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000e+00</td>
      <td>0.002861</td>
      <td>-0.002861</td>
      <td>0.002861</td>
      <td>0.180545</td>
    </tr>
    <tr>
      <th>2073</th>
      <td>topic 147</td>
      <td>1.371278e-02</td>
      <td>-0.002859</td>
      <td>0.002859</td>
      <td>0.002859</td>
      <td>0.183404</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002838</td>
      <td>-0.002838</td>
      <td>0.002838</td>
      <td>0.180566</td>
    </tr>
    <tr>
      <th>1110</th>
      <td>order</td>
      <td>1.714986e-01</td>
      <td>-0.002685</td>
      <td>0.002685</td>
      <td>0.002685</td>
      <td>0.183251</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002604</td>
      <td>0.002604</td>
      <td>0.002604</td>
      <td>0.185855</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002505</td>
      <td>-0.002505</td>
      <td>0.002505</td>
      <td>0.183350</td>
    </tr>
    <tr>
      <th>347</th>
      <td>could not</td>
      <td>0.000000e+00</td>
      <td>0.002498</td>
      <td>-0.002498</td>
      <td>0.002498</td>
      <td>0.180852</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002448</td>
      <td>-0.002448</td>
      <td>0.002448</td>
      <td>0.178404</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002433</td>
      <td>0.002433</td>
      <td>0.002433</td>
      <td>0.180837</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 40
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Not to mention the combination of pears, almonds and bacon is a big winner!&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.495 0.505]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>5.000000e+00</td>
      <td>-0.134139</td>
      <td>0.134139</td>
      <td>0.134139</td>
      <td>0.633649</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.540000e-01</td>
      <td>0.063503</td>
      <td>-0.063503</td>
      <td>0.063503</td>
      <td>0.570146</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.039898</td>
      <td>-0.039898</td>
      <td>0.039898</td>
      <td>0.530248</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.239000e-01</td>
      <td>-0.039497</td>
      <td>0.039497</td>
      <td>0.039497</td>
      <td>0.569745</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.034693</td>
      <td>-0.034693</td>
      <td>0.034693</td>
      <td>0.535052</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.400000e+01</td>
      <td>0.018439</td>
      <td>-0.018439</td>
      <td>0.018439</td>
      <td>0.516613</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.017967</td>
      <td>0.017967</td>
      <td>0.017967</td>
      <td>0.534580</td>
    </tr>
    <tr>
      <th>2061</th>
      <td>topic 135</td>
      <td>5.589864e-02</td>
      <td>-0.009769</td>
      <td>0.009769</td>
      <td>0.009769</td>
      <td>0.544349</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007412</td>
      <td>-0.007412</td>
      <td>0.007412</td>
      <td>0.536937</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007185</td>
      <td>-0.007185</td>
      <td>0.007185</td>
      <td>0.529752</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.004917</td>
      <td>-0.004917</td>
      <td>0.004917</td>
      <td>0.524836</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003913</td>
      <td>-0.003913</td>
      <td>0.003913</td>
      <td>0.520923</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.507324e-08</td>
      <td>0.003781</td>
      <td>-0.003781</td>
      <td>0.003781</td>
      <td>0.517142</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>0.000000e+00</td>
      <td>-0.003724</td>
      <td>0.003724</td>
      <td>0.003724</td>
      <td>0.520866</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003367</td>
      <td>0.003367</td>
      <td>0.003367</td>
      <td>0.524233</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002887</td>
      <td>-0.002887</td>
      <td>0.002887</td>
      <td>0.521346</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002826</td>
      <td>0.002826</td>
      <td>0.002826</td>
      <td>0.524172</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.002802</td>
      <td>0.002802</td>
      <td>0.002802</td>
      <td>0.526974</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>3.535534e-01</td>
      <td>0.002583</td>
      <td>-0.002583</td>
      <td>0.002583</td>
      <td>0.524391</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.002517</td>
      <td>0.526908</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002433</td>
      <td>-0.002433</td>
      <td>0.002433</td>
      <td>0.524475</td>
    </tr>
    <tr>
      <th>142</th>
      <td>at the</td>
      <td>0.000000e+00</td>
      <td>0.002427</td>
      <td>-0.002427</td>
      <td>0.002427</td>
      <td>0.522048</td>
    </tr>
    <tr>
      <th>1766</th>
      <td>wa that</td>
      <td>0.000000e+00</td>
      <td>-0.002419</td>
      <td>0.002419</td>
      <td>0.002419</td>
      <td>0.524467</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.050997e-189</td>
      <td>-0.002380</td>
      <td>0.002380</td>
      <td>0.002380</td>
      <td>0.526847</td>
    </tr>
    <tr>
      <th>310</th>
      <td>cinematography</td>
      <td>0.000000e+00</td>
      <td>0.002346</td>
      <td>-0.002346</td>
      <td>0.002346</td>
      <td>0.524501</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002323</td>
      <td>0.002323</td>
      <td>0.002323</td>
      <td>0.526823</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.002291</td>
      <td>-0.002291</td>
      <td>0.002291</td>
      <td>0.524533</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>this place</td>
      <td>0.000000e+00</td>
      <td>0.002280</td>
      <td>-0.002280</td>
      <td>0.002280</td>
      <td>0.522253</td>
    </tr>
    <tr>
      <th>1929</th>
      <td>topic 3</td>
      <td>0.000000e+00</td>
      <td>-0.002253</td>
      <td>0.002253</td>
      <td>0.002253</td>
      <td>0.524505</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.002216</td>
      <td>-0.002216</td>
      <td>0.002216</td>
      <td>0.522289</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 41
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Someone shouldve invented this sooner.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8425 0.1575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.0</td>
      <td>0.085240</td>
      <td>-0.085240</td>
      <td>0.085240</td>
      <td>0.414270</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.0</td>
      <td>0.037966</td>
      <td>-0.037966</td>
      <td>0.037966</td>
      <td>0.376304</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.0</td>
      <td>0.032271</td>
      <td>-0.032271</td>
      <td>0.032271</td>
      <td>0.344033</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.0</td>
      <td>-0.025438</td>
      <td>0.025438</td>
      <td>0.025438</td>
      <td>0.369471</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.0</td>
      <td>-0.019574</td>
      <td>0.019574</td>
      <td>0.019574</td>
      <td>0.389045</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>38.0</td>
      <td>0.018135</td>
      <td>-0.018135</td>
      <td>0.018135</td>
      <td>0.370910</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.0</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.361103</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.0</td>
      <td>-0.008623</td>
      <td>0.008623</td>
      <td>0.008623</td>
      <td>0.369726</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.0</td>
      <td>0.008076</td>
      <td>-0.008076</td>
      <td>0.008076</td>
      <td>0.361650</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.0</td>
      <td>0.007530</td>
      <td>-0.007530</td>
      <td>0.007530</td>
      <td>0.354120</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.0</td>
      <td>0.007236</td>
      <td>-0.007236</td>
      <td>0.007236</td>
      <td>0.346884</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.0</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.340345</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.0</td>
      <td>0.005649</td>
      <td>-0.005649</td>
      <td>0.005649</td>
      <td>0.334696</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.0</td>
      <td>-0.005630</td>
      <td>0.005630</td>
      <td>0.005630</td>
      <td>0.340326</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.0</td>
      <td>-0.005433</td>
      <td>0.005433</td>
      <td>0.005433</td>
      <td>0.345759</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.0</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.340772</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.0</td>
      <td>0.004793</td>
      <td>-0.004793</td>
      <td>0.004793</td>
      <td>0.335979</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.0</td>
      <td>0.004648</td>
      <td>-0.004648</td>
      <td>0.004648</td>
      <td>0.331332</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.0</td>
      <td>0.004449</td>
      <td>-0.004449</td>
      <td>0.004449</td>
      <td>0.326883</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.0</td>
      <td>-0.004401</td>
      <td>0.004401</td>
      <td>0.004401</td>
      <td>0.331284</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.0</td>
      <td>-0.004103</td>
      <td>0.004103</td>
      <td>0.004103</td>
      <td>0.335386</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.0</td>
      <td>0.004081</td>
      <td>-0.004081</td>
      <td>0.004081</td>
      <td>0.331305</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.0</td>
      <td>-0.003984</td>
      <td>0.003984</td>
      <td>0.003984</td>
      <td>0.335290</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.0</td>
      <td>-0.003848</td>
      <td>0.003848</td>
      <td>0.003848</td>
      <td>0.339138</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.0</td>
      <td>0.003847</td>
      <td>-0.003847</td>
      <td>0.003847</td>
      <td>0.335291</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.0</td>
      <td>0.003623</td>
      <td>-0.003623</td>
      <td>0.003623</td>
      <td>0.331668</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.0</td>
      <td>0.003473</td>
      <td>-0.003473</td>
      <td>0.003473</td>
      <td>0.328195</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.0</td>
      <td>0.003380</td>
      <td>-0.003380</td>
      <td>0.003380</td>
      <td>0.324815</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.0</td>
      <td>0.003365</td>
      <td>-0.003365</td>
      <td>0.003365</td>
      <td>0.321449</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.0</td>
      <td>-0.003312</td>
      <td>0.003312</td>
      <td>0.003312</td>
      <td>0.324761</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 47
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;This was a poor remake of &#34;My Best Friends Wedding&#34;.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.42 0.58]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.076973</td>
      <td>0.076973</td>
      <td>0.076973</td>
      <td>0.576482</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>4.450000e-01</td>
      <td>0.052455</td>
      <td>-0.052455</td>
      <td>0.052455</td>
      <td>0.524028</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.369000e-01</td>
      <td>-0.040669</td>
      <td>0.040669</td>
      <td>0.040669</td>
      <td>0.564697</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023647</td>
      <td>0.023647</td>
      <td>0.023647</td>
      <td>0.588345</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021288</td>
      <td>0.021288</td>
      <td>0.021288</td>
      <td>0.609632</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>0.015569</td>
      <td>-0.015569</td>
      <td>0.015569</td>
      <td>0.594063</td>
    </tr>
    <tr>
      <th>1199</th>
      <td>poor</td>
      <td>3.333333e-01</td>
      <td>0.014846</td>
      <td>-0.014846</td>
      <td>0.014846</td>
      <td>0.579218</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.000000e+01</td>
      <td>0.014380</td>
      <td>-0.014380</td>
      <td>0.014380</td>
      <td>0.564838</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.010301</td>
      <td>-0.010301</td>
      <td>0.010301</td>
      <td>0.554536</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009579</td>
      <td>-0.009579</td>
      <td>0.009579</td>
      <td>0.544957</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>8.123486e-227</td>
      <td>0.007727</td>
      <td>-0.007727</td>
      <td>0.007727</td>
      <td>0.537230</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006939</td>
      <td>-0.006939</td>
      <td>0.006939</td>
      <td>0.530292</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006462</td>
      <td>-0.006462</td>
      <td>0.006462</td>
      <td>0.523829</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.005085</td>
      <td>-0.005085</td>
      <td>0.005085</td>
      <td>0.518744</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005029</td>
      <td>-0.005029</td>
      <td>0.005029</td>
      <td>0.513715</td>
    </tr>
    <tr>
      <th>1993</th>
      <td>topic 67</td>
      <td>2.842513e-01</td>
      <td>0.003773</td>
      <td>-0.003773</td>
      <td>0.003773</td>
      <td>0.509941</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003715</td>
      <td>0.003715</td>
      <td>0.003715</td>
      <td>0.513656</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003625</td>
      <td>0.003625</td>
      <td>0.003625</td>
      <td>0.517281</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003454</td>
      <td>-0.003454</td>
      <td>0.003454</td>
      <td>0.513827</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003258</td>
      <td>0.003258</td>
      <td>0.003258</td>
      <td>0.517085</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>7.718170e-30</td>
      <td>-0.003068</td>
      <td>0.003068</td>
      <td>0.003068</td>
      <td>0.520154</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>0.000000e+00</td>
      <td>-0.003032</td>
      <td>0.003032</td>
      <td>0.003032</td>
      <td>0.523185</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003012</td>
      <td>0.003012</td>
      <td>0.003012</td>
      <td>0.526197</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002917</td>
      <td>0.002917</td>
      <td>0.002917</td>
      <td>0.529114</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002894</td>
      <td>0.002894</td>
      <td>0.002894</td>
      <td>0.532008</td>
    </tr>
    <tr>
      <th>1767</th>
      <td>wa the</td>
      <td>0.000000e+00</td>
      <td>-0.002890</td>
      <td>0.002890</td>
      <td>0.002890</td>
      <td>0.534898</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002846</td>
      <td>-0.002846</td>
      <td>0.002846</td>
      <td>0.532052</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002728</td>
      <td>0.002728</td>
      <td>0.002728</td>
      <td>0.534780</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.400000e+01</td>
      <td>0.002581</td>
      <td>-0.002581</td>
      <td>0.002581</td>
      <td>0.532198</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>3.333333e-01</td>
      <td>-0.002573</td>
      <td>0.002573</td>
      <td>0.002573</td>
      <td>0.534772</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 58
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The loudspeaker option is great, the bumpers with the lights is very ... appealing.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.255 0.745]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>5.000000e+00</td>
      <td>-0.150072</td>
      <td>0.150072</td>
      <td>0.150072</td>
      <td>0.649582</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.400000e-01</td>
      <td>0.075415</td>
      <td>-0.075415</td>
      <td>0.075415</td>
      <td>0.574167</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.249000e-01</td>
      <td>-0.048861</td>
      <td>0.048861</td>
      <td>0.048861</td>
      <td>0.623028</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022128</td>
      <td>0.022128</td>
      <td>0.022128</td>
      <td>0.645156</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.000000e-01</td>
      <td>-0.021374</td>
      <td>0.021374</td>
      <td>0.021374</td>
      <td>0.666530</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019933</td>
      <td>0.019933</td>
      <td>0.019933</td>
      <td>0.686463</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.300000e+01</td>
      <td>0.015126</td>
      <td>-0.015126</td>
      <td>0.015126</td>
      <td>0.671337</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>2.773501e-01</td>
      <td>-0.008524</td>
      <td>0.008524</td>
      <td>0.008524</td>
      <td>0.679861</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008209</td>
      <td>-0.008209</td>
      <td>0.008209</td>
      <td>0.671652</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>topic 82</td>
      <td>6.514291e-04</td>
      <td>-0.007118</td>
      <td>0.007118</td>
      <td>0.007118</td>
      <td>0.678771</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006348</td>
      <td>-0.006348</td>
      <td>0.006348</td>
      <td>0.672422</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>-0.005209</td>
      <td>0.005209</td>
      <td>0.005209</td>
      <td>0.677631</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.960433e-02</td>
      <td>0.005076</td>
      <td>-0.005076</td>
      <td>0.005076</td>
      <td>0.672555</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>6.901345e-309</td>
      <td>0.004923</td>
      <td>-0.004923</td>
      <td>0.004923</td>
      <td>0.667632</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>1.400647e-02</td>
      <td>0.004188</td>
      <td>-0.004188</td>
      <td>0.004188</td>
      <td>0.663444</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003865</td>
      <td>0.003865</td>
      <td>0.003865</td>
      <td>0.667309</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003550</td>
      <td>0.003550</td>
      <td>0.003550</td>
      <td>0.670858</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003283</td>
      <td>-0.003283</td>
      <td>0.003283</td>
      <td>0.667575</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>5.547002e-01</td>
      <td>0.002778</td>
      <td>-0.002778</td>
      <td>0.002778</td>
      <td>0.664797</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002716</td>
      <td>-0.002716</td>
      <td>0.002716</td>
      <td>0.662081</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002715</td>
      <td>-0.002715</td>
      <td>0.002715</td>
      <td>0.659366</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002649</td>
      <td>0.002649</td>
      <td>0.002649</td>
      <td>0.662016</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002632</td>
      <td>0.002632</td>
      <td>0.002632</td>
      <td>0.664648</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002579</td>
      <td>0.002579</td>
      <td>0.002579</td>
      <td>0.667226</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002547</td>
      <td>0.002547</td>
      <td>0.002547</td>
      <td>0.669773</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002411</td>
      <td>0.002411</td>
      <td>0.002411</td>
      <td>0.672184</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002410</td>
      <td>0.002410</td>
      <td>0.002410</td>
      <td>0.674595</td>
    </tr>
    <tr>
      <th>1758</th>
      <td>wa not</td>
      <td>0.000000e+00</td>
      <td>-0.002272</td>
      <td>0.002272</td>
      <td>0.002272</td>
      <td>0.676867</td>
    </tr>
    <tr>
      <th>771</th>
      <td>is great</td>
      <td>2.773501e-01</td>
      <td>-0.002193</td>
      <td>0.002193</td>
      <td>0.002193</td>
      <td>0.679060</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002111</td>
      <td>0.002111</td>
      <td>0.002111</td>
      <td>0.681171</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 75
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The Greek dressing was very creamy and flavorful.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.765 0.235]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.0</td>
      <td>0.089898</td>
      <td>-0.089898</td>
      <td>0.089898</td>
      <td>0.409612</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.1</td>
      <td>0.026663</td>
      <td>-0.026663</td>
      <td>0.026663</td>
      <td>0.382949</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.0</td>
      <td>-0.025885</td>
      <td>0.025885</td>
      <td>0.025885</td>
      <td>0.408834</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.0</td>
      <td>0.025146</td>
      <td>-0.025146</td>
      <td>0.025146</td>
      <td>0.383688</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.0</td>
      <td>-0.019495</td>
      <td>0.019495</td>
      <td>0.019495</td>
      <td>0.403183</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>49.0</td>
      <td>0.018125</td>
      <td>-0.018125</td>
      <td>0.018125</td>
      <td>0.385058</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.0</td>
      <td>-0.010662</td>
      <td>0.010662</td>
      <td>0.010662</td>
      <td>0.395720</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.0</td>
      <td>0.009884</td>
      <td>-0.009884</td>
      <td>0.009884</td>
      <td>0.385836</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.0</td>
      <td>0.007818</td>
      <td>-0.007818</td>
      <td>0.007818</td>
      <td>0.378018</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.0</td>
      <td>0.007585</td>
      <td>-0.007585</td>
      <td>0.007585</td>
      <td>0.370434</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.0</td>
      <td>0.007364</td>
      <td>-0.007364</td>
      <td>0.007364</td>
      <td>0.363069</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.0</td>
      <td>0.006370</td>
      <td>-0.006370</td>
      <td>0.006370</td>
      <td>0.356699</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.0</td>
      <td>-0.005117</td>
      <td>0.005117</td>
      <td>0.005117</td>
      <td>0.361816</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.0</td>
      <td>0.004793</td>
      <td>-0.004793</td>
      <td>0.004793</td>
      <td>0.357024</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.0</td>
      <td>0.004764</td>
      <td>-0.004764</td>
      <td>0.004764</td>
      <td>0.352260</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.5</td>
      <td>-0.004693</td>
      <td>0.004693</td>
      <td>0.004693</td>
      <td>0.356953</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.5</td>
      <td>-0.004572</td>
      <td>0.004572</td>
      <td>0.004572</td>
      <td>0.361525</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.0</td>
      <td>0.004267</td>
      <td>-0.004267</td>
      <td>0.004267</td>
      <td>0.357258</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.0</td>
      <td>0.004057</td>
      <td>-0.004057</td>
      <td>0.004057</td>
      <td>0.353201</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.0</td>
      <td>-0.003884</td>
      <td>0.003884</td>
      <td>0.003884</td>
      <td>0.357085</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.0</td>
      <td>-0.003879</td>
      <td>0.003879</td>
      <td>0.003879</td>
      <td>0.360965</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.0</td>
      <td>0.003809</td>
      <td>-0.003809</td>
      <td>0.003809</td>
      <td>0.357156</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.0</td>
      <td>-0.003628</td>
      <td>0.003628</td>
      <td>0.003628</td>
      <td>0.360784</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.0</td>
      <td>0.003563</td>
      <td>-0.003563</td>
      <td>0.003563</td>
      <td>0.357221</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.0</td>
      <td>-0.003413</td>
      <td>0.003413</td>
      <td>0.003413</td>
      <td>0.360634</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.0</td>
      <td>-0.003342</td>
      <td>0.003342</td>
      <td>0.003342</td>
      <td>0.363977</td>
    </tr>
    <tr>
      <th>941</th>
      <td>meal</td>
      <td>0.0</td>
      <td>0.003247</td>
      <td>-0.003247</td>
      <td>0.003247</td>
      <td>0.360729</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.0</td>
      <td>0.003145</td>
      <td>-0.003145</td>
      <td>0.003145</td>
      <td>0.357584</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.0</td>
      <td>-0.003141</td>
      <td>0.003141</td>
      <td>0.003141</td>
      <td>0.360725</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.0</td>
      <td>-0.003118</td>
      <td>0.003118</td>
      <td>0.003118</td>
      <td>0.363843</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 77
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Lordy, the Khao Soi is a dish that is not to be missed for curry lovers!&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.82 0.18]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.156120</td>
      <td>-0.156120</td>
      <td>0.156120</td>
      <td>0.343390</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.788000e-01</td>
      <td>-0.048472</td>
      <td>0.048472</td>
      <td>0.048472</td>
      <td>0.391861</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.000000e-01</td>
      <td>0.047752</td>
      <td>-0.047752</td>
      <td>0.047752</td>
      <td>0.344110</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.042565</td>
      <td>-0.042565</td>
      <td>0.042565</td>
      <td>0.301544</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.030743</td>
      <td>-0.030743</td>
      <td>0.030743</td>
      <td>0.270801</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.017126</td>
      <td>0.017126</td>
      <td>0.017126</td>
      <td>0.287927</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.600000e+01</td>
      <td>0.014506</td>
      <td>-0.014506</td>
      <td>0.014506</td>
      <td>0.273422</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007644</td>
      <td>-0.007644</td>
      <td>0.007644</td>
      <td>0.265778</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007265</td>
      <td>-0.007265</td>
      <td>0.007265</td>
      <td>0.258513</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.212834e-15</td>
      <td>0.006428</td>
      <td>-0.006428</td>
      <td>0.006428</td>
      <td>0.252085</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005640</td>
      <td>-0.005640</td>
      <td>0.005640</td>
      <td>0.246445</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>0.000000e+00</td>
      <td>-0.005209</td>
      <td>0.005209</td>
      <td>0.005209</td>
      <td>0.251654</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>-0.004553</td>
      <td>0.004553</td>
      <td>0.004553</td>
      <td>0.256207</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>7.200000e+01</td>
      <td>0.004203</td>
      <td>-0.004203</td>
      <td>0.004203</td>
      <td>0.252003</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003966</td>
      <td>0.003966</td>
      <td>0.003966</td>
      <td>0.255969</td>
    </tr>
    <tr>
      <th>122</th>
      <td>are</td>
      <td>0.000000e+00</td>
      <td>0.003421</td>
      <td>-0.003421</td>
      <td>0.003421</td>
      <td>0.252548</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003334</td>
      <td>0.003334</td>
      <td>0.003334</td>
      <td>0.255882</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003320</td>
      <td>-0.003320</td>
      <td>0.003320</td>
      <td>0.252562</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002942</td>
      <td>0.002942</td>
      <td>0.002942</td>
      <td>0.255504</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002696</td>
      <td>-0.002696</td>
      <td>0.002696</td>
      <td>0.252809</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002663</td>
      <td>0.002663</td>
      <td>0.002663</td>
      <td>0.255472</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002647</td>
      <td>-0.002647</td>
      <td>0.002647</td>
      <td>0.252825</td>
    </tr>
    <tr>
      <th>1766</th>
      <td>wa that</td>
      <td>0.000000e+00</td>
      <td>-0.002419</td>
      <td>0.002419</td>
      <td>0.002419</td>
      <td>0.255244</td>
    </tr>
    <tr>
      <th>1946</th>
      <td>topic 20</td>
      <td>0.000000e+00</td>
      <td>-0.002413</td>
      <td>0.002413</td>
      <td>0.002413</td>
      <td>0.257657</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002355</td>
      <td>0.002355</td>
      <td>0.002355</td>
      <td>0.260011</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002312</td>
      <td>-0.002312</td>
      <td>0.002312</td>
      <td>0.257700</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002179</td>
      <td>0.002179</td>
      <td>0.002179</td>
      <td>0.259879</td>
    </tr>
    <tr>
      <th>682</th>
      <td>here</td>
      <td>0.000000e+00</td>
      <td>0.002175</td>
      <td>-0.002175</td>
      <td>0.002175</td>
      <td>0.257704</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>2.672612e-01</td>
      <td>0.002119</td>
      <td>-0.002119</td>
      <td>0.002119</td>
      <td>0.255586</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002020</td>
      <td>0.002020</td>
      <td>0.002020</td>
      <td>0.257605</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 82
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Battery charge-life is quite long.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.82 0.18]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085126</td>
      <td>-0.085126</td>
      <td>0.085126</td>
      <td>0.414384</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-5.000000e-02</td>
      <td>0.040825</td>
      <td>-0.040825</td>
      <td>0.040825</td>
      <td>0.373559</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.032855</td>
      <td>-0.032855</td>
      <td>0.032855</td>
      <td>0.340703</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025100</td>
      <td>0.025100</td>
      <td>0.025100</td>
      <td>0.365804</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019619</td>
      <td>0.019619</td>
      <td>0.019619</td>
      <td>0.385423</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.014171</td>
      <td>-0.014171</td>
      <td>0.014171</td>
      <td>0.371252</td>
    </tr>
    <tr>
      <th>1946</th>
      <td>topic 20</td>
      <td>1.936538e-01</td>
      <td>-0.012976</td>
      <td>0.012976</td>
      <td>0.012976</td>
      <td>0.384227</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009823</td>
      <td>-0.009823</td>
      <td>0.009823</td>
      <td>0.374404</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.535534e-01</td>
      <td>0.008086</td>
      <td>-0.008086</td>
      <td>0.008086</td>
      <td>0.366318</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.400000e+01</td>
      <td>0.007861</td>
      <td>-0.007861</td>
      <td>0.007861</td>
      <td>0.358457</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007606</td>
      <td>-0.007606</td>
      <td>0.007606</td>
      <td>0.350851</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.960277e-247</td>
      <td>0.007374</td>
      <td>-0.007374</td>
      <td>0.007374</td>
      <td>0.343477</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.336938</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>7.913321e-02</td>
      <td>-0.005954</td>
      <td>0.005954</td>
      <td>0.005954</td>
      <td>0.342892</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005637</td>
      <td>0.005637</td>
      <td>0.005637</td>
      <td>0.348529</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.005072</td>
      <td>-0.005072</td>
      <td>0.005072</td>
      <td>0.343457</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.759289e-51</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.338470</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004669</td>
      <td>-0.004669</td>
      <td>0.004669</td>
      <td>0.333801</td>
    </tr>
    <tr>
      <th>1236</th>
      <td>quite</td>
      <td>3.535534e-01</td>
      <td>-0.004585</td>
      <td>0.004585</td>
      <td>0.004585</td>
      <td>0.338385</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.004429</td>
      <td>0.004429</td>
      <td>0.004429</td>
      <td>0.342815</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004372</td>
      <td>-0.004372</td>
      <td>0.004372</td>
      <td>0.338443</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004357</td>
      <td>0.004357</td>
      <td>0.004357</td>
      <td>0.342801</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003882</td>
      <td>0.003882</td>
      <td>0.003882</td>
      <td>0.346683</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.609001e-194</td>
      <td>0.003714</td>
      <td>-0.003714</td>
      <td>0.003714</td>
      <td>0.342969</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003698</td>
      <td>0.003698</td>
      <td>0.003698</td>
      <td>0.346667</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003636</td>
      <td>0.003636</td>
      <td>0.003636</td>
      <td>0.350304</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003621</td>
      <td>0.003621</td>
      <td>0.003621</td>
      <td>0.353925</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003307</td>
      <td>-0.003307</td>
      <td>0.003307</td>
      <td>0.350618</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.115235e-296</td>
      <td>-0.003271</td>
      <td>0.003271</td>
      <td>0.003271</td>
      <td>0.353889</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003197</td>
      <td>-0.003197</td>
      <td>0.003197</td>
      <td>0.350692</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 98
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The picture resolution is far below what other comparably-priced phones are offering today.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.485 0.515]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.190473</td>
      <td>0.190473</td>
      <td>0.190473</td>
      <td>0.689983</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085861</td>
      <td>-0.085861</td>
      <td>0.085861</td>
      <td>0.604122</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.250000e-02</td>
      <td>0.036099</td>
      <td>-0.036099</td>
      <td>0.036099</td>
      <td>0.568023</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025593</td>
      <td>0.025593</td>
      <td>0.025593</td>
      <td>0.593616</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.300000e+01</td>
      <td>0.025099</td>
      <td>-0.025099</td>
      <td>0.025099</td>
      <td>0.568517</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019630</td>
      <td>0.019630</td>
      <td>0.019630</td>
      <td>0.588147</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.017997</td>
      <td>-0.017997</td>
      <td>0.017997</td>
      <td>0.570150</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.100000e+01</td>
      <td>-0.009429</td>
      <td>0.009429</td>
      <td>0.009429</td>
      <td>0.579579</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.009312</td>
      <td>-0.009312</td>
      <td>0.009312</td>
      <td>0.570267</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009134</td>
      <td>-0.009134</td>
      <td>0.009134</td>
      <td>0.561133</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008712</td>
      <td>-0.008712</td>
      <td>0.008712</td>
      <td>0.552420</td>
    </tr>
    <tr>
      <th>2017</th>
      <td>topic 91</td>
      <td>3.875311e-03</td>
      <td>-0.007905</td>
      <td>0.007905</td>
      <td>0.007905</td>
      <td>0.560326</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.966550e-33</td>
      <td>0.007489</td>
      <td>-0.007489</td>
      <td>0.007489</td>
      <td>0.552837</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.006163</td>
      <td>0.006163</td>
      <td>0.006163</td>
      <td>0.559000</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005796</td>
      <td>-0.005796</td>
      <td>0.005796</td>
      <td>0.553204</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.005602</td>
      <td>0.005602</td>
      <td>0.005602</td>
      <td>0.558806</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.131452e-132</td>
      <td>0.005081</td>
      <td>-0.005081</td>
      <td>0.005081</td>
      <td>0.553725</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004235</td>
      <td>-0.004235</td>
      <td>0.004235</td>
      <td>0.549491</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004183</td>
      <td>0.004183</td>
      <td>0.004183</td>
      <td>0.553674</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003925</td>
      <td>0.003925</td>
      <td>0.003925</td>
      <td>0.557599</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003882</td>
      <td>-0.003882</td>
      <td>0.003882</td>
      <td>0.553717</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.162278e-01</td>
      <td>0.003235</td>
      <td>-0.003235</td>
      <td>0.003235</td>
      <td>0.550482</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003162</td>
      <td>-0.003162</td>
      <td>0.003162</td>
      <td>0.547320</td>
    </tr>
    <tr>
      <th>122</th>
      <td>are</td>
      <td>3.162278e-01</td>
      <td>0.003121</td>
      <td>-0.003121</td>
      <td>0.003121</td>
      <td>0.544199</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003100</td>
      <td>0.003100</td>
      <td>0.003100</td>
      <td>0.547298</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002967</td>
      <td>0.002967</td>
      <td>0.002967</td>
      <td>0.550266</td>
    </tr>
    <tr>
      <th>2080</th>
      <td>topic 154</td>
      <td>1.947388e-01</td>
      <td>-0.002950</td>
      <td>0.002950</td>
      <td>0.002950</td>
      <td>0.553216</td>
    </tr>
    <tr>
      <th>1823</th>
      <td>what</td>
      <td>3.162278e-01</td>
      <td>0.002944</td>
      <td>-0.002944</td>
      <td>0.002944</td>
      <td>0.550272</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.575755e-21</td>
      <td>-0.002877</td>
      <td>0.002877</td>
      <td>0.002877</td>
      <td>0.553149</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002876</td>
      <td>0.002876</td>
      <td>0.002876</td>
      <td>0.556025</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 99
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The lead man is charisma-free.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.47 0.53]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.205141</td>
      <td>0.205141</td>
      <td>0.205141</td>
      <td>0.704651</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.082683</td>
      <td>-0.082683</td>
      <td>0.082683</td>
      <td>0.621968</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031167</td>
      <td>-0.031167</td>
      <td>0.031167</td>
      <td>0.590801</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.026700</td>
      <td>-0.026700</td>
      <td>0.026700</td>
      <td>0.564102</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025051</td>
      <td>0.025051</td>
      <td>0.025051</td>
      <td>0.589153</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021220</td>
      <td>0.021220</td>
      <td>0.021220</td>
      <td>0.610373</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.017276</td>
      <td>-0.017276</td>
      <td>0.017276</td>
      <td>0.593097</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008384</td>
      <td>-0.008384</td>
      <td>0.008384</td>
      <td>0.584713</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.007701</td>
      <td>-0.007701</td>
      <td>0.007701</td>
      <td>0.577012</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007492</td>
      <td>-0.007492</td>
      <td>0.007492</td>
      <td>0.569520</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007273</td>
      <td>-0.007273</td>
      <td>0.007273</td>
      <td>0.562247</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.006167</td>
      <td>-0.006167</td>
      <td>0.006167</td>
      <td>0.556080</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005658</td>
      <td>-0.005658</td>
      <td>0.005658</td>
      <td>0.550422</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.005602</td>
      <td>0.005602</td>
      <td>0.005602</td>
      <td>0.556024</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.200000e+01</td>
      <td>-0.005378</td>
      <td>0.005378</td>
      <td>0.005378</td>
      <td>0.561402</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005335</td>
      <td>0.005335</td>
      <td>0.005335</td>
      <td>0.566737</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.100179e-101</td>
      <td>0.005116</td>
      <td>-0.005116</td>
      <td>0.005116</td>
      <td>0.561621</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>5.773503e-01</td>
      <td>0.004174</td>
      <td>-0.004174</td>
      <td>0.004174</td>
      <td>0.557447</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004134</td>
      <td>0.004134</td>
      <td>0.004134</td>
      <td>0.561580</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004019</td>
      <td>0.004019</td>
      <td>0.004019</td>
      <td>0.565599</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003962</td>
      <td>-0.003962</td>
      <td>0.003962</td>
      <td>0.561637</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003458</td>
      <td>0.003458</td>
      <td>0.003458</td>
      <td>0.565096</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003384</td>
      <td>-0.003384</td>
      <td>0.003384</td>
      <td>0.561711</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.002959</td>
      <td>-0.002959</td>
      <td>0.002959</td>
      <td>0.558752</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002902</td>
      <td>-0.002902</td>
      <td>0.002902</td>
      <td>0.555850</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002820</td>
      <td>0.002820</td>
      <td>0.002820</td>
      <td>0.558669</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002757</td>
      <td>0.002757</td>
      <td>0.002757</td>
      <td>0.561426</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002737</td>
      <td>0.002737</td>
      <td>0.002737</td>
      <td>0.564163</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002667</td>
      <td>0.002667</td>
      <td>0.002667</td>
      <td>0.566830</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.002616</td>
      <td>-0.002616</td>
      <td>0.002616</td>
      <td>0.564214</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 107
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The feel of the dining room was more college cooking course than high class dining and the service was slow at best.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3 0.7]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.168221</td>
      <td>0.168221</td>
      <td>0.168221</td>
      <td>0.667730</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.670000e-01</td>
      <td>0.075908</td>
      <td>-0.075908</td>
      <td>0.075908</td>
      <td>0.591822</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.369000e-01</td>
      <td>-0.048679</td>
      <td>0.048679</td>
      <td>0.048679</td>
      <td>0.640501</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023429</td>
      <td>0.023429</td>
      <td>0.023429</td>
      <td>0.663930</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020867</td>
      <td>0.020867</td>
      <td>0.020867</td>
      <td>0.684797</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.400000e-01</td>
      <td>-0.009612</td>
      <td>0.009612</td>
      <td>0.009612</td>
      <td>0.694410</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008480</td>
      <td>-0.008480</td>
      <td>0.008480</td>
      <td>0.685929</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.230692e-72</td>
      <td>0.007812</td>
      <td>-0.007812</td>
      <td>0.007812</td>
      <td>0.678117</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.200000e+01</td>
      <td>0.007322</td>
      <td>-0.007322</td>
      <td>0.007322</td>
      <td>0.670795</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006508</td>
      <td>-0.006508</td>
      <td>0.006508</td>
      <td>0.664287</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005526</td>
      <td>-0.005526</td>
      <td>0.005526</td>
      <td>0.658761</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.660216e-53</td>
      <td>0.004988</td>
      <td>-0.004988</td>
      <td>0.004988</td>
      <td>0.653773</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.004142</td>
      <td>-0.004142</td>
      <td>0.004142</td>
      <td>0.649631</td>
    </tr>
    <tr>
      <th>2059</th>
      <td>topic 133</td>
      <td>2.795561e-04</td>
      <td>-0.004068</td>
      <td>0.004068</td>
      <td>0.004068</td>
      <td>0.653699</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>5.725906e-02</td>
      <td>0.004040</td>
      <td>-0.004040</td>
      <td>0.004040</td>
      <td>0.649659</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003706</td>
      <td>-0.003706</td>
      <td>0.003706</td>
      <td>0.645952</td>
    </tr>
    <tr>
      <th>2005</th>
      <td>topic 79</td>
      <td>2.575842e-02</td>
      <td>-0.003433</td>
      <td>0.003433</td>
      <td>0.003433</td>
      <td>0.649385</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003406</td>
      <td>0.003406</td>
      <td>0.003406</td>
      <td>0.652791</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003299</td>
      <td>-0.003299</td>
      <td>0.003299</td>
      <td>0.649492</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003034</td>
      <td>-0.003034</td>
      <td>0.003034</td>
      <td>0.646458</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002784</td>
      <td>-0.002784</td>
      <td>0.002784</td>
      <td>0.643674</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002769</td>
      <td>-0.002769</td>
      <td>0.002769</td>
      <td>0.640905</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002739</td>
      <td>0.002739</td>
      <td>0.002739</td>
      <td>0.643644</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>-0.002648</td>
      <td>0.002648</td>
      <td>0.002648</td>
      <td>0.646292</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.812695e-97</td>
      <td>-0.002602</td>
      <td>0.002602</td>
      <td>0.002602</td>
      <td>0.648894</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002544</td>
      <td>0.002544</td>
      <td>0.002544</td>
      <td>0.651438</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002516</td>
      <td>0.002516</td>
      <td>0.002516</td>
      <td>0.653954</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002488</td>
      <td>-0.002488</td>
      <td>0.002488</td>
      <td>0.651466</td>
    </tr>
    <tr>
      <th>2082</th>
      <td>topic 156</td>
      <td>1.558908e-01</td>
      <td>0.002414</td>
      <td>-0.002414</td>
      <td>0.002414</td>
      <td>0.649051</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002396</td>
      <td>0.002396</td>
      <td>0.002396</td>
      <td>0.651447</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 111
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I really wanted the Plantronics 510 to be the right one, but it has too many issues for me.The good&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.265 0.735]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.170826</td>
      <td>0.170826</td>
      <td>0.170826</td>
      <td>0.670336</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.760000e-01</td>
      <td>0.071562</td>
      <td>-0.071562</td>
      <td>0.071562</td>
      <td>0.598774</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.927000e-01</td>
      <td>-0.046682</td>
      <td>0.046682</td>
      <td>0.046682</td>
      <td>0.645456</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023750</td>
      <td>0.023750</td>
      <td>0.023750</td>
      <td>0.669206</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020884</td>
      <td>0.020884</td>
      <td>0.020884</td>
      <td>0.690090</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.214286e-01</td>
      <td>-0.019586</td>
      <td>0.019586</td>
      <td>0.019586</td>
      <td>0.709676</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.000000e+01</td>
      <td>0.011122</td>
      <td>-0.011122</td>
      <td>0.011122</td>
      <td>0.698554</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009321</td>
      <td>-0.009321</td>
      <td>0.009321</td>
      <td>0.689233</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008326</td>
      <td>-0.008326</td>
      <td>0.008326</td>
      <td>0.680907</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.647126e-156</td>
      <td>0.007576</td>
      <td>-0.007576</td>
      <td>0.007576</td>
      <td>0.673331</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006116</td>
      <td>-0.006116</td>
      <td>0.006116</td>
      <td>0.667215</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.546235e-02</td>
      <td>0.005510</td>
      <td>-0.005510</td>
      <td>0.005510</td>
      <td>0.661706</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.900000e+01</td>
      <td>0.005302</td>
      <td>-0.005302</td>
      <td>0.005302</td>
      <td>0.656404</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004178</td>
      <td>0.004178</td>
      <td>0.004178</td>
      <td>0.660582</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>2.236068e-01</td>
      <td>-0.003878</td>
      <td>0.003878</td>
      <td>0.003878</td>
      <td>0.664460</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003873</td>
      <td>-0.003873</td>
      <td>0.003873</td>
      <td>0.660588</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003455</td>
      <td>0.003455</td>
      <td>0.003455</td>
      <td>0.664042</td>
    </tr>
    <tr>
      <th>1520</th>
      <td>the place</td>
      <td>0.000000e+00</td>
      <td>-0.003325</td>
      <td>0.003325</td>
      <td>0.003325</td>
      <td>0.667367</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>1.164745e-154</td>
      <td>-0.003256</td>
      <td>0.003256</td>
      <td>0.003256</td>
      <td>0.670623</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003171</td>
      <td>0.003171</td>
      <td>0.003171</td>
      <td>0.673794</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003130</td>
      <td>-0.003130</td>
      <td>0.003130</td>
      <td>0.670664</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002773</td>
      <td>-0.002773</td>
      <td>0.002773</td>
      <td>0.667890</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002691</td>
      <td>-0.002691</td>
      <td>0.002691</td>
      <td>0.665199</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.444928e-132</td>
      <td>-0.002680</td>
      <td>0.002680</td>
      <td>0.002680</td>
      <td>0.667879</td>
    </tr>
    <tr>
      <th>1983</th>
      <td>topic 57</td>
      <td>4.149003e-03</td>
      <td>-0.002662</td>
      <td>0.002662</td>
      <td>0.002662</td>
      <td>0.670541</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.002656</td>
      <td>-0.002656</td>
      <td>0.002656</td>
      <td>0.667885</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002600</td>
      <td>0.002600</td>
      <td>0.002600</td>
      <td>0.670486</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002446</td>
      <td>0.002446</td>
      <td>0.002446</td>
      <td>0.672932</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.002411</td>
      <td>0.002411</td>
      <td>0.002411</td>
      <td>0.675343</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>2.236068e-01</td>
      <td>-0.002363</td>
      <td>0.002363</td>
      <td>0.002363</td>
      <td>0.677705</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 116
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Looks good in the picture, but this case was a huge disappointment!!&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.5075 0.4925]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.162640</td>
      <td>0.162640</td>
      <td>0.162640</td>
      <td>0.662150</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-2.810000e-01</td>
      <td>0.089413</td>
      <td>-0.089413</td>
      <td>0.089413</td>
      <td>0.572737</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.060000e-01</td>
      <td>0.068239</td>
      <td>-0.068239</td>
      <td>0.068239</td>
      <td>0.504498</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.416667e-02</td>
      <td>0.030705</td>
      <td>-0.030705</td>
      <td>0.030705</td>
      <td>0.473793</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022415</td>
      <td>0.022415</td>
      <td>0.022415</td>
      <td>0.496208</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020086</td>
      <td>0.020086</td>
      <td>0.020086</td>
      <td>0.516295</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.015130</td>
      <td>-0.015130</td>
      <td>0.015130</td>
      <td>0.501165</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>2.000000e+00</td>
      <td>-0.013249</td>
      <td>0.013249</td>
      <td>0.013249</td>
      <td>0.514414</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008703</td>
      <td>-0.008703</td>
      <td>0.008703</td>
      <td>0.505711</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008599</td>
      <td>-0.008599</td>
      <td>0.008599</td>
      <td>0.497112</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.869786e-28</td>
      <td>0.007422</td>
      <td>-0.007422</td>
      <td>0.007422</td>
      <td>0.489690</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.006269</td>
      <td>-0.006269</td>
      <td>0.006269</td>
      <td>0.483421</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.006029</td>
      <td>0.006029</td>
      <td>0.006029</td>
      <td>0.489450</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.006014</td>
      <td>-0.006014</td>
      <td>0.006014</td>
      <td>0.483436</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>6.736401e-02</td>
      <td>0.004766</td>
      <td>-0.004766</td>
      <td>0.004766</td>
      <td>0.478670</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004609</td>
      <td>0.004609</td>
      <td>0.004609</td>
      <td>0.483279</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.773501e-01</td>
      <td>-0.004372</td>
      <td>0.004372</td>
      <td>0.004372</td>
      <td>0.487651</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004049</td>
      <td>-0.004049</td>
      <td>0.004049</td>
      <td>0.483602</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003914</td>
      <td>0.003914</td>
      <td>0.003914</td>
      <td>0.487516</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003544</td>
      <td>0.003544</td>
      <td>0.003544</td>
      <td>0.491060</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>0.000000e+00</td>
      <td>-0.003536</td>
      <td>0.003536</td>
      <td>0.003536</td>
      <td>0.494596</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.003230</td>
      <td>0.003230</td>
      <td>0.003230</td>
      <td>0.497825</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.003191</td>
      <td>-0.003191</td>
      <td>0.003191</td>
      <td>0.494634</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.565746e-22</td>
      <td>-0.003117</td>
      <td>0.003117</td>
      <td>0.003117</td>
      <td>0.497752</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>2.773501e-01</td>
      <td>-0.003092</td>
      <td>0.003092</td>
      <td>0.003092</td>
      <td>0.500844</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>2.773501e-01</td>
      <td>-0.003082</td>
      <td>0.003082</td>
      <td>0.003082</td>
      <td>0.503926</td>
    </tr>
    <tr>
      <th>1158</th>
      <td>phone</td>
      <td>0.000000e+00</td>
      <td>-0.003041</td>
      <td>0.003041</td>
      <td>0.003041</td>
      <td>0.506967</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.800000e+01</td>
      <td>0.003012</td>
      <td>-0.003012</td>
      <td>0.003012</td>
      <td>0.503955</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002950</td>
      <td>0.002950</td>
      <td>0.002950</td>
      <td>0.506905</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002797</td>
      <td>0.002797</td>
      <td>0.002797</td>
      <td>0.509702</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 121
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It plays louder than any other speaker of this size; the price is so low that most would think the quality is lacking, however, it&#39;s not.&#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.58 0.42]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.149460</td>
      <td>0.149460</td>
      <td>0.149460</td>
      <td>0.648970</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>7.000000e-02</td>
      <td>0.062693</td>
      <td>-0.062693</td>
      <td>0.062693</td>
      <td>0.586277</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-1.880000e-01</td>
      <td>0.059681</td>
      <td>-0.059681</td>
      <td>0.059681</td>
      <td>0.526596</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.036642</td>
      <td>-0.036642</td>
      <td>0.036642</td>
      <td>0.489954</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.250000e-01</td>
      <td>0.018949</td>
      <td>-0.018949</td>
      <td>0.018949</td>
      <td>0.471005</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.600000e+01</td>
      <td>0.017064</td>
      <td>-0.017064</td>
      <td>0.017064</td>
      <td>0.453941</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>-0.010126</td>
      <td>0.010126</td>
      <td>0.010126</td>
      <td>0.464067</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.767767e-01</td>
      <td>-0.009153</td>
      <td>0.009153</td>
      <td>0.009153</td>
      <td>0.473220</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007702</td>
      <td>-0.007702</td>
      <td>0.007702</td>
      <td>0.465518</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.226849e-55</td>
      <td>0.007224</td>
      <td>-0.007224</td>
      <td>0.007224</td>
      <td>0.458294</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006968</td>
      <td>-0.006968</td>
      <td>0.006968</td>
      <td>0.451326</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.004908</td>
      <td>-0.004908</td>
      <td>0.004908</td>
      <td>0.446418</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004338</td>
      <td>-0.004338</td>
      <td>0.004338</td>
      <td>0.442081</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004277</td>
      <td>-0.004277</td>
      <td>0.004277</td>
      <td>0.437804</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.155729e-72</td>
      <td>0.003861</td>
      <td>-0.003861</td>
      <td>0.003861</td>
      <td>0.433944</td>
    </tr>
    <tr>
      <th>1212</th>
      <td>price</td>
      <td>1.767767e-01</td>
      <td>-0.003759</td>
      <td>0.003759</td>
      <td>0.003759</td>
      <td>0.437703</td>
    </tr>
    <tr>
      <th>2042</th>
      <td>topic 116</td>
      <td>1.300861e-04</td>
      <td>0.003675</td>
      <td>-0.003675</td>
      <td>0.003675</td>
      <td>0.434028</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>1.767767e-01</td>
      <td>-0.003526</td>
      <td>0.003526</td>
      <td>0.003526</td>
      <td>0.437554</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003495</td>
      <td>0.003495</td>
      <td>0.003495</td>
      <td>0.441049</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003251</td>
      <td>0.003251</td>
      <td>0.003251</td>
      <td>0.444300</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>3.535534e-01</td>
      <td>-0.003247</td>
      <td>0.003247</td>
      <td>0.003247</td>
      <td>0.447547</td>
    </tr>
    <tr>
      <th>1887</th>
      <td>would</td>
      <td>1.767767e-01</td>
      <td>0.003185</td>
      <td>-0.003185</td>
      <td>0.003185</td>
      <td>0.444363</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>1.767767e-01</td>
      <td>0.003080</td>
      <td>-0.003080</td>
      <td>0.003080</td>
      <td>0.441282</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003031</td>
      <td>-0.003031</td>
      <td>0.003031</td>
      <td>0.438252</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002920</td>
      <td>0.002920</td>
      <td>0.002920</td>
      <td>0.441172</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002911</td>
      <td>0.002911</td>
      <td>0.002911</td>
      <td>0.444082</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002861</td>
      <td>0.002861</td>
      <td>0.002861</td>
      <td>0.446943</td>
    </tr>
    <tr>
      <th>1079</th>
      <td>of this</td>
      <td>1.767767e-01</td>
      <td>0.002790</td>
      <td>-0.002790</td>
      <td>0.002790</td>
      <td>0.444153</td>
    </tr>
    <tr>
      <th>1972</th>
      <td>topic 46</td>
      <td>1.355423e-01</td>
      <td>-0.002752</td>
      <td>0.002752</td>
      <td>0.002752</td>
      <td>0.446904</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002725</td>
      <td>0.002725</td>
      <td>0.002725</td>
      <td>0.449630</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 131
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;My headset works just peachy-keen.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.555 0.445]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.132183</td>
      <td>0.132183</td>
      <td>0.132183</td>
      <td>0.631693</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.088890</td>
      <td>-0.088890</td>
      <td>0.088890</td>
      <td>0.542803</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.034880</td>
      <td>-0.034880</td>
      <td>0.034880</td>
      <td>0.507923</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.027380</td>
      <td>-0.027380</td>
      <td>0.027380</td>
      <td>0.480543</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026566</td>
      <td>0.026566</td>
      <td>0.026566</td>
      <td>0.507109</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022677</td>
      <td>0.022677</td>
      <td>0.022677</td>
      <td>0.529787</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.017161</td>
      <td>-0.017161</td>
      <td>0.017161</td>
      <td>0.512626</td>
    </tr>
    <tr>
      <th>1940</th>
      <td>topic 14</td>
      <td>2.007344e-01</td>
      <td>-0.011388</td>
      <td>0.011388</td>
      <td>0.011388</td>
      <td>0.524014</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009875</td>
      <td>-0.009875</td>
      <td>0.009875</td>
      <td>0.514139</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009229</td>
      <td>-0.009229</td>
      <td>0.009229</td>
      <td>0.504910</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.359711e-33</td>
      <td>0.007590</td>
      <td>-0.007590</td>
      <td>0.007590</td>
      <td>0.497320</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.400000e+01</td>
      <td>-0.007078</td>
      <td>0.007078</td>
      <td>0.007078</td>
      <td>0.504398</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.006785</td>
      <td>-0.006785</td>
      <td>0.006785</td>
      <td>0.497613</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.006589</td>
      <td>-0.006589</td>
      <td>0.006589</td>
      <td>0.491024</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.006432</td>
      <td>0.006432</td>
      <td>0.006432</td>
      <td>0.497456</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006237</td>
      <td>-0.006237</td>
      <td>0.006237</td>
      <td>0.491219</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005746</td>
      <td>-0.005746</td>
      <td>0.005746</td>
      <td>0.485474</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>6.793225e-219</td>
      <td>0.005300</td>
      <td>-0.005300</td>
      <td>0.005300</td>
      <td>0.480173</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004971</td>
      <td>0.004971</td>
      <td>0.004971</td>
      <td>0.485144</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004638</td>
      <td>0.004638</td>
      <td>0.004638</td>
      <td>0.489782</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004381</td>
      <td>0.004381</td>
      <td>0.004381</td>
      <td>0.494164</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004045</td>
      <td>-0.004045</td>
      <td>0.004045</td>
      <td>0.490119</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003404</td>
      <td>0.003404</td>
      <td>0.003404</td>
      <td>0.493522</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003238</td>
      <td>0.003238</td>
      <td>0.003238</td>
      <td>0.496761</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003229</td>
      <td>0.003229</td>
      <td>0.003229</td>
      <td>0.499990</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.799199e-01</td>
      <td>0.003134</td>
      <td>-0.003134</td>
      <td>0.003134</td>
      <td>0.496856</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003083</td>
      <td>0.003083</td>
      <td>0.003083</td>
      <td>0.499939</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003054</td>
      <td>0.003054</td>
      <td>0.003054</td>
      <td>0.502993</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002985</td>
      <td>0.002985</td>
      <td>0.002985</td>
      <td>0.505977</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>0.000000e+00</td>
      <td>-0.002956</td>
      <td>0.002956</td>
      <td>0.002956</td>
      <td>0.508933</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 143
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Unfortunately the ability to actually know you are receiving a call is a rather important feature and this phone is pitiful in that respect.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.4525 0.5475]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>6.000000e+00</td>
      <td>-0.184721</td>
      <td>0.184721</td>
      <td>0.184721</td>
      <td>0.684231</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.420000e-01</td>
      <td>0.068562</td>
      <td>-0.068562</td>
      <td>0.068562</td>
      <td>0.615670</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-3.333333e-02</td>
      <td>0.038921</td>
      <td>-0.038921</td>
      <td>0.038921</td>
      <td>0.576749</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024670</td>
      <td>0.024670</td>
      <td>0.024670</td>
      <td>0.601419</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.400000e+01</td>
      <td>0.022196</td>
      <td>-0.022196</td>
      <td>0.022196</td>
      <td>0.579223</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018974</td>
      <td>0.018974</td>
      <td>0.018974</td>
      <td>0.598197</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008293</td>
      <td>-0.008293</td>
      <td>0.008293</td>
      <td>0.589904</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.340809e-42</td>
      <td>0.007181</td>
      <td>-0.007181</td>
      <td>0.007181</td>
      <td>0.582723</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005841</td>
      <td>-0.005841</td>
      <td>0.005841</td>
      <td>0.576882</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005124</td>
      <td>0.005124</td>
      <td>0.005124</td>
      <td>0.582006</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>2.085144e-01</td>
      <td>0.005094</td>
      <td>-0.005094</td>
      <td>0.005094</td>
      <td>0.576911</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>1.531000e-01</td>
      <td>0.005050</td>
      <td>-0.005050</td>
      <td>0.005050</td>
      <td>0.571861</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.276383e-17</td>
      <td>0.004957</td>
      <td>-0.004957</td>
      <td>0.004957</td>
      <td>0.566904</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004308</td>
      <td>0.004308</td>
      <td>0.004308</td>
      <td>0.571211</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.400000e+02</td>
      <td>0.004101</td>
      <td>-0.004101</td>
      <td>0.004101</td>
      <td>0.567110</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004068</td>
      <td>-0.004068</td>
      <td>0.004068</td>
      <td>0.563042</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003904</td>
      <td>0.003904</td>
      <td>0.003904</td>
      <td>0.566946</td>
    </tr>
    <tr>
      <th>1163</th>
      <td>phone is</td>
      <td>2.085144e-01</td>
      <td>-0.003565</td>
      <td>0.003565</td>
      <td>0.003565</td>
      <td>0.570512</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003547</td>
      <td>-0.003547</td>
      <td>0.003547</td>
      <td>0.566965</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.085144e-01</td>
      <td>-0.003395</td>
      <td>0.003395</td>
      <td>0.003395</td>
      <td>0.570359</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003300</td>
      <td>-0.003300</td>
      <td>0.003300</td>
      <td>0.567059</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>6.871416e-61</td>
      <td>0.002788</td>
      <td>-0.002788</td>
      <td>0.002788</td>
      <td>0.564271</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002779</td>
      <td>0.002779</td>
      <td>0.002779</td>
      <td>0.567050</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002773</td>
      <td>0.002773</td>
      <td>0.002773</td>
      <td>0.569823</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002705</td>
      <td>-0.002705</td>
      <td>0.002705</td>
      <td>0.567118</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002648</td>
      <td>0.002648</td>
      <td>0.002648</td>
      <td>0.569766</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>6.980092e-152</td>
      <td>-0.002630</td>
      <td>0.002630</td>
      <td>0.002630</td>
      <td>0.572396</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002564</td>
      <td>-0.002564</td>
      <td>0.002564</td>
      <td>0.569831</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002507</td>
      <td>0.002507</td>
      <td>0.002507</td>
      <td>0.572339</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.574839</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 148
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The cast of veteran actors are more than just a nostalgia trip.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7375 0.2625]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.089191</td>
      <td>-0.089191</td>
      <td>0.089191</td>
      <td>0.410319</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025185</td>
      <td>0.025185</td>
      <td>0.025185</td>
      <td>0.435503</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019775</td>
      <td>0.019775</td>
      <td>0.019775</td>
      <td>0.455279</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.017030</td>
      <td>-0.017030</td>
      <td>0.017030</td>
      <td>0.438249</td>
    </tr>
    <tr>
      <th>1940</th>
      <td>topic 14</td>
      <td>1.466841e-01</td>
      <td>-0.015475</td>
      <td>0.015475</td>
      <td>0.015475</td>
      <td>0.453724</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.500000e+01</td>
      <td>0.015205</td>
      <td>-0.015205</td>
      <td>0.015205</td>
      <td>0.438519</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009834</td>
      <td>-0.009834</td>
      <td>0.009834</td>
      <td>0.428684</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008826</td>
      <td>-0.008826</td>
      <td>0.008826</td>
      <td>0.419859</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007865</td>
      <td>-0.007865</td>
      <td>0.007865</td>
      <td>0.411994</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.007658</td>
      <td>0.007658</td>
      <td>0.007658</td>
      <td>0.419652</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007656</td>
      <td>-0.007656</td>
      <td>0.007656</td>
      <td>0.411996</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.007524</td>
      <td>-0.007524</td>
      <td>0.007524</td>
      <td>0.404472</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006659</td>
      <td>-0.006659</td>
      <td>0.006659</td>
      <td>0.397813</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.005529</td>
      <td>-0.005529</td>
      <td>0.005529</td>
      <td>0.392285</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005339</td>
      <td>0.005339</td>
      <td>0.005339</td>
      <td>0.397624</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.325831e-13</td>
      <td>0.005073</td>
      <td>-0.005073</td>
      <td>0.005073</td>
      <td>0.392550</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004394</td>
      <td>0.004394</td>
      <td>0.004394</td>
      <td>0.396944</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004248</td>
      <td>0.004248</td>
      <td>0.004248</td>
      <td>0.401193</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004223</td>
      <td>-0.004223</td>
      <td>0.004223</td>
      <td>0.396970</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.500000e-01</td>
      <td>0.004007</td>
      <td>-0.004007</td>
      <td>0.004007</td>
      <td>0.392963</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003953</td>
      <td>0.003953</td>
      <td>0.003953</td>
      <td>0.396915</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003916</td>
      <td>0.003916</td>
      <td>0.003916</td>
      <td>0.400831</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.003566</td>
      <td>0.003566</td>
      <td>0.003566</td>
      <td>0.404397</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003491</td>
      <td>0.003491</td>
      <td>0.003491</td>
      <td>0.407888</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003477</td>
      <td>-0.003477</td>
      <td>0.003477</td>
      <td>0.404410</td>
    </tr>
    <tr>
      <th>1678</th>
      <td>trip</td>
      <td>3.535534e-01</td>
      <td>-0.003326</td>
      <td>0.003326</td>
      <td>0.003326</td>
      <td>0.407736</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>3.956289e-94</td>
      <td>0.003325</td>
      <td>-0.003325</td>
      <td>0.003325</td>
      <td>0.404411</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.003325</td>
      <td>-0.003325</td>
      <td>0.003325</td>
      <td>0.401086</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003285</td>
      <td>-0.003285</td>
      <td>0.003285</td>
      <td>0.397801</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.252904e-18</td>
      <td>-0.003279</td>
      <td>0.003279</td>
      <td>0.003279</td>
      <td>0.401080</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 155
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;When I received my Pita it was huge it did have a lot of meat in it so thumbs up there.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.5425 0.4575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.107257</td>
      <td>0.107257</td>
      <td>0.107257</td>
      <td>0.606766</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-2.732000e-01</td>
      <td>0.095445</td>
      <td>-0.095445</td>
      <td>0.095445</td>
      <td>0.511321</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.010000e-01</td>
      <td>0.077204</td>
      <td>-0.077204</td>
      <td>0.077204</td>
      <td>0.434117</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.000000e-01</td>
      <td>-0.027566</td>
      <td>0.027566</td>
      <td>0.027566</td>
      <td>0.461683</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024624</td>
      <td>0.024624</td>
      <td>0.024624</td>
      <td>0.486307</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021851</td>
      <td>0.021851</td>
      <td>0.021851</td>
      <td>0.508158</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009759</td>
      <td>-0.009759</td>
      <td>0.009759</td>
      <td>0.498399</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008701</td>
      <td>-0.008701</td>
      <td>0.008701</td>
      <td>0.489697</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.123355e-32</td>
      <td>0.007692</td>
      <td>-0.007692</td>
      <td>0.007692</td>
      <td>0.482005</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000e+00</td>
      <td>-0.006423</td>
      <td>0.006423</td>
      <td>0.006423</td>
      <td>0.488428</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006284</td>
      <td>-0.006284</td>
      <td>0.006284</td>
      <td>0.482144</td>
    </tr>
    <tr>
      <th>984</th>
      <td>my</td>
      <td>1.796053e-01</td>
      <td>0.004993</td>
      <td>-0.004993</td>
      <td>0.004993</td>
      <td>0.477151</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004986</td>
      <td>-0.004986</td>
      <td>0.004986</td>
      <td>0.472165</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>2.880324e-143</td>
      <td>0.004985</td>
      <td>-0.004985</td>
      <td>0.004985</td>
      <td>0.467180</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>0.000000e+00</td>
      <td>-0.004894</td>
      <td>0.004894</td>
      <td>0.004894</td>
      <td>0.472074</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.091166e-100</td>
      <td>0.004792</td>
      <td>-0.004792</td>
      <td>0.004792</td>
      <td>0.467282</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.100000e+01</td>
      <td>0.004580</td>
      <td>-0.004580</td>
      <td>0.004580</td>
      <td>0.462702</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.700000e+01</td>
      <td>0.004443</td>
      <td>-0.004443</td>
      <td>0.004443</td>
      <td>0.458259</td>
    </tr>
    <tr>
      <th>2098</th>
      <td>topic 172</td>
      <td>2.890701e-01</td>
      <td>-0.004337</td>
      <td>0.004337</td>
      <td>0.004337</td>
      <td>0.462596</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004172</td>
      <td>-0.004172</td>
      <td>0.004172</td>
      <td>0.458424</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003660</td>
      <td>0.003660</td>
      <td>0.003660</td>
      <td>0.462084</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003311</td>
      <td>0.003311</td>
      <td>0.003311</td>
      <td>0.465395</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003203</td>
      <td>0.003203</td>
      <td>0.003203</td>
      <td>0.468598</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003190</td>
      <td>0.003190</td>
      <td>0.003190</td>
      <td>0.471788</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003135</td>
      <td>-0.003135</td>
      <td>0.003135</td>
      <td>0.468653</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002981</td>
      <td>-0.002981</td>
      <td>0.002981</td>
      <td>0.465673</td>
    </tr>
    <tr>
      <th>1767</th>
      <td>wa the</td>
      <td>0.000000e+00</td>
      <td>-0.002834</td>
      <td>0.002834</td>
      <td>0.002834</td>
      <td>0.468506</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002805</td>
      <td>-0.002805</td>
      <td>0.002805</td>
      <td>0.465702</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002691</td>
      <td>0.002691</td>
      <td>0.002691</td>
      <td>0.468392</td>
    </tr>
    <tr>
      <th>798</th>
      <td>it did</td>
      <td>1.796053e-01</td>
      <td>0.002679</td>
      <td>-0.002679</td>
      <td>0.002679</td>
      <td>0.465714</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 171
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The movie lacks visual interest, drama, expression of feeling, and celebration of the very patriotism that underlines the narrative.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3725 0.6275]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>5.000000e+00</td>
      <td>-0.170982</td>
      <td>0.170982</td>
      <td>0.170982</td>
      <td>0.670492</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.090000e-01</td>
      <td>0.074526</td>
      <td>-0.074526</td>
      <td>0.074526</td>
      <td>0.595966</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.423000e-01</td>
      <td>-0.048938</td>
      <td>0.048938</td>
      <td>0.048938</td>
      <td>0.644904</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.000000e-01</td>
      <td>0.032988</td>
      <td>-0.032988</td>
      <td>0.032988</td>
      <td>0.611916</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.900000e+01</td>
      <td>0.025399</td>
      <td>-0.025399</td>
      <td>0.025399</td>
      <td>0.586516</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024125</td>
      <td>0.024125</td>
      <td>0.024125</td>
      <td>0.610642</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020597</td>
      <td>0.020597</td>
      <td>0.020597</td>
      <td>0.631238</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008466</td>
      <td>-0.008466</td>
      <td>0.008466</td>
      <td>0.622773</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.017259e-239</td>
      <td>0.007415</td>
      <td>-0.007415</td>
      <td>0.007415</td>
      <td>0.615357</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005856</td>
      <td>-0.005856</td>
      <td>0.005856</td>
      <td>0.609501</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.340000e+02</td>
      <td>0.005374</td>
      <td>-0.005374</td>
      <td>0.005374</td>
      <td>0.604127</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>2.773501e-01</td>
      <td>-0.005228</td>
      <td>0.005228</td>
      <td>0.005228</td>
      <td>0.609355</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.718473e-194</td>
      <td>0.005127</td>
      <td>-0.005127</td>
      <td>0.005127</td>
      <td>0.604228</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004676</td>
      <td>-0.004676</td>
      <td>0.004676</td>
      <td>0.599552</td>
    </tr>
    <tr>
      <th>1512</th>
      <td>the movie</td>
      <td>2.773501e-01</td>
      <td>0.004189</td>
      <td>-0.004189</td>
      <td>0.004189</td>
      <td>0.595363</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003875</td>
      <td>-0.003875</td>
      <td>0.003875</td>
      <td>0.591488</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003686</td>
      <td>0.003686</td>
      <td>0.003686</td>
      <td>0.595174</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003348</td>
      <td>0.003348</td>
      <td>0.003348</td>
      <td>0.598522</td>
    </tr>
    <tr>
      <th>1935</th>
      <td>topic 9</td>
      <td>7.633036e-02</td>
      <td>-0.003286</td>
      <td>0.003286</td>
      <td>0.003286</td>
      <td>0.601808</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003067</td>
      <td>0.003067</td>
      <td>0.003067</td>
      <td>0.604875</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003049</td>
      <td>-0.003049</td>
      <td>0.003049</td>
      <td>0.601826</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002822</td>
      <td>0.002822</td>
      <td>0.002822</td>
      <td>0.604647</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002816</td>
      <td>0.002816</td>
      <td>0.002816</td>
      <td>0.607464</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002806</td>
      <td>0.002806</td>
      <td>0.002806</td>
      <td>0.610270</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.097430e-88</td>
      <td>-0.002667</td>
      <td>0.002667</td>
      <td>0.002667</td>
      <td>0.612937</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002613</td>
      <td>-0.002613</td>
      <td>0.002613</td>
      <td>0.610324</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002560</td>
      <td>0.002560</td>
      <td>0.002560</td>
      <td>0.612884</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002549</td>
      <td>0.002549</td>
      <td>0.002549</td>
      <td>0.615433</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002548</td>
      <td>0.002548</td>
      <td>0.002548</td>
      <td>0.617981</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>2.126876e-172</td>
      <td>0.002388</td>
      <td>-0.002388</td>
      <td>0.002388</td>
      <td>0.615593</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 179
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;This place should honestly be blown up.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.5 0.5]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.330000e-01</td>
      <td>0.070890</td>
      <td>-0.070890</td>
      <td>0.070890</td>
      <td>0.428620</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>6.000000e-01</td>
      <td>-0.059463</td>
      <td>0.059463</td>
      <td>0.059463</td>
      <td>0.488083</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.588000e-01</td>
      <td>-0.048482</td>
      <td>0.048482</td>
      <td>0.048482</td>
      <td>0.536566</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024976</td>
      <td>0.024976</td>
      <td>0.024976</td>
      <td>0.561541</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020258</td>
      <td>0.020258</td>
      <td>0.020258</td>
      <td>0.581799</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.017510</td>
      <td>-0.017510</td>
      <td>0.017510</td>
      <td>0.564289</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.014702</td>
      <td>-0.014702</td>
      <td>0.014702</td>
      <td>0.549586</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.010362</td>
      <td>-0.010362</td>
      <td>0.010362</td>
      <td>0.539224</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009866</td>
      <td>-0.009866</td>
      <td>0.009866</td>
      <td>0.529358</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008716</td>
      <td>-0.008716</td>
      <td>0.008716</td>
      <td>0.520643</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.872707e-83</td>
      <td>0.008177</td>
      <td>-0.008177</td>
      <td>0.008177</td>
      <td>0.512465</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.007162</td>
      <td>-0.007162</td>
      <td>0.007162</td>
      <td>0.505303</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.900000e+01</td>
      <td>0.006661</td>
      <td>-0.006661</td>
      <td>0.006661</td>
      <td>0.498642</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.006515</td>
      <td>-0.006515</td>
      <td>0.006515</td>
      <td>0.492127</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.005500</td>
      <td>-0.005500</td>
      <td>0.005500</td>
      <td>0.486627</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.951739e-84</td>
      <td>0.005272</td>
      <td>-0.005272</td>
      <td>0.005272</td>
      <td>0.481355</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.004446</td>
      <td>-0.004446</td>
      <td>0.004446</td>
      <td>0.476909</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003738</td>
      <td>0.003738</td>
      <td>0.003738</td>
      <td>0.480647</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003589</td>
      <td>0.003589</td>
      <td>0.003589</td>
      <td>0.484235</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003383</td>
      <td>0.003383</td>
      <td>0.003383</td>
      <td>0.487619</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003215</td>
      <td>0.003215</td>
      <td>0.003215</td>
      <td>0.490833</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003167</td>
      <td>0.003167</td>
      <td>0.003167</td>
      <td>0.494001</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.003070</td>
      <td>-0.003070</td>
      <td>0.003070</td>
      <td>0.490931</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003033</td>
      <td>0.003033</td>
      <td>0.003033</td>
      <td>0.493964</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002982</td>
      <td>-0.002982</td>
      <td>0.002982</td>
      <td>0.490982</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>this place</td>
      <td>4.082483e-01</td>
      <td>0.002953</td>
      <td>-0.002953</td>
      <td>0.002953</td>
      <td>0.488029</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>0.000000e+00</td>
      <td>-0.002859</td>
      <td>0.002859</td>
      <td>0.002859</td>
      <td>0.490888</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002825</td>
      <td>-0.002825</td>
      <td>0.002825</td>
      <td>0.488063</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002798</td>
      <td>0.002798</td>
      <td>0.002798</td>
      <td>0.490861</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002794</td>
      <td>0.002794</td>
      <td>0.002794</td>
      <td>0.493655</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 190
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;This is definitely a must have if your state does not allow cell phone usage while driving.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.68 0.32]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.076411</td>
      <td>0.076411</td>
      <td>0.076411</td>
      <td>0.575921</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.470000e-01</td>
      <td>0.059744</td>
      <td>-0.059744</td>
      <td>0.059744</td>
      <td>0.516177</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.051608</td>
      <td>-0.051608</td>
      <td>0.051608</td>
      <td>0.464568</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.034148</td>
      <td>-0.034148</td>
      <td>0.034148</td>
      <td>0.430421</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.016063</td>
      <td>-0.016063</td>
      <td>0.016063</td>
      <td>0.414358</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>2.579000e-01</td>
      <td>-0.010794</td>
      <td>0.010794</td>
      <td>0.010794</td>
      <td>0.425152</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.100000e+01</td>
      <td>0.009367</td>
      <td>-0.009367</td>
      <td>0.009367</td>
      <td>0.415785</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008004</td>
      <td>-0.008004</td>
      <td>0.008004</td>
      <td>0.407781</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007978</td>
      <td>-0.007978</td>
      <td>0.007978</td>
      <td>0.399802</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.127189e-40</td>
      <td>0.007613</td>
      <td>-0.007613</td>
      <td>0.007613</td>
      <td>0.392189</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006669</td>
      <td>-0.006669</td>
      <td>0.006669</td>
      <td>0.385520</td>
    </tr>
    <tr>
      <th>1978</th>
      <td>topic 52</td>
      <td>1.982527e-01</td>
      <td>-0.005646</td>
      <td>0.005646</td>
      <td>0.005646</td>
      <td>0.391166</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004530</td>
      <td>-0.004530</td>
      <td>0.004530</td>
      <td>0.386637</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>2.425356e-01</td>
      <td>0.004129</td>
      <td>-0.004129</td>
      <td>0.004129</td>
      <td>0.382507</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.003984</td>
      <td>-0.003984</td>
      <td>0.003984</td>
      <td>0.378523</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.402113e-195</td>
      <td>0.003966</td>
      <td>-0.003966</td>
      <td>0.003966</td>
      <td>0.374558</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003860</td>
      <td>0.003860</td>
      <td>0.003860</td>
      <td>0.378418</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003759</td>
      <td>0.003759</td>
      <td>0.003759</td>
      <td>0.382177</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003737</td>
      <td>-0.003737</td>
      <td>0.003737</td>
      <td>0.378440</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003593</td>
      <td>0.003593</td>
      <td>0.003593</td>
      <td>0.382033</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003400</td>
      <td>-0.003400</td>
      <td>0.003400</td>
      <td>0.378633</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003086</td>
      <td>0.003086</td>
      <td>0.003086</td>
      <td>0.381719</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.003034</td>
      <td>-0.003034</td>
      <td>0.003034</td>
      <td>0.378685</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003028</td>
      <td>-0.003028</td>
      <td>0.003028</td>
      <td>0.375657</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.003004</td>
      <td>-0.003004</td>
      <td>0.003004</td>
      <td>0.372653</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.809296e-98</td>
      <td>-0.002800</td>
      <td>0.002800</td>
      <td>0.002800</td>
      <td>0.375453</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002687</td>
      <td>0.002687</td>
      <td>0.002687</td>
      <td>0.378140</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002682</td>
      <td>-0.002682</td>
      <td>0.002682</td>
      <td>0.375458</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002674</td>
      <td>-0.002674</td>
      <td>0.002674</td>
      <td>0.372784</td>
    </tr>
    <tr>
      <th>1929</th>
      <td>topic 3</td>
      <td>9.169239e-02</td>
      <td>0.002663</td>
      <td>-0.002663</td>
      <td>0.002663</td>
      <td>0.370121</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 195
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Will be back again!&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.755 0.245]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.084565</td>
      <td>-0.084565</td>
      <td>0.084565</td>
      <td>0.414945</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>4.000000</td>
      <td>0.028007</td>
      <td>-0.028007</td>
      <td>0.028007</td>
      <td>0.386938</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000</td>
      <td>0.027288</td>
      <td>-0.027288</td>
      <td>0.027288</td>
      <td>0.359650</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025266</td>
      <td>0.025266</td>
      <td>0.025266</td>
      <td>0.384916</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000</td>
      <td>-0.023745</td>
      <td>0.023745</td>
      <td>0.023745</td>
      <td>0.408661</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.018794</td>
      <td>0.018794</td>
      <td>0.018794</td>
      <td>0.427455</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009668</td>
      <td>-0.009668</td>
      <td>0.009668</td>
      <td>0.417787</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.008969</td>
      <td>-0.008969</td>
      <td>0.008969</td>
      <td>0.408818</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>-0.008770</td>
      <td>0.008770</td>
      <td>0.008770</td>
      <td>0.417587</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.007523</td>
      <td>-0.007523</td>
      <td>0.007523</td>
      <td>0.410065</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007478</td>
      <td>-0.007478</td>
      <td>0.007478</td>
      <td>0.402587</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>0.006710</td>
      <td>-0.006710</td>
      <td>0.006710</td>
      <td>0.395876</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006518</td>
      <td>-0.006518</td>
      <td>0.006518</td>
      <td>0.389358</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000</td>
      <td>0.004965</td>
      <td>-0.004965</td>
      <td>0.004965</td>
      <td>0.384393</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004954</td>
      <td>-0.004954</td>
      <td>0.004954</td>
      <td>0.379440</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000</td>
      <td>-0.004817</td>
      <td>0.004817</td>
      <td>0.004817</td>
      <td>0.384256</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000</td>
      <td>0.004650</td>
      <td>-0.004650</td>
      <td>0.004650</td>
      <td>0.379606</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.004549</td>
      <td>0.004549</td>
      <td>0.004549</td>
      <td>0.384155</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.004530</td>
      <td>-0.004530</td>
      <td>0.004530</td>
      <td>0.379625</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>19.000000</td>
      <td>0.004477</td>
      <td>-0.004477</td>
      <td>0.004477</td>
      <td>0.375148</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>0.408248</td>
      <td>-0.004316</td>
      <td>0.004316</td>
      <td>0.004316</td>
      <td>0.379465</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000</td>
      <td>0.004075</td>
      <td>-0.004075</td>
      <td>0.004075</td>
      <td>0.375390</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.003996</td>
      <td>0.003996</td>
      <td>0.003996</td>
      <td>0.379386</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000</td>
      <td>0.003961</td>
      <td>-0.003961</td>
      <td>0.003961</td>
      <td>0.375425</td>
    </tr>
    <tr>
      <th>178</th>
      <td>be back</td>
      <td>0.408248</td>
      <td>-0.003867</td>
      <td>0.003867</td>
      <td>0.003867</td>
      <td>0.379293</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.408248</td>
      <td>0.003815</td>
      <td>-0.003815</td>
      <td>0.003815</td>
      <td>0.375478</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.003675</td>
      <td>0.003675</td>
      <td>0.003675</td>
      <td>0.379152</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003465</td>
      <td>0.003465</td>
      <td>0.003465</td>
      <td>0.382618</td>
    </tr>
    <tr>
      <th>1400</th>
      <td>stay</td>
      <td>0.000000</td>
      <td>-0.003357</td>
      <td>0.003357</td>
      <td>0.003357</td>
      <td>0.385975</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003339</td>
      <td>0.003339</td>
      <td>0.003339</td>
      <td>0.389313</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 206
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;All in all, I&#39;d expected a better consumer experience from Motorola.&#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3825 0.6175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.170262</td>
      <td>0.170262</td>
      <td>0.170262</td>
      <td>0.669772</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.440000e-01</td>
      <td>0.078385</td>
      <td>-0.078385</td>
      <td>0.078385</td>
      <td>0.591387</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.404000e-01</td>
      <td>-0.030682</td>
      <td>0.030682</td>
      <td>0.030682</td>
      <td>0.622069</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025387</td>
      <td>0.025387</td>
      <td>0.025387</td>
      <td>0.647456</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021234</td>
      <td>0.021234</td>
      <td>0.021234</td>
      <td>0.668690</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.018219</td>
      <td>-0.018219</td>
      <td>0.018219</td>
      <td>0.650471</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.000000e-01</td>
      <td>0.016215</td>
      <td>-0.016215</td>
      <td>0.016215</td>
      <td>0.634256</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009881</td>
      <td>-0.009881</td>
      <td>0.009881</td>
      <td>0.624375</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009150</td>
      <td>-0.009150</td>
      <td>0.009150</td>
      <td>0.615225</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.313782e-102</td>
      <td>0.007709</td>
      <td>-0.007709</td>
      <td>0.007709</td>
      <td>0.607516</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.800000e+01</td>
      <td>0.007090</td>
      <td>-0.007090</td>
      <td>0.007090</td>
      <td>0.600425</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006775</td>
      <td>-0.006775</td>
      <td>0.006775</td>
      <td>0.593651</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.006004</td>
      <td>-0.006004</td>
      <td>0.006004</td>
      <td>0.587646</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005404</td>
      <td>-0.005404</td>
      <td>0.005404</td>
      <td>0.582243</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.005356</td>
      <td>-0.005356</td>
      <td>0.005356</td>
      <td>0.576887</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.698273e-196</td>
      <td>0.005261</td>
      <td>-0.005261</td>
      <td>0.005261</td>
      <td>0.571626</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.005232</td>
      <td>0.005232</td>
      <td>0.005232</td>
      <td>0.576858</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004111</td>
      <td>0.004111</td>
      <td>0.004111</td>
      <td>0.580969</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003962</td>
      <td>0.003962</td>
      <td>0.003962</td>
      <td>0.584931</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003567</td>
      <td>0.003567</td>
      <td>0.003567</td>
      <td>0.588498</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003490</td>
      <td>-0.003490</td>
      <td>0.003490</td>
      <td>0.585008</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003161</td>
      <td>0.003161</td>
      <td>0.003161</td>
      <td>0.588168</td>
    </tr>
    <tr>
      <th>206</th>
      <td>better</td>
      <td>2.886751e-01</td>
      <td>0.002949</td>
      <td>-0.002949</td>
      <td>0.002949</td>
      <td>0.585219</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002919</td>
      <td>0.002919</td>
      <td>0.002919</td>
      <td>0.588139</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.886751e-01</td>
      <td>-0.002877</td>
      <td>0.002877</td>
      <td>0.002877</td>
      <td>0.591016</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002876</td>
      <td>0.002876</td>
      <td>0.002876</td>
      <td>0.593892</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.313159e-93</td>
      <td>-0.002856</td>
      <td>0.002856</td>
      <td>0.002856</td>
      <td>0.596748</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002834</td>
      <td>-0.002834</td>
      <td>0.002834</td>
      <td>0.593915</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002798</td>
      <td>-0.002798</td>
      <td>0.002798</td>
      <td>0.591117</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002778</td>
      <td>0.002778</td>
      <td>0.002778</td>
      <td>0.593894</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 219
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The service was poor and thats being nice.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.5625 0.4375]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.102755</td>
      <td>0.102755</td>
      <td>0.102755</td>
      <td>0.602265</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.350000e-01</td>
      <td>0.067904</td>
      <td>-0.067904</td>
      <td>0.067904</td>
      <td>0.534361</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.000000e-01</td>
      <td>0.034497</td>
      <td>-0.034497</td>
      <td>0.034497</td>
      <td>0.499864</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-7.720000e-02</td>
      <td>0.030945</td>
      <td>-0.030945</td>
      <td>0.030945</td>
      <td>0.468919</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>topic 26</td>
      <td>1.762058e-01</td>
      <td>-0.028299</td>
      <td>0.028299</td>
      <td>0.028299</td>
      <td>0.497218</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025000</td>
      <td>0.025000</td>
      <td>0.025000</td>
      <td>0.522218</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.024369</td>
      <td>-0.024369</td>
      <td>0.024369</td>
      <td>0.497849</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021487</td>
      <td>0.021487</td>
      <td>0.021487</td>
      <td>0.519336</td>
    </tr>
    <tr>
      <th>1199</th>
      <td>poor</td>
      <td>3.333333e-01</td>
      <td>0.014684</td>
      <td>-0.014684</td>
      <td>0.014684</td>
      <td>0.504653</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009425</td>
      <td>-0.009425</td>
      <td>0.009425</td>
      <td>0.495227</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.930377e-67</td>
      <td>0.007387</td>
      <td>-0.007387</td>
      <td>0.007387</td>
      <td>0.487840</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006533</td>
      <td>-0.006533</td>
      <td>0.006533</td>
      <td>0.481307</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005611</td>
      <td>0.005611</td>
      <td>0.005611</td>
      <td>0.486919</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>3.333333e-01</td>
      <td>-0.005335</td>
      <td>0.005335</td>
      <td>0.005335</td>
      <td>0.492254</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005094</td>
      <td>-0.005094</td>
      <td>0.005094</td>
      <td>0.487160</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.118298e-131</td>
      <td>0.004861</td>
      <td>-0.004861</td>
      <td>0.004861</td>
      <td>0.482299</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003839</td>
      <td>0.003839</td>
      <td>0.003839</td>
      <td>0.486138</td>
    </tr>
    <tr>
      <th>1993</th>
      <td>topic 67</td>
      <td>2.462639e-01</td>
      <td>0.003767</td>
      <td>-0.003767</td>
      <td>0.003767</td>
      <td>0.482371</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003365</td>
      <td>-0.003365</td>
      <td>0.003365</td>
      <td>0.479007</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003154</td>
      <td>-0.003154</td>
      <td>0.003154</td>
      <td>0.475853</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003141</td>
      <td>-0.003141</td>
      <td>0.003141</td>
      <td>0.472711</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003056</td>
      <td>0.003056</td>
      <td>0.003056</td>
      <td>0.475767</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003026</td>
      <td>-0.003026</td>
      <td>0.003026</td>
      <td>0.472741</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.560083e-92</td>
      <td>-0.002990</td>
      <td>0.002990</td>
      <td>0.002990</td>
      <td>0.475732</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002839</td>
      <td>0.002839</td>
      <td>0.002839</td>
      <td>0.478571</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002816</td>
      <td>-0.002816</td>
      <td>0.002816</td>
      <td>0.475754</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002804</td>
      <td>0.002804</td>
      <td>0.002804</td>
      <td>0.478558</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.002683</td>
      <td>-0.002683</td>
      <td>0.002683</td>
      <td>0.475875</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.200000e+01</td>
      <td>0.002648</td>
      <td>-0.002648</td>
      <td>0.002648</td>
      <td>0.473227</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002575</td>
      <td>0.002575</td>
      <td>0.002575</td>
      <td>0.475802</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 223
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;It definitely was not as good as my S11.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.51 0.49]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.144679</td>
      <td>0.144679</td>
      <td>0.144679</td>
      <td>0.644189</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.230000e-01</td>
      <td>0.061387</td>
      <td>-0.061387</td>
      <td>0.061387</td>
      <td>0.582802</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.040706</td>
      <td>-0.040706</td>
      <td>0.040706</td>
      <td>0.542095</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.570000e-02</td>
      <td>0.020142</td>
      <td>-0.020142</td>
      <td>0.020142</td>
      <td>0.521953</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.500000e-01</td>
      <td>-0.008747</td>
      <td>0.008747</td>
      <td>0.008747</td>
      <td>0.530700</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007928</td>
      <td>-0.007928</td>
      <td>0.007928</td>
      <td>0.522772</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.269427e-150</td>
      <td>0.007424</td>
      <td>-0.007424</td>
      <td>0.007424</td>
      <td>0.515348</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007232</td>
      <td>-0.007232</td>
      <td>0.007232</td>
      <td>0.508117</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>3.535534e-01</td>
      <td>-0.006634</td>
      <td>0.006634</td>
      <td>0.006634</td>
      <td>0.514751</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000e+00</td>
      <td>0.005420</td>
      <td>-0.005420</td>
      <td>0.005420</td>
      <td>0.509331</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000e+00</td>
      <td>-0.005157</td>
      <td>0.005157</td>
      <td>0.005157</td>
      <td>0.514488</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.004580</td>
      <td>0.004580</td>
      <td>0.004580</td>
      <td>0.519067</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004464</td>
      <td>-0.004464</td>
      <td>0.004464</td>
      <td>0.514603</td>
    </tr>
    <tr>
      <th>984</th>
      <td>my</td>
      <td>3.535534e-01</td>
      <td>0.004438</td>
      <td>-0.004438</td>
      <td>0.004438</td>
      <td>0.510165</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.004436</td>
      <td>0.004436</td>
      <td>0.004436</td>
      <td>0.514602</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.000000e+01</td>
      <td>0.003980</td>
      <td>-0.003980</td>
      <td>0.003980</td>
      <td>0.510622</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003598</td>
      <td>-0.003598</td>
      <td>0.003598</td>
      <td>0.507024</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003220</td>
      <td>0.003220</td>
      <td>0.003220</td>
      <td>0.510243</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>-0.003063</td>
      <td>0.003063</td>
      <td>0.003063</td>
      <td>0.513306</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002828</td>
      <td>-0.002828</td>
      <td>0.002828</td>
      <td>0.510478</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>3.535534e-01</td>
      <td>0.002804</td>
      <td>-0.002804</td>
      <td>0.002804</td>
      <td>0.507674</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>5.538885e-174</td>
      <td>0.002778</td>
      <td>-0.002778</td>
      <td>0.002778</td>
      <td>0.504896</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002766</td>
      <td>0.002766</td>
      <td>0.002766</td>
      <td>0.507662</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002695</td>
      <td>-0.002695</td>
      <td>0.002695</td>
      <td>0.504967</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002639</td>
      <td>-0.002639</td>
      <td>0.002639</td>
      <td>0.502328</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002577</td>
      <td>0.002577</td>
      <td>0.002577</td>
      <td>0.504905</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.002517</td>
      <td>0.507422</td>
    </tr>
    <tr>
      <th>1077</th>
      <td>of the</td>
      <td>0.000000e+00</td>
      <td>0.002517</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.504906</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002514</td>
      <td>0.002514</td>
      <td>0.002514</td>
      <td>0.507419</td>
    </tr>
    <tr>
      <th>130</th>
      <td>aren</td>
      <td>0.000000e+00</td>
      <td>-0.002493</td>
      <td>0.002493</td>
      <td>0.002493</td>
      <td>0.509912</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 224
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;You have to hold the phone at a particular angle for the other party to hear you clearly.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.4825 0.5175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.092889</td>
      <td>0.092889</td>
      <td>0.092889</td>
      <td>0.592399</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.650000e-01</td>
      <td>0.075832</td>
      <td>-0.075832</td>
      <td>0.075832</td>
      <td>0.516567</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.597000e-01</td>
      <td>-0.062371</td>
      <td>0.062371</td>
      <td>0.062371</td>
      <td>0.578938</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.722222e-02</td>
      <td>0.035803</td>
      <td>-0.035803</td>
      <td>0.035803</td>
      <td>0.543135</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025222</td>
      <td>0.025222</td>
      <td>0.025222</td>
      <td>0.568357</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.800000e+01</td>
      <td>0.023892</td>
      <td>-0.023892</td>
      <td>0.023892</td>
      <td>0.544465</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021686</td>
      <td>0.021686</td>
      <td>0.021686</td>
      <td>0.566151</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>topic 78</td>
      <td>4.180110e-02</td>
      <td>0.015538</td>
      <td>-0.015538</td>
      <td>0.015538</td>
      <td>0.550613</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009973</td>
      <td>-0.009973</td>
      <td>0.009973</td>
      <td>0.540640</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009032</td>
      <td>-0.009032</td>
      <td>0.009032</td>
      <td>0.531608</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.377233e-40</td>
      <td>0.007833</td>
      <td>-0.007833</td>
      <td>0.007833</td>
      <td>0.523775</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006951</td>
      <td>-0.006951</td>
      <td>0.006951</td>
      <td>0.516824</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.005236</td>
      <td>-0.005236</td>
      <td>0.005236</td>
      <td>0.511588</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.516015e-195</td>
      <td>0.005122</td>
      <td>-0.005122</td>
      <td>0.005122</td>
      <td>0.506466</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005097</td>
      <td>-0.005097</td>
      <td>0.005097</td>
      <td>0.501369</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.004681</td>
      <td>0.004681</td>
      <td>0.004681</td>
      <td>0.506050</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004438</td>
      <td>-0.004438</td>
      <td>0.004438</td>
      <td>0.501612</td>
    </tr>
    <tr>
      <th>1515</th>
      <td>the other</td>
      <td>2.182179e-01</td>
      <td>-0.004027</td>
      <td>0.004027</td>
      <td>0.004027</td>
      <td>0.505639</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003929</td>
      <td>0.003929</td>
      <td>0.003929</td>
      <td>0.509567</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>2.182179e-01</td>
      <td>0.003857</td>
      <td>-0.003857</td>
      <td>0.003857</td>
      <td>0.505710</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003769</td>
      <td>-0.003769</td>
      <td>0.003769</td>
      <td>0.501941</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003506</td>
      <td>0.003506</td>
      <td>0.003506</td>
      <td>0.505447</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.900000e+01</td>
      <td>0.003384</td>
      <td>-0.003384</td>
      <td>0.003384</td>
      <td>0.502064</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.634831e-209</td>
      <td>-0.003230</td>
      <td>0.003230</td>
      <td>0.003230</td>
      <td>0.505293</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003215</td>
      <td>0.003215</td>
      <td>0.003215</td>
      <td>0.508508</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003180</td>
      <td>-0.003180</td>
      <td>0.003180</td>
      <td>0.505328</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003115</td>
      <td>-0.003115</td>
      <td>0.003115</td>
      <td>0.502213</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003113</td>
      <td>0.003113</td>
      <td>0.003113</td>
      <td>0.505326</td>
    </tr>
    <tr>
      <th>595</th>
      <td>going back</td>
      <td>0.000000e+00</td>
      <td>-0.003019</td>
      <td>0.003019</td>
      <td>0.003019</td>
      <td>0.508345</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002995</td>
      <td>0.002995</td>
      <td>0.002995</td>
      <td>0.511340</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 226
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I was proven dead wrong by this sushi bar, not only because the quality is great, but the service is fast and the food, impeccable.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.835 0.165]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-2.846000e-01</td>
      <td>0.080950</td>
      <td>-0.080950</td>
      <td>0.080950</td>
      <td>0.418560</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>9.000000e-02</td>
      <td>0.063219</td>
      <td>-0.063219</td>
      <td>0.063219</td>
      <td>0.355340</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.045266</td>
      <td>-0.045266</td>
      <td>0.045266</td>
      <td>0.310074</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.014514</td>
      <td>-0.014514</td>
      <td>0.014514</td>
      <td>0.295560</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.750000e-01</td>
      <td>0.009393</td>
      <td>-0.009393</td>
      <td>0.009393</td>
      <td>0.286168</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.796053e-01</td>
      <td>-0.009237</td>
      <td>0.009237</td>
      <td>0.009237</td>
      <td>0.295405</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.310000e+02</td>
      <td>0.007374</td>
      <td>-0.007374</td>
      <td>0.007374</td>
      <td>0.288031</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.718608e-02</td>
      <td>0.007116</td>
      <td>-0.007116</td>
      <td>0.007116</td>
      <td>0.280915</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.592106e-01</td>
      <td>0.006220</td>
      <td>-0.006220</td>
      <td>0.006220</td>
      <td>0.274695</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005257</td>
      <td>-0.005257</td>
      <td>0.005257</td>
      <td>0.269437</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004543</td>
      <td>0.004543</td>
      <td>0.004543</td>
      <td>0.273981</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.885635e-81</td>
      <td>0.004119</td>
      <td>-0.004119</td>
      <td>0.004119</td>
      <td>0.269861</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003970</td>
      <td>-0.003970</td>
      <td>0.003970</td>
      <td>0.265892</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.003779</td>
      <td>-0.003779</td>
      <td>0.003779</td>
      <td>0.262112</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>-0.003628</td>
      <td>0.003628</td>
      <td>0.003628</td>
      <td>0.265740</td>
    </tr>
    <tr>
      <th>2028</th>
      <td>topic 102</td>
      <td>1.821832e-01</td>
      <td>-0.003552</td>
      <td>0.003552</td>
      <td>0.003552</td>
      <td>0.269292</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003300</td>
      <td>0.003300</td>
      <td>0.003300</td>
      <td>0.272592</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>4.066550e-304</td>
      <td>0.003199</td>
      <td>-0.003199</td>
      <td>0.003199</td>
      <td>0.269393</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003076</td>
      <td>-0.003076</td>
      <td>0.003076</td>
      <td>0.266317</td>
    </tr>
    <tr>
      <th>1932</th>
      <td>topic 6</td>
      <td>6.528298e-02</td>
      <td>0.002703</td>
      <td>-0.002703</td>
      <td>0.002703</td>
      <td>0.263613</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.089796e-92</td>
      <td>-0.002693</td>
      <td>0.002693</td>
      <td>0.002693</td>
      <td>0.266307</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002622</td>
      <td>0.002622</td>
      <td>0.002622</td>
      <td>0.268928</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002577</td>
      <td>0.002577</td>
      <td>0.002577</td>
      <td>0.271506</td>
    </tr>
    <tr>
      <th>543</th>
      <td>forced</td>
      <td>0.000000e+00</td>
      <td>-0.002564</td>
      <td>0.002564</td>
      <td>0.002564</td>
      <td>0.274070</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002534</td>
      <td>0.002534</td>
      <td>0.002534</td>
      <td>0.276604</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002507</td>
      <td>-0.002507</td>
      <td>0.002507</td>
      <td>0.274096</td>
    </tr>
    <tr>
      <th>1082</th>
      <td>off</td>
      <td>0.000000e+00</td>
      <td>-0.002486</td>
      <td>0.002486</td>
      <td>0.002486</td>
      <td>0.276582</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>1.796053e-01</td>
      <td>-0.002471</td>
      <td>0.002471</td>
      <td>0.002471</td>
      <td>0.279053</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002378</td>
      <td>-0.002378</td>
      <td>0.002378</td>
      <td>0.276675</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002338</td>
      <td>0.002338</td>
      <td>0.002338</td>
      <td>0.279014</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 239
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;for 40 bucks a head, i really expect better food.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.325 0.675]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.153654</td>
      <td>0.153654</td>
      <td>0.153654</td>
      <td>0.653164</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.120000e-01</td>
      <td>0.080157</td>
      <td>-0.080157</td>
      <td>0.080157</td>
      <td>0.573007</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.902000e-01</td>
      <td>-0.043920</td>
      <td>0.043920</td>
      <td>0.043920</td>
      <td>0.616927</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024864</td>
      <td>0.024864</td>
      <td>0.024864</td>
      <td>0.641791</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.000000e+01</td>
      <td>0.022058</td>
      <td>-0.022058</td>
      <td>0.022058</td>
      <td>0.619733</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020700</td>
      <td>0.020700</td>
      <td>0.020700</td>
      <td>0.640433</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.500000e-01</td>
      <td>-0.012402</td>
      <td>0.012402</td>
      <td>0.012402</td>
      <td>0.652836</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.010452</td>
      <td>-0.010452</td>
      <td>0.010452</td>
      <td>0.642383</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009258</td>
      <td>-0.009258</td>
      <td>0.009258</td>
      <td>0.633126</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.717382e-83</td>
      <td>0.007685</td>
      <td>-0.007685</td>
      <td>0.007685</td>
      <td>0.625440</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.007550</td>
      <td>-0.007550</td>
      <td>0.007550</td>
      <td>0.617891</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.007071</td>
      <td>-0.007071</td>
      <td>0.007071</td>
      <td>0.610819</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.006112</td>
      <td>0.006112</td>
      <td>0.006112</td>
      <td>0.616931</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.900000e+01</td>
      <td>-0.005500</td>
      <td>0.005500</td>
      <td>0.005500</td>
      <td>0.622431</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.195162e-24</td>
      <td>0.005429</td>
      <td>-0.005429</td>
      <td>0.005429</td>
      <td>0.617002</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005360</td>
      <td>-0.005360</td>
      <td>0.005360</td>
      <td>0.611642</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004290</td>
      <td>0.004290</td>
      <td>0.004290</td>
      <td>0.615932</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003633</td>
      <td>0.003633</td>
      <td>0.003633</td>
      <td>0.619565</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003467</td>
      <td>0.003467</td>
      <td>0.003467</td>
      <td>0.623032</td>
    </tr>
    <tr>
      <th>1520</th>
      <td>the place</td>
      <td>0.000000e+00</td>
      <td>-0.003375</td>
      <td>0.003375</td>
      <td>0.003375</td>
      <td>0.626407</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003316</td>
      <td>-0.003316</td>
      <td>0.003316</td>
      <td>0.623091</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003036</td>
      <td>-0.003036</td>
      <td>0.003036</td>
      <td>0.620055</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002945</td>
      <td>0.002945</td>
      <td>0.002945</td>
      <td>0.622999</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002932</td>
      <td>-0.002932</td>
      <td>0.002932</td>
      <td>0.620067</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>8.210045e-127</td>
      <td>-0.002854</td>
      <td>0.002854</td>
      <td>0.002854</td>
      <td>0.622921</td>
    </tr>
    <tr>
      <th>206</th>
      <td>better</td>
      <td>4.472136e-01</td>
      <td>0.002814</td>
      <td>-0.002814</td>
      <td>0.002814</td>
      <td>0.620107</td>
    </tr>
    <tr>
      <th>1887</th>
      <td>would</td>
      <td>0.000000e+00</td>
      <td>-0.002792</td>
      <td>0.002792</td>
      <td>0.002792</td>
      <td>0.622898</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002769</td>
      <td>-0.002769</td>
      <td>0.002769</td>
      <td>0.620129</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002691</td>
      <td>0.002691</td>
      <td>0.002691</td>
      <td>0.622820</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002651</td>
      <td>0.002651</td>
      <td>0.002651</td>
      <td>0.625471</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 243
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Some may say this buffet is pricey but I think you get what you pay for and this place you are getting quite a lot!&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.895 0.105]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.164006</td>
      <td>-0.164006</td>
      <td>0.164006</td>
      <td>0.335503</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.077861</td>
      <td>-0.077861</td>
      <td>0.077861</td>
      <td>0.257643</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-2.244000e-01</td>
      <td>0.055382</td>
      <td>-0.055382</td>
      <td>0.055382</td>
      <td>0.202261</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.028058</td>
      <td>0.028058</td>
      <td>0.028058</td>
      <td>0.230319</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.023321</td>
      <td>-0.023321</td>
      <td>0.023321</td>
      <td>0.206998</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022825</td>
      <td>0.022825</td>
      <td>0.022825</td>
      <td>0.229823</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.018624</td>
      <td>-0.018624</td>
      <td>0.018624</td>
      <td>0.211200</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016709</td>
      <td>0.016709</td>
      <td>0.016709</td>
      <td>0.227909</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.150000e+02</td>
      <td>0.016461</td>
      <td>-0.016461</td>
      <td>0.016461</td>
      <td>0.211448</td>
    </tr>
    <tr>
      <th>2021</th>
      <td>topic 95</td>
      <td>1.688747e-01</td>
      <td>-0.012946</td>
      <td>0.012946</td>
      <td>0.012946</td>
      <td>0.224394</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009398</td>
      <td>-0.009398</td>
      <td>0.009398</td>
      <td>0.214996</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.397908e-96</td>
      <td>0.006444</td>
      <td>-0.006444</td>
      <td>0.006444</td>
      <td>0.208552</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005786</td>
      <td>-0.005786</td>
      <td>0.005786</td>
      <td>0.202766</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>0.004732</td>
      <td>-0.004732</td>
      <td>0.004732</td>
      <td>0.198034</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.585834e-53</td>
      <td>0.004361</td>
      <td>-0.004361</td>
      <td>0.004361</td>
      <td>0.193673</td>
    </tr>
    <tr>
      <th>1586</th>
      <td>this</td>
      <td>3.287980e-01</td>
      <td>-0.003731</td>
      <td>0.003731</td>
      <td>0.003731</td>
      <td>0.197404</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003709</td>
      <td>0.003709</td>
      <td>0.003709</td>
      <td>0.201113</td>
    </tr>
    <tr>
      <th>122</th>
      <td>are</td>
      <td>1.643990e-01</td>
      <td>0.003504</td>
      <td>-0.003504</td>
      <td>0.003504</td>
      <td>0.197609</td>
    </tr>
    <tr>
      <th>249</th>
      <td>but think</td>
      <td>1.643990e-01</td>
      <td>-0.003485</td>
      <td>0.003485</td>
      <td>0.003485</td>
      <td>0.201094</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.653394e-20</td>
      <td>-0.003408</td>
      <td>0.003408</td>
      <td>0.003408</td>
      <td>0.204502</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>1.643990e-01</td>
      <td>0.003324</td>
      <td>-0.003324</td>
      <td>0.003324</td>
      <td>0.201178</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002915</td>
      <td>0.002915</td>
      <td>0.002915</td>
      <td>0.204093</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>4.931970e-01</td>
      <td>-0.002784</td>
      <td>0.002784</td>
      <td>0.002784</td>
      <td>0.206876</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002662</td>
      <td>0.002662</td>
      <td>0.002662</td>
      <td>0.209539</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002639</td>
      <td>0.002639</td>
      <td>0.002639</td>
      <td>0.212178</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>1.643990e-01</td>
      <td>0.002616</td>
      <td>-0.002616</td>
      <td>0.002616</td>
      <td>0.209562</td>
    </tr>
    <tr>
      <th>1930</th>
      <td>topic 4</td>
      <td>7.901275e-02</td>
      <td>0.002598</td>
      <td>-0.002598</td>
      <td>0.002598</td>
      <td>0.206964</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002472</td>
      <td>-0.002472</td>
      <td>0.002472</td>
      <td>0.204492</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002378</td>
      <td>0.002378</td>
      <td>0.002378</td>
      <td>0.206870</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002329</td>
      <td>0.002329</td>
      <td>0.002329</td>
      <td>0.209199</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 259
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;My side Greek salad with the Greek dressing was so tasty, and the pita and hummus was very refreshing.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8275 0.1725]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-5.267000e-01</td>
      <td>0.149081</td>
      <td>-0.149081</td>
      <td>0.149081</td>
      <td>0.350429</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.088490</td>
      <td>-0.088490</td>
      <td>0.088490</td>
      <td>0.261939</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023495</td>
      <td>0.023495</td>
      <td>0.023495</td>
      <td>0.285434</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018914</td>
      <td>0.018914</td>
      <td>0.018914</td>
      <td>0.304347</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>-0.015038</td>
      <td>0.015038</td>
      <td>0.015038</td>
      <td>0.319386</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009630</td>
      <td>-0.009630</td>
      <td>0.009630</td>
      <td>0.309756</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.008307</td>
      <td>-0.008307</td>
      <td>0.008307</td>
      <td>0.301448</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.020000e+02</td>
      <td>0.007714</td>
      <td>-0.007714</td>
      <td>0.007714</td>
      <td>0.293734</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.900000e+01</td>
      <td>0.007691</td>
      <td>-0.007691</td>
      <td>0.007691</td>
      <td>0.286043</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.469826e-37</td>
      <td>0.007245</td>
      <td>-0.007245</td>
      <td>0.007245</td>
      <td>0.278799</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.166667e-01</td>
      <td>0.006900</td>
      <td>-0.006900</td>
      <td>0.006900</td>
      <td>0.271899</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006349</td>
      <td>-0.006349</td>
      <td>0.006349</td>
      <td>0.265550</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.005141</td>
      <td>-0.005141</td>
      <td>0.005141</td>
      <td>0.260409</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004565</td>
      <td>-0.004565</td>
      <td>0.004565</td>
      <td>0.255844</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004230</td>
      <td>-0.004230</td>
      <td>0.004230</td>
      <td>0.251614</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003529</td>
      <td>0.003529</td>
      <td>0.003529</td>
      <td>0.255142</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003511</td>
      <td>0.003511</td>
      <td>0.003511</td>
      <td>0.258653</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>4.588315e-01</td>
      <td>-0.003473</td>
      <td>0.003473</td>
      <td>0.003473</td>
      <td>0.262126</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003300</td>
      <td>0.003300</td>
      <td>0.003300</td>
      <td>0.265426</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003296</td>
      <td>0.003296</td>
      <td>0.003296</td>
      <td>0.268723</td>
    </tr>
    <tr>
      <th>1762</th>
      <td>wa so</td>
      <td>2.294157e-01</td>
      <td>-0.003148</td>
      <td>0.003148</td>
      <td>0.003148</td>
      <td>0.271871</td>
    </tr>
    <tr>
      <th>1005</th>
      <td>never</td>
      <td>0.000000e+00</td>
      <td>0.002746</td>
      <td>-0.002746</td>
      <td>0.002746</td>
      <td>0.269125</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002695</td>
      <td>-0.002695</td>
      <td>0.002695</td>
      <td>0.266430</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002682</td>
      <td>-0.002682</td>
      <td>0.002682</td>
      <td>0.263748</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002677</td>
      <td>0.002677</td>
      <td>0.002677</td>
      <td>0.266425</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.002673</td>
      <td>-0.002673</td>
      <td>0.002673</td>
      <td>0.263752</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.002632</td>
      <td>0.002632</td>
      <td>0.002632</td>
      <td>0.266384</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002610</td>
      <td>0.002610</td>
      <td>0.002610</td>
      <td>0.268994</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002566</td>
      <td>0.002566</td>
      <td>0.002566</td>
      <td>0.271560</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002554</td>
      <td>0.002554</td>
      <td>0.002554</td>
      <td>0.274114</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 261
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;As a sushi lover avoid this place by all means.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.825 0.175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.163192</td>
      <td>-0.163192</td>
      <td>0.163192</td>
      <td>0.336318</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.920000e-01</td>
      <td>0.060129</td>
      <td>-0.060129</td>
      <td>0.060129</td>
      <td>0.276188</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.818000e-01</td>
      <td>-0.038157</td>
      <td>0.038157</td>
      <td>0.038157</td>
      <td>0.314345</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031891</td>
      <td>-0.031891</td>
      <td>0.031891</td>
      <td>0.282454</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023100</td>
      <td>0.023100</td>
      <td>0.023100</td>
      <td>0.305554</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.017898</td>
      <td>0.017898</td>
      <td>0.017898</td>
      <td>0.323452</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.000000e+01</td>
      <td>0.016624</td>
      <td>-0.016624</td>
      <td>0.016624</td>
      <td>0.306829</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.700000e+01</td>
      <td>0.013391</td>
      <td>-0.013391</td>
      <td>0.013391</td>
      <td>0.293438</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009125</td>
      <td>-0.009125</td>
      <td>0.009125</td>
      <td>0.284313</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008054</td>
      <td>-0.008054</td>
      <td>0.008054</td>
      <td>0.276259</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.973226e-93</td>
      <td>0.006976</td>
      <td>-0.006976</td>
      <td>0.006976</td>
      <td>0.269283</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005907</td>
      <td>-0.005907</td>
      <td>0.005907</td>
      <td>0.263377</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>6.237695e-94</td>
      <td>0.004430</td>
      <td>-0.004430</td>
      <td>0.004430</td>
      <td>0.258946</td>
    </tr>
    <tr>
      <th>28</th>
      <td>all the</td>
      <td>0.000000e+00</td>
      <td>0.004336</td>
      <td>-0.004336</td>
      <td>0.004336</td>
      <td>0.254610</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.003936</td>
      <td>-0.003936</td>
      <td>0.003936</td>
      <td>0.250674</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003530</td>
      <td>0.003530</td>
      <td>0.003530</td>
      <td>0.254204</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003511</td>
      <td>0.003511</td>
      <td>0.003511</td>
      <td>0.257716</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003472</td>
      <td>-0.003472</td>
      <td>0.003472</td>
      <td>0.254244</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.342671e-260</td>
      <td>-0.003326</td>
      <td>0.003326</td>
      <td>0.003326</td>
      <td>0.257570</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003267</td>
      <td>0.003267</td>
      <td>0.003267</td>
      <td>0.260837</td>
    </tr>
    <tr>
      <th>1930</th>
      <td>topic 4</td>
      <td>1.047338e-01</td>
      <td>-0.003117</td>
      <td>0.003117</td>
      <td>0.003117</td>
      <td>0.263953</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003062</td>
      <td>0.003062</td>
      <td>0.003062</td>
      <td>0.267016</td>
    </tr>
    <tr>
      <th>22</th>
      <td>all</td>
      <td>3.333333e-01</td>
      <td>-0.002791</td>
      <td>0.002791</td>
      <td>0.002791</td>
      <td>0.269806</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002639</td>
      <td>0.002639</td>
      <td>0.002639</td>
      <td>0.272445</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002630</td>
      <td>-0.002630</td>
      <td>0.002630</td>
      <td>0.269815</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002629</td>
      <td>-0.002629</td>
      <td>0.002629</td>
      <td>0.267186</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002618</td>
      <td>0.002618</td>
      <td>0.002618</td>
      <td>0.269804</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002591</td>
      <td>-0.002591</td>
      <td>0.002591</td>
      <td>0.267213</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002501</td>
      <td>0.002501</td>
      <td>0.002501</td>
      <td>0.269715</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002480</td>
      <td>0.002480</td>
      <td>0.002480</td>
      <td>0.272194</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 264
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Garbo, who showed right off the bat that her talents could carry over from the silent era (I wanted to see some of her silent work, but Netflix doesn&#39;t seem to be stocking them.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.6975 0.3025]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>5.700000e-02</td>
      <td>0.084486</td>
      <td>-0.084486</td>
      <td>0.084486</td>
      <td>0.415024</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>2.500000e-01</td>
      <td>-0.038104</td>
      <td>0.038104</td>
      <td>0.038104</td>
      <td>0.453128</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.400000e+01</td>
      <td>0.031712</td>
      <td>-0.031712</td>
      <td>0.031712</td>
      <td>0.421416</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>9.523810e-02</td>
      <td>0.027576</td>
      <td>-0.027576</td>
      <td>0.027576</td>
      <td>0.393840</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026130</td>
      <td>0.026130</td>
      <td>0.026130</td>
      <td>0.419970</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019573</td>
      <td>0.019573</td>
      <td>0.019573</td>
      <td>0.439542</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>-0.011948</td>
      <td>0.011948</td>
      <td>0.011948</td>
      <td>0.451490</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009886</td>
      <td>-0.009886</td>
      <td>0.009886</td>
      <td>0.441604</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008915</td>
      <td>-0.008915</td>
      <td>0.008915</td>
      <td>0.432689</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007780</td>
      <td>-0.007780</td>
      <td>0.007780</td>
      <td>0.424910</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.007643</td>
      <td>-0.007643</td>
      <td>0.007643</td>
      <td>0.417266</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.555634e-37</td>
      <td>0.007623</td>
      <td>-0.007623</td>
      <td>0.007623</td>
      <td>0.409644</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.007457</td>
      <td>-0.007457</td>
      <td>0.007457</td>
      <td>0.402186</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.790000e+02</td>
      <td>0.007227</td>
      <td>-0.007227</td>
      <td>0.007227</td>
      <td>0.394959</td>
    </tr>
    <tr>
      <th>1082</th>
      <td>off</td>
      <td>1.856953e-01</td>
      <td>0.006400</td>
      <td>-0.006400</td>
      <td>0.006400</td>
      <td>0.388560</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006373</td>
      <td>-0.006373</td>
      <td>0.006373</td>
      <td>0.382187</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005597</td>
      <td>0.005597</td>
      <td>0.005597</td>
      <td>0.387784</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.340180e-238</td>
      <td>0.005128</td>
      <td>-0.005128</td>
      <td>0.005128</td>
      <td>0.382656</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>1.089451e-16</td>
      <td>0.004947</td>
      <td>-0.004947</td>
      <td>0.004947</td>
      <td>0.377708</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004349</td>
      <td>-0.004349</td>
      <td>0.004349</td>
      <td>0.373359</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004080</td>
      <td>0.004080</td>
      <td>0.004080</td>
      <td>0.377439</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003991</td>
      <td>0.003991</td>
      <td>0.003991</td>
      <td>0.381431</td>
    </tr>
    <tr>
      <th>344</th>
      <td>could</td>
      <td>1.856953e-01</td>
      <td>-0.003660</td>
      <td>0.003660</td>
      <td>0.003660</td>
      <td>0.385090</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003316</td>
      <td>0.003316</td>
      <td>0.003316</td>
      <td>0.388407</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003230</td>
      <td>0.003230</td>
      <td>0.003230</td>
      <td>0.391637</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.757864e-235</td>
      <td>-0.003195</td>
      <td>0.003195</td>
      <td>0.003195</td>
      <td>0.394832</td>
    </tr>
    <tr>
      <th>1932</th>
      <td>topic 6</td>
      <td>0.000000e+00</td>
      <td>0.003180</td>
      <td>-0.003180</td>
      <td>0.003180</td>
      <td>0.391652</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003155</td>
      <td>-0.003155</td>
      <td>0.003155</td>
      <td>0.388498</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.190173e-01</td>
      <td>0.003123</td>
      <td>-0.003123</td>
      <td>0.003123</td>
      <td>0.385375</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003094</td>
      <td>0.003094</td>
      <td>0.003094</td>
      <td>0.388469</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 271
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;His on screen presence shined thought even though there were other senior actors on the screen with him.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8425 0.1575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.082489</td>
      <td>-0.082489</td>
      <td>0.082489</td>
      <td>0.417021</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.250000e-01</td>
      <td>0.056052</td>
      <td>-0.056052</td>
      <td>0.056052</td>
      <td>0.360969</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.800000e+01</td>
      <td>0.032385</td>
      <td>-0.032385</td>
      <td>0.032385</td>
      <td>0.328584</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024957</td>
      <td>0.024957</td>
      <td>0.024957</td>
      <td>0.353542</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019711</td>
      <td>0.019711</td>
      <td>0.019711</td>
      <td>0.373253</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.060000e+02</td>
      <td>0.019378</td>
      <td>-0.019378</td>
      <td>0.019378</td>
      <td>0.353876</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009660</td>
      <td>-0.009660</td>
      <td>0.009660</td>
      <td>0.344216</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.007909</td>
      <td>-0.007909</td>
      <td>0.007909</td>
      <td>0.336307</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.680010e-258</td>
      <td>0.007297</td>
      <td>-0.007297</td>
      <td>0.007297</td>
      <td>0.329011</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007233</td>
      <td>-0.007233</td>
      <td>0.007233</td>
      <td>0.321777</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.315238</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006383</td>
      <td>-0.006383</td>
      <td>0.006383</td>
      <td>0.308855</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.006366</td>
      <td>0.006366</td>
      <td>0.006366</td>
      <td>0.315221</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005344</td>
      <td>0.005344</td>
      <td>0.005344</td>
      <td>0.320565</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.837392e-16</td>
      <td>0.004953</td>
      <td>-0.004953</td>
      <td>0.004953</td>
      <td>0.315612</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004656</td>
      <td>-0.004656</td>
      <td>0.004656</td>
      <td>0.310956</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004422</td>
      <td>-0.004422</td>
      <td>0.004422</td>
      <td>0.306534</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004357</td>
      <td>0.004357</td>
      <td>0.004357</td>
      <td>0.310891</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004032</td>
      <td>-0.004032</td>
      <td>0.004032</td>
      <td>0.306859</td>
    </tr>
    <tr>
      <th>2102</th>
      <td>topic 176</td>
      <td>1.129138e-02</td>
      <td>-0.003906</td>
      <td>0.003906</td>
      <td>0.003906</td>
      <td>0.310766</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003706</td>
      <td>0.003706</td>
      <td>0.003706</td>
      <td>0.314471</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003650</td>
      <td>0.003650</td>
      <td>0.003650</td>
      <td>0.318121</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>9.875965e-07</td>
      <td>-0.003618</td>
      <td>0.003618</td>
      <td>0.003618</td>
      <td>0.321739</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.003611</td>
      <td>-0.003611</td>
      <td>0.003611</td>
      <td>0.318129</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.465530e-24</td>
      <td>0.003594</td>
      <td>-0.003594</td>
      <td>0.003594</td>
      <td>0.314535</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.003584</td>
      <td>0.003584</td>
      <td>0.003584</td>
      <td>0.318119</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003463</td>
      <td>0.003463</td>
      <td>0.003463</td>
      <td>0.321583</td>
    </tr>
    <tr>
      <th>2096</th>
      <td>topic 170</td>
      <td>1.675205e-06</td>
      <td>-0.003441</td>
      <td>0.003441</td>
      <td>0.003441</td>
      <td>0.325023</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.384887e-21</td>
      <td>-0.003312</td>
      <td>0.003312</td>
      <td>0.003312</td>
      <td>0.328335</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.003264</td>
      <td>-0.003264</td>
      <td>0.003264</td>
      <td>0.325072</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 275
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Also, it&#39;s a real treat to see Anthony Quinn playing Crazy Horse.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8625 0.1375]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.179498</td>
      <td>-0.179498</td>
      <td>0.179498</td>
      <td>0.320011</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.020000e-01</td>
      <td>0.056449</td>
      <td>-0.056449</td>
      <td>0.056449</td>
      <td>0.263563</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-2.000000e-01</td>
      <td>0.043045</td>
      <td>-0.043045</td>
      <td>0.043045</td>
      <td>0.220518</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.021930</td>
      <td>0.021930</td>
      <td>0.021930</td>
      <td>0.242448</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>2.732000e-01</td>
      <td>-0.021344</td>
      <td>0.021344</td>
      <td>0.021344</td>
      <td>0.263791</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.017185</td>
      <td>-0.017185</td>
      <td>0.017185</td>
      <td>0.246606</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016242</td>
      <td>0.016242</td>
      <td>0.016242</td>
      <td>0.262848</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.700000e+01</td>
      <td>0.015805</td>
      <td>-0.015805</td>
      <td>0.015805</td>
      <td>0.247043</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008742</td>
      <td>-0.008742</td>
      <td>0.008742</td>
      <td>0.238301</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008195</td>
      <td>-0.008195</td>
      <td>0.008195</td>
      <td>0.230106</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006556</td>
      <td>-0.006556</td>
      <td>0.006556</td>
      <td>0.223550</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005585</td>
      <td>-0.005585</td>
      <td>0.005585</td>
      <td>0.217965</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.004768</td>
      <td>-0.004768</td>
      <td>0.004768</td>
      <td>0.213197</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.108517e-131</td>
      <td>0.004071</td>
      <td>-0.004071</td>
      <td>0.004071</td>
      <td>0.209126</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.003379</td>
      <td>-0.003379</td>
      <td>0.003379</td>
      <td>0.205747</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003360</td>
      <td>0.003360</td>
      <td>0.003360</td>
      <td>0.209107</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003207</td>
      <td>-0.003207</td>
      <td>0.003207</td>
      <td>0.205900</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003196</td>
      <td>0.003196</td>
      <td>0.003196</td>
      <td>0.209096</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003076</td>
      <td>0.003076</td>
      <td>0.003076</td>
      <td>0.212172</td>
    </tr>
    <tr>
      <th>1908</th>
      <td>you ll</td>
      <td>0.000000e+00</td>
      <td>0.002712</td>
      <td>-0.002712</td>
      <td>0.002712</td>
      <td>0.209460</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002701</td>
      <td>0.002701</td>
      <td>0.002701</td>
      <td>0.212161</td>
    </tr>
    <tr>
      <th>254</th>
      <td>button</td>
      <td>0.000000e+00</td>
      <td>-0.002682</td>
      <td>0.002682</td>
      <td>0.002682</td>
      <td>0.214843</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>-0.002647</td>
      <td>0.002647</td>
      <td>0.002647</td>
      <td>0.217490</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002630</td>
      <td>-0.002630</td>
      <td>0.002630</td>
      <td>0.214860</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>0.000000e+00</td>
      <td>-0.002504</td>
      <td>0.002504</td>
      <td>0.002504</td>
      <td>0.217364</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002495</td>
      <td>0.002495</td>
      <td>0.002495</td>
      <td>0.219859</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002411</td>
      <td>-0.002411</td>
      <td>0.002411</td>
      <td>0.217448</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>0.000000e+00</td>
      <td>0.002375</td>
      <td>-0.002375</td>
      <td>0.002375</td>
      <td>0.215073</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002373</td>
      <td>0.002373</td>
      <td>0.002373</td>
      <td>0.217445</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002371</td>
      <td>0.002371</td>
      <td>0.002371</td>
      <td>0.219816</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 278
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;So I bought about 10 of these and saved alot of money.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.4575 0.5425]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.161145</td>
      <td>0.161145</td>
      <td>0.161145</td>
      <td>0.660655</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.190000e-01</td>
      <td>0.073114</td>
      <td>-0.073114</td>
      <td>0.073114</td>
      <td>0.587541</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.039667</td>
      <td>-0.039667</td>
      <td>0.039667</td>
      <td>0.547874</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.215000e-01</td>
      <td>-0.029778</td>
      <td>0.029778</td>
      <td>0.029778</td>
      <td>0.577653</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.026650</td>
      <td>-0.026650</td>
      <td>0.026650</td>
      <td>0.551003</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024801</td>
      <td>0.024801</td>
      <td>0.024801</td>
      <td>0.575804</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021018</td>
      <td>0.021018</td>
      <td>0.021018</td>
      <td>0.596822</td>
    </tr>
    <tr>
      <th>1949</th>
      <td>topic 23</td>
      <td>1.605165e-01</td>
      <td>0.009431</td>
      <td>-0.009431</td>
      <td>0.009431</td>
      <td>0.587391</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009100</td>
      <td>-0.009100</td>
      <td>0.009100</td>
      <td>0.578291</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007625</td>
      <td>-0.007625</td>
      <td>0.007625</td>
      <td>0.570666</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006248</td>
      <td>-0.006248</td>
      <td>0.006248</td>
      <td>0.564417</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005938</td>
      <td>-0.005938</td>
      <td>0.005938</td>
      <td>0.558479</td>
    </tr>
    <tr>
      <th>1565</th>
      <td>these</td>
      <td>3.015113e-01</td>
      <td>0.005931</td>
      <td>-0.005931</td>
      <td>0.005931</td>
      <td>0.552548</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>0.005006</td>
      <td>-0.005006</td>
      <td>0.005006</td>
      <td>0.547541</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.806128e-16</td>
      <td>0.004973</td>
      <td>-0.004973</td>
      <td>0.004973</td>
      <td>0.542568</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004123</td>
      <td>-0.004123</td>
      <td>0.004123</td>
      <td>0.538445</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003655</td>
      <td>0.003655</td>
      <td>0.003655</td>
      <td>0.542100</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003416</td>
      <td>0.003416</td>
      <td>0.003416</td>
      <td>0.545516</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003055</td>
      <td>-0.003055</td>
      <td>0.003055</td>
      <td>0.542461</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003013</td>
      <td>0.003013</td>
      <td>0.003013</td>
      <td>0.545474</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.002894</td>
      <td>0.002894</td>
      <td>0.002894</td>
      <td>0.548369</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002798</td>
      <td>-0.002798</td>
      <td>0.002798</td>
      <td>0.545571</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002794</td>
      <td>0.002794</td>
      <td>0.002794</td>
      <td>0.548364</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002789</td>
      <td>0.002789</td>
      <td>0.002789</td>
      <td>0.551153</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002778</td>
      <td>0.002778</td>
      <td>0.002778</td>
      <td>0.553931</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002774</td>
      <td>0.002774</td>
      <td>0.002774</td>
      <td>0.556706</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002621</td>
      <td>0.002621</td>
      <td>0.002621</td>
      <td>0.559327</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002566</td>
      <td>-0.002566</td>
      <td>0.002566</td>
      <td>0.556760</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.559260</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002462</td>
      <td>-0.002462</td>
      <td>0.002462</td>
      <td>0.556798</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 282
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;I don&#39;t think you will be disappointed.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.975 0.025]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.142889</td>
      <td>-0.142889</td>
      <td>0.142889</td>
      <td>0.356620</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-7.500000e-01</td>
      <td>0.093143</td>
      <td>-0.093143</td>
      <td>0.093143</td>
      <td>0.263477</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.767000e-01</td>
      <td>0.068401</td>
      <td>-0.068401</td>
      <td>0.068401</td>
      <td>0.195076</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.059682</td>
      <td>-0.059682</td>
      <td>0.059682</td>
      <td>0.135395</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.020189</td>
      <td>0.020189</td>
      <td>0.020189</td>
      <td>0.155583</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.011634</td>
      <td>-0.011634</td>
      <td>0.011634</td>
      <td>0.143950</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007995</td>
      <td>-0.007995</td>
      <td>0.007995</td>
      <td>0.135955</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.957035e-131</td>
      <td>0.005946</td>
      <td>-0.005946</td>
      <td>0.005946</td>
      <td>0.130009</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.005936</td>
      <td>-0.005936</td>
      <td>0.005936</td>
      <td>0.124073</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005316</td>
      <td>-0.005316</td>
      <td>0.005316</td>
      <td>0.118757</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>2.886751e-01</td>
      <td>-0.004215</td>
      <td>0.004215</td>
      <td>0.004215</td>
      <td>0.122972</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.364522e-132</td>
      <td>0.003599</td>
      <td>-0.003599</td>
      <td>0.003599</td>
      <td>0.119373</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>2.886751e-01</td>
      <td>-0.003349</td>
      <td>0.003349</td>
      <td>0.003349</td>
      <td>0.122722</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003182</td>
      <td>0.003182</td>
      <td>0.003182</td>
      <td>0.125905</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.100000e+01</td>
      <td>0.002729</td>
      <td>-0.002729</td>
      <td>0.002729</td>
      <td>0.123176</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002664</td>
      <td>0.002664</td>
      <td>0.002664</td>
      <td>0.125839</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002592</td>
      <td>-0.002592</td>
      <td>0.002592</td>
      <td>0.123247</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002561</td>
      <td>0.002561</td>
      <td>0.002561</td>
      <td>0.125808</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>2.886751e-01</td>
      <td>-0.002171</td>
      <td>0.002171</td>
      <td>0.002171</td>
      <td>0.127978</td>
    </tr>
    <tr>
      <th>1637</th>
      <td>to it</td>
      <td>0.000000e+00</td>
      <td>0.002164</td>
      <td>-0.002164</td>
      <td>0.002164</td>
      <td>0.125814</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002158</td>
      <td>-0.002158</td>
      <td>0.002158</td>
      <td>0.123657</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002039</td>
      <td>0.002039</td>
      <td>0.002039</td>
      <td>0.125695</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002001</td>
      <td>0.002001</td>
      <td>0.002001</td>
      <td>0.127696</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.001797</td>
      <td>-0.001797</td>
      <td>0.001797</td>
      <td>0.125898</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>2.886751e-01</td>
      <td>0.001734</td>
      <td>-0.001734</td>
      <td>0.001734</td>
      <td>0.124164</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>0.000000e+00</td>
      <td>0.001682</td>
      <td>-0.001682</td>
      <td>0.001682</td>
      <td>0.122483</td>
    </tr>
    <tr>
      <th>1943</th>
      <td>topic 17</td>
      <td>0.000000e+00</td>
      <td>0.001658</td>
      <td>-0.001658</td>
      <td>0.001658</td>
      <td>0.120825</td>
    </tr>
    <tr>
      <th>2042</th>
      <td>topic 116</td>
      <td>0.000000e+00</td>
      <td>0.001641</td>
      <td>-0.001641</td>
      <td>0.001641</td>
      <td>0.119183</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.001639</td>
      <td>-0.001639</td>
      <td>0.001639</td>
      <td>0.117545</td>
    </tr>
    <tr>
      <th>1635</th>
      <td>to go</td>
      <td>0.000000e+00</td>
      <td>0.001596</td>
      <td>-0.001596</td>
      <td>0.001596</td>
      <td>0.115948</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 284
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The deal included 5 tastings and 2 drinks, and Jeff went above and beyond what we expected.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.775 0.225]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.090528</td>
      <td>-0.090528</td>
      <td>0.090528</td>
      <td>0.408982</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-5.000000e-02</td>
      <td>0.040694</td>
      <td>-0.040694</td>
      <td>0.040694</td>
      <td>0.368288</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.025878</td>
      <td>-0.025878</td>
      <td>0.025878</td>
      <td>0.342410</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025337</td>
      <td>0.025337</td>
      <td>0.025337</td>
      <td>0.367747</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019303</td>
      <td>0.019303</td>
      <td>0.019303</td>
      <td>0.387050</td>
    </tr>
    <tr>
      <th>2109</th>
      <td>topic 183</td>
      <td>2.768853e-01</td>
      <td>-0.014972</td>
      <td>0.014972</td>
      <td>0.014972</td>
      <td>0.402022</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.010417</td>
      <td>0.010417</td>
      <td>0.010417</td>
      <td>0.412439</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.010405</td>
      <td>-0.010405</td>
      <td>0.010405</td>
      <td>0.402034</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.009826</td>
      <td>-0.009826</td>
      <td>0.009826</td>
      <td>0.392208</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008040</td>
      <td>-0.008040</td>
      <td>0.008040</td>
      <td>0.384168</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.349797e-22</td>
      <td>0.007417</td>
      <td>-0.007417</td>
      <td>0.007417</td>
      <td>0.376750</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006064</td>
      <td>-0.006064</td>
      <td>0.006064</td>
      <td>0.370687</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005609</td>
      <td>0.005609</td>
      <td>0.005609</td>
      <td>0.376296</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.887653e-212</td>
      <td>0.004798</td>
      <td>-0.004798</td>
      <td>0.004798</td>
      <td>0.371498</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004578</td>
      <td>-0.004578</td>
      <td>0.004578</td>
      <td>0.366920</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004254</td>
      <td>-0.004254</td>
      <td>0.004254</td>
      <td>0.362666</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004100</td>
      <td>-0.004100</td>
      <td>0.004100</td>
      <td>0.358566</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004003</td>
      <td>0.004003</td>
      <td>0.004003</td>
      <td>0.362569</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003816</td>
      <td>-0.003816</td>
      <td>0.003816</td>
      <td>0.358753</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003672</td>
      <td>0.003672</td>
      <td>0.003672</td>
      <td>0.362425</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003646</td>
      <td>-0.003646</td>
      <td>0.003646</td>
      <td>0.358779</td>
    </tr>
    <tr>
      <th>219</th>
      <td>bland</td>
      <td>0.000000e+00</td>
      <td>-0.003626</td>
      <td>0.003626</td>
      <td>0.003626</td>
      <td>0.362404</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003537</td>
      <td>0.003537</td>
      <td>0.003537</td>
      <td>0.365941</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>7.276069e-01</td>
      <td>-0.003427</td>
      <td>0.003427</td>
      <td>0.003427</td>
      <td>0.369369</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003399</td>
      <td>0.003399</td>
      <td>0.003399</td>
      <td>0.372768</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003313</td>
      <td>0.003313</td>
      <td>0.003313</td>
      <td>0.376081</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>0.000000e+00</td>
      <td>-0.003155</td>
      <td>0.003155</td>
      <td>0.003155</td>
      <td>0.379236</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.003096</td>
      <td>-0.003096</td>
      <td>0.003096</td>
      <td>0.376141</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003092</td>
      <td>-0.003092</td>
      <td>0.003092</td>
      <td>0.373049</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003040</td>
      <td>0.003040</td>
      <td>0.003040</td>
      <td>0.376089</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 303
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The owner used to work at Nobu, so this place is really similar for half the price.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.785 0.215]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.078524</td>
      <td>-0.078524</td>
      <td>0.078524</td>
      <td>0.420986</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-8.333333e-02</td>
      <td>0.049401</td>
      <td>-0.049401</td>
      <td>0.049401</td>
      <td>0.371585</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.027931</td>
      <td>-0.027931</td>
      <td>0.027931</td>
      <td>0.343654</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024980</td>
      <td>0.024980</td>
      <td>0.024980</td>
      <td>0.368634</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018834</td>
      <td>0.018834</td>
      <td>0.018834</td>
      <td>0.387468</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.300000e+01</td>
      <td>0.012987</td>
      <td>-0.012987</td>
      <td>0.012987</td>
      <td>0.374481</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.012248</td>
      <td>-0.012248</td>
      <td>0.012248</td>
      <td>0.362233</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009589</td>
      <td>-0.009589</td>
      <td>0.009589</td>
      <td>0.352644</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.008483</td>
      <td>0.008483</td>
      <td>0.008483</td>
      <td>0.361127</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007665</td>
      <td>-0.007665</td>
      <td>0.007665</td>
      <td>0.353461</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.947746e-38</td>
      <td>0.007281</td>
      <td>-0.007281</td>
      <td>0.007281</td>
      <td>0.346180</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006560</td>
      <td>-0.006560</td>
      <td>0.006560</td>
      <td>0.339620</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.006105</td>
      <td>-0.006105</td>
      <td>0.006105</td>
      <td>0.333515</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>2.236068e-01</td>
      <td>-0.005856</td>
      <td>0.005856</td>
      <td>0.005856</td>
      <td>0.339371</td>
    </tr>
    <tr>
      <th>1945</th>
      <td>topic 19</td>
      <td>1.169831e-01</td>
      <td>-0.005627</td>
      <td>0.005627</td>
      <td>0.005627</td>
      <td>0.344998</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005348</td>
      <td>0.005348</td>
      <td>0.005348</td>
      <td>0.350346</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.005098</td>
      <td>-0.005098</td>
      <td>0.005098</td>
      <td>0.345248</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.240989e-85</td>
      <td>0.004756</td>
      <td>-0.004756</td>
      <td>0.004756</td>
      <td>0.340492</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004230</td>
      <td>0.004230</td>
      <td>0.004230</td>
      <td>0.344721</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.236068e-01</td>
      <td>0.004166</td>
      <td>-0.004166</td>
      <td>0.004166</td>
      <td>0.340555</td>
    </tr>
    <tr>
      <th>1523</th>
      <td>the price</td>
      <td>2.236068e-01</td>
      <td>-0.004060</td>
      <td>0.004060</td>
      <td>0.004060</td>
      <td>0.344615</td>
    </tr>
    <tr>
      <th>1212</th>
      <td>price</td>
      <td>2.236068e-01</td>
      <td>-0.003722</td>
      <td>0.003722</td>
      <td>0.003722</td>
      <td>0.348337</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003674</td>
      <td>0.003674</td>
      <td>0.003674</td>
      <td>0.352011</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>9.584896e-02</td>
      <td>0.003509</td>
      <td>-0.003509</td>
      <td>0.003509</td>
      <td>0.348502</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003191</td>
      <td>0.003191</td>
      <td>0.003191</td>
      <td>0.351693</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003178</td>
      <td>0.003178</td>
      <td>0.003178</td>
      <td>0.354871</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>4.535894e-21</td>
      <td>0.003156</td>
      <td>-0.003156</td>
      <td>0.003156</td>
      <td>0.351715</td>
    </tr>
    <tr>
      <th>1438</th>
      <td>tasty</td>
      <td>0.000000e+00</td>
      <td>0.003120</td>
      <td>-0.003120</td>
      <td>0.003120</td>
      <td>0.348595</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.903615e-133</td>
      <td>-0.003027</td>
      <td>0.003027</td>
      <td>0.003027</td>
      <td>0.351622</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.002984</td>
      <td>-0.002984</td>
      <td>0.002984</td>
      <td>0.348638</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 304
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;He came running after us when he realized my husband had left his sunglasses on the table.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8475 0.1525]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084630</td>
      <td>-0.084630</td>
      <td>0.084630</td>
      <td>0.414880</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.039162</td>
      <td>-0.039162</td>
      <td>0.039162</td>
      <td>0.375718</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.032207</td>
      <td>-0.032207</td>
      <td>0.032207</td>
      <td>0.343511</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025495</td>
      <td>0.025495</td>
      <td>0.025495</td>
      <td>0.369006</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019609</td>
      <td>0.019609</td>
      <td>0.019609</td>
      <td>0.388615</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.000000e+01</td>
      <td>0.018610</td>
      <td>-0.018610</td>
      <td>0.018610</td>
      <td>0.370005</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.360198</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008596</td>
      <td>-0.008596</td>
      <td>0.008596</td>
      <td>0.351602</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.671522e-28</td>
      <td>0.007530</td>
      <td>-0.007530</td>
      <td>0.007530</td>
      <td>0.344072</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007242</td>
      <td>-0.007242</td>
      <td>0.007242</td>
      <td>0.336829</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.006898</td>
      <td>0.006898</td>
      <td>0.006898</td>
      <td>0.343728</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.337188</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005500</td>
      <td>0.005500</td>
      <td>0.005500</td>
      <td>0.342688</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.005350</td>
      <td>0.005350</td>
      <td>0.005350</td>
      <td>0.348038</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>4.514455e-203</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.343051</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004875</td>
      <td>-0.004875</td>
      <td>0.004875</td>
      <td>0.338176</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004449</td>
      <td>-0.004449</td>
      <td>0.004449</td>
      <td>0.333727</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.004432</td>
      <td>-0.004432</td>
      <td>0.004432</td>
      <td>0.329294</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004417</td>
      <td>-0.004417</td>
      <td>0.004417</td>
      <td>0.324878</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004401</td>
      <td>0.004401</td>
      <td>0.004401</td>
      <td>0.329279</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.004288</td>
      <td>0.004288</td>
      <td>0.004288</td>
      <td>0.333567</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004234</td>
      <td>-0.004234</td>
      <td>0.004234</td>
      <td>0.329333</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.004105</td>
      <td>0.004105</td>
      <td>0.004105</td>
      <td>0.333438</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.004065</td>
      <td>-0.004065</td>
      <td>0.004065</td>
      <td>0.329373</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.003935</td>
      <td>-0.003935</td>
      <td>0.003935</td>
      <td>0.325438</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003933</td>
      <td>0.003933</td>
      <td>0.003933</td>
      <td>0.329371</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003583</td>
      <td>-0.003583</td>
      <td>0.003583</td>
      <td>0.325788</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003380</td>
      <td>-0.003380</td>
      <td>0.003380</td>
      <td>0.322408</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003365</td>
      <td>-0.003365</td>
      <td>0.003365</td>
      <td>0.319042</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003364</td>
      <td>0.003364</td>
      <td>0.003364</td>
      <td>0.322406</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 311
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It&#39;s very convenient and simple to use - gets job done &amp; makes the car ride so much smoother.&#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.76 0.24]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.092201</td>
      <td>-0.092201</td>
      <td>0.092201</td>
      <td>0.407309</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.025952</td>
      <td>-0.025952</td>
      <td>0.025952</td>
      <td>0.381358</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025721</td>
      <td>0.025721</td>
      <td>0.025721</td>
      <td>0.407078</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019238</td>
      <td>0.019238</td>
      <td>0.019238</td>
      <td>0.426316</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.333333e-01</td>
      <td>0.015071</td>
      <td>-0.015071</td>
      <td>0.015071</td>
      <td>0.411245</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.300000e+01</td>
      <td>0.012884</td>
      <td>-0.012884</td>
      <td>0.012884</td>
      <td>0.398361</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.010288</td>
      <td>-0.010288</td>
      <td>0.010288</td>
      <td>0.388073</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.010009</td>
      <td>-0.010009</td>
      <td>0.010009</td>
      <td>0.378063</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>0.008987</td>
      <td>-0.008987</td>
      <td>0.008987</td>
      <td>0.369076</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007880</td>
      <td>-0.007880</td>
      <td>0.007880</td>
      <td>0.361196</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.051615e-110</td>
      <td>0.007491</td>
      <td>-0.007491</td>
      <td>0.007491</td>
      <td>0.353705</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.007345</td>
      <td>0.007345</td>
      <td>0.007345</td>
      <td>0.361050</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006714</td>
      <td>-0.006714</td>
      <td>0.006714</td>
      <td>0.354336</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>2.357023e-01</td>
      <td>-0.006182</td>
      <td>0.006182</td>
      <td>0.006182</td>
      <td>0.360518</td>
    </tr>
    <tr>
      <th>1959</th>
      <td>topic 33</td>
      <td>1.879623e-01</td>
      <td>0.005859</td>
      <td>-0.005859</td>
      <td>0.005859</td>
      <td>0.354659</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005301</td>
      <td>0.005301</td>
      <td>0.005301</td>
      <td>0.359960</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.258708e-85</td>
      <td>0.005040</td>
      <td>-0.005040</td>
      <td>0.005040</td>
      <td>0.354919</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004662</td>
      <td>-0.004662</td>
      <td>0.004662</td>
      <td>0.350257</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004049</td>
      <td>0.004049</td>
      <td>0.004049</td>
      <td>0.354307</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004047</td>
      <td>0.004047</td>
      <td>0.004047</td>
      <td>0.358354</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003930</td>
      <td>0.003930</td>
      <td>0.003930</td>
      <td>0.362284</td>
    </tr>
    <tr>
      <th>2102</th>
      <td>topic 176</td>
      <td>3.664182e-02</td>
      <td>-0.003859</td>
      <td>0.003859</td>
      <td>0.003859</td>
      <td>0.366143</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003694</td>
      <td>0.003694</td>
      <td>0.003694</td>
      <td>0.369837</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000e+00</td>
      <td>0.003466</td>
      <td>-0.003466</td>
      <td>0.003466</td>
      <td>0.366371</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003390</td>
      <td>0.003390</td>
      <td>0.003390</td>
      <td>0.369761</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.649139e-189</td>
      <td>0.003347</td>
      <td>-0.003347</td>
      <td>0.003347</td>
      <td>0.366414</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>2.556649e-108</td>
      <td>0.003340</td>
      <td>-0.003340</td>
      <td>0.003340</td>
      <td>0.363074</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.969988e-128</td>
      <td>-0.003233</td>
      <td>0.003233</td>
      <td>0.003233</td>
      <td>0.366308</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003208</td>
      <td>0.003208</td>
      <td>0.003208</td>
      <td>0.369515</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003207</td>
      <td>-0.003207</td>
      <td>0.003207</td>
      <td>0.366309</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 314
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;All in all, a great disappointment.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.465 0.535]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.096216</td>
      <td>0.096216</td>
      <td>0.096216</td>
      <td>0.595726</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.940000e-01</td>
      <td>0.056233</td>
      <td>-0.056233</td>
      <td>0.056233</td>
      <td>0.539493</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.000000e-01</td>
      <td>0.033660</td>
      <td>-0.033660</td>
      <td>0.033660</td>
      <td>0.505832</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026101</td>
      <td>0.026101</td>
      <td>0.026101</td>
      <td>0.531934</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022206</td>
      <td>0.022206</td>
      <td>0.022206</td>
      <td>0.554140</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>6.000000e+00</td>
      <td>0.021778</td>
      <td>-0.021778</td>
      <td>0.021778</td>
      <td>0.532362</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>3.333333e-01</td>
      <td>-0.015885</td>
      <td>0.015885</td>
      <td>0.015885</td>
      <td>0.548247</td>
    </tr>
    <tr>
      <th>2035</th>
      <td>topic 109</td>
      <td>4.960259e-01</td>
      <td>-0.008321</td>
      <td>0.008321</td>
      <td>0.008321</td>
      <td>0.556568</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008071</td>
      <td>-0.008071</td>
      <td>0.008071</td>
      <td>0.548497</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006437</td>
      <td>-0.006437</td>
      <td>0.006437</td>
      <td>0.542060</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.006167</td>
      <td>-0.006167</td>
      <td>0.006167</td>
      <td>0.535892</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.006004</td>
      <td>-0.006004</td>
      <td>0.006004</td>
      <td>0.529888</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.354367e-01</td>
      <td>0.005679</td>
      <td>-0.005679</td>
      <td>0.005679</td>
      <td>0.524209</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005676</td>
      <td>-0.005676</td>
      <td>0.005676</td>
      <td>0.518533</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.005516</td>
      <td>0.005516</td>
      <td>0.005516</td>
      <td>0.524049</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005194</td>
      <td>0.005194</td>
      <td>0.005194</td>
      <td>0.529243</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.429653e-306</td>
      <td>0.005046</td>
      <td>-0.005046</td>
      <td>0.005046</td>
      <td>0.524197</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004554</td>
      <td>0.004554</td>
      <td>0.004554</td>
      <td>0.528751</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003907</td>
      <td>0.003907</td>
      <td>0.003907</td>
      <td>0.532658</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003705</td>
      <td>0.003705</td>
      <td>0.003705</td>
      <td>0.536363</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>3.333333e-01</td>
      <td>-0.003469</td>
      <td>0.003469</td>
      <td>0.003469</td>
      <td>0.539833</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003459</td>
      <td>-0.003459</td>
      <td>0.003459</td>
      <td>0.536373</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003340</td>
      <td>0.003340</td>
      <td>0.003340</td>
      <td>0.539713</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003283</td>
      <td>-0.003283</td>
      <td>0.003283</td>
      <td>0.536429</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003262</td>
      <td>0.003262</td>
      <td>0.003262</td>
      <td>0.539691</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003247</td>
      <td>0.003247</td>
      <td>0.003247</td>
      <td>0.542938</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003125</td>
      <td>0.003125</td>
      <td>0.003125</td>
      <td>0.546063</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003047</td>
      <td>0.003047</td>
      <td>0.003047</td>
      <td>0.549110</td>
    </tr>
    <tr>
      <th>22</th>
      <td>all</td>
      <td>6.666667e-01</td>
      <td>-0.002951</td>
      <td>0.002951</td>
      <td>0.002951</td>
      <td>0.552061</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002950</td>
      <td>-0.002950</td>
      <td>0.002950</td>
      <td>0.549111</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 322
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Phone now holds charge like it did when it was new.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.4475 0.5525]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.166710</td>
      <td>0.166710</td>
      <td>0.166710</td>
      <td>0.666220</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.000000e-01</td>
      <td>0.074779</td>
      <td>-0.074779</td>
      <td>0.074779</td>
      <td>0.591441</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.363636e-01</td>
      <td>0.028327</td>
      <td>-0.028327</td>
      <td>0.028327</td>
      <td>0.563114</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.612000e-01</td>
      <td>-0.026621</td>
      <td>0.026621</td>
      <td>0.026621</td>
      <td>0.589735</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024233</td>
      <td>0.024233</td>
      <td>0.024233</td>
      <td>0.613968</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021049</td>
      <td>0.021049</td>
      <td>0.021049</td>
      <td>0.635017</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.018634</td>
      <td>-0.018634</td>
      <td>0.018634</td>
      <td>0.616383</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.100000e+01</td>
      <td>0.010787</td>
      <td>-0.010787</td>
      <td>0.010787</td>
      <td>0.605596</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008794</td>
      <td>-0.008794</td>
      <td>0.008794</td>
      <td>0.596802</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008770</td>
      <td>-0.008770</td>
      <td>0.008770</td>
      <td>0.588032</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.119536e-41</td>
      <td>0.007360</td>
      <td>-0.007360</td>
      <td>0.007360</td>
      <td>0.580671</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006536</td>
      <td>-0.006536</td>
      <td>0.006536</td>
      <td>0.574135</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005589</td>
      <td>-0.005589</td>
      <td>0.005589</td>
      <td>0.568546</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.077382e-197</td>
      <td>0.004806</td>
      <td>-0.004806</td>
      <td>0.004806</td>
      <td>0.563740</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004533</td>
      <td>-0.004533</td>
      <td>0.004533</td>
      <td>0.559207</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>4.850713e-01</td>
      <td>0.003644</td>
      <td>-0.003644</td>
      <td>0.003644</td>
      <td>0.555563</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003614</td>
      <td>0.003614</td>
      <td>0.003614</td>
      <td>0.559176</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003159</td>
      <td>-0.003159</td>
      <td>0.003159</td>
      <td>0.556018</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003089</td>
      <td>-0.003089</td>
      <td>0.003089</td>
      <td>0.552928</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003066</td>
      <td>0.003066</td>
      <td>0.003066</td>
      <td>0.555995</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002939</td>
      <td>0.002939</td>
      <td>0.002939</td>
      <td>0.558934</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.002828</td>
      <td>0.002828</td>
      <td>0.002828</td>
      <td>0.561762</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.956517e-211</td>
      <td>-0.002827</td>
      <td>0.002827</td>
      <td>0.002827</td>
      <td>0.564589</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002819</td>
      <td>-0.002819</td>
      <td>0.002819</td>
      <td>0.561769</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002756</td>
      <td>0.002756</td>
      <td>0.002756</td>
      <td>0.564526</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002695</td>
      <td>-0.002695</td>
      <td>0.002695</td>
      <td>0.561830</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002694</td>
      <td>-0.002694</td>
      <td>0.002694</td>
      <td>0.559136</td>
    </tr>
    <tr>
      <th>798</th>
      <td>it did</td>
      <td>2.425356e-01</td>
      <td>0.002679</td>
      <td>-0.002679</td>
      <td>0.002679</td>
      <td>0.556457</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002596</td>
      <td>0.002596</td>
      <td>0.002596</td>
      <td>0.559053</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002564</td>
      <td>0.002564</td>
      <td>0.002564</td>
      <td>0.561617</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 328
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;You get extra minutes so that you can carry out the call and not get cut off.&#34;&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9 0.1]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.134272</td>
      <td>-0.134272</td>
      <td>0.134272</td>
      <td>0.365238</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.020000e-01</td>
      <td>0.053782</td>
      <td>-0.053782</td>
      <td>0.053782</td>
      <td>0.311455</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.043390</td>
      <td>-0.043390</td>
      <td>0.043390</td>
      <td>0.268065</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.028054</td>
      <td>-0.028054</td>
      <td>0.028054</td>
      <td>0.240011</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.013196</td>
      <td>-0.013196</td>
      <td>0.013196</td>
      <td>0.226815</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>2.000000e-01</td>
      <td>-0.009712</td>
      <td>0.009712</td>
      <td>0.009712</td>
      <td>0.236527</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>2.057000e-01</td>
      <td>-0.008793</td>
      <td>0.008793</td>
      <td>0.008793</td>
      <td>0.245320</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008209</td>
      <td>-0.008209</td>
      <td>0.008209</td>
      <td>0.237111</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006714</td>
      <td>-0.006714</td>
      <td>0.006714</td>
      <td>0.230397</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006088</td>
      <td>-0.006088</td>
      <td>0.006088</td>
      <td>0.224309</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.005500</td>
      <td>-0.005500</td>
      <td>0.005500</td>
      <td>0.218809</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>4.000000e-01</td>
      <td>-0.004063</td>
      <td>0.004063</td>
      <td>0.004063</td>
      <td>0.222872</td>
    </tr>
    <tr>
      <th>1082</th>
      <td>off</td>
      <td>2.000000e-01</td>
      <td>0.004044</td>
      <td>-0.004044</td>
      <td>0.004044</td>
      <td>0.218828</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.066951e-281</td>
      <td>0.003631</td>
      <td>-0.003631</td>
      <td>0.003631</td>
      <td>0.215196</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>7.800000e+01</td>
      <td>0.003505</td>
      <td>-0.003505</td>
      <td>0.003505</td>
      <td>0.211691</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.003402</td>
      <td>-0.003402</td>
      <td>0.003402</td>
      <td>0.208289</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003185</td>
      <td>0.003185</td>
      <td>0.003185</td>
      <td>0.211474</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>2.000000e-01</td>
      <td>0.003010</td>
      <td>-0.003010</td>
      <td>0.003010</td>
      <td>0.208464</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002994</td>
      <td>0.002994</td>
      <td>0.002994</td>
      <td>0.211458</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002942</td>
      <td>-0.002942</td>
      <td>0.002942</td>
      <td>0.208515</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002882</td>
      <td>-0.002882</td>
      <td>0.002882</td>
      <td>0.205634</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002643</td>
      <td>-0.002643</td>
      <td>0.002643</td>
      <td>0.202990</td>
    </tr>
    <tr>
      <th>2088</th>
      <td>topic 162</td>
      <td>5.393072e-03</td>
      <td>0.002620</td>
      <td>-0.002620</td>
      <td>0.002620</td>
      <td>0.200370</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002601</td>
      <td>0.002601</td>
      <td>0.002601</td>
      <td>0.202972</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002586</td>
      <td>0.002586</td>
      <td>0.002586</td>
      <td>0.205557</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>3.596926e-263</td>
      <td>0.002525</td>
      <td>-0.002525</td>
      <td>0.002525</td>
      <td>0.203032</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002364</td>
      <td>-0.002364</td>
      <td>0.002364</td>
      <td>0.200669</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.002344</td>
      <td>-0.002344</td>
      <td>0.002344</td>
      <td>0.198325</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002297</td>
      <td>0.002297</td>
      <td>0.002297</td>
      <td>0.200621</td>
    </tr>
    <tr>
      <th>1957</th>
      <td>topic 31</td>
      <td>5.970050e-04</td>
      <td>-0.002152</td>
      <td>0.002152</td>
      <td>0.002152</td>
      <td>0.202773</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 332
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Clear Skype Calls, Long Battery Life, Long Range.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.5225 0.4775]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.102178</td>
      <td>0.102178</td>
      <td>0.102178</td>
      <td>0.601688</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.710000e-01</td>
      <td>0.069593</td>
      <td>-0.069593</td>
      <td>0.069593</td>
      <td>0.532095</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.625929e-18</td>
      <td>0.038985</td>
      <td>-0.038985</td>
      <td>0.038985</td>
      <td>0.493110</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.818000e-01</td>
      <td>-0.030547</td>
      <td>0.030547</td>
      <td>0.030547</td>
      <td>0.523657</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>8.000000e+00</td>
      <td>0.029270</td>
      <td>-0.029270</td>
      <td>0.029270</td>
      <td>0.494387</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025798</td>
      <td>0.025798</td>
      <td>0.025798</td>
      <td>0.520185</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.023143</td>
      <td>-0.023143</td>
      <td>0.023143</td>
      <td>0.497042</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022397</td>
      <td>0.022397</td>
      <td>0.022397</td>
      <td>0.519439</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009715</td>
      <td>-0.009715</td>
      <td>0.009715</td>
      <td>0.509724</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008768</td>
      <td>-0.008768</td>
      <td>0.008768</td>
      <td>0.500956</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.774813e-185</td>
      <td>0.007901</td>
      <td>-0.007901</td>
      <td>0.007901</td>
      <td>0.493055</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006741</td>
      <td>-0.006741</td>
      <td>0.006741</td>
      <td>0.486314</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.006398</td>
      <td>-0.006398</td>
      <td>0.006398</td>
      <td>0.479916</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.006029</td>
      <td>-0.006029</td>
      <td>0.006029</td>
      <td>0.473886</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005631</td>
      <td>-0.005631</td>
      <td>0.005631</td>
      <td>0.468256</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>9.368799e-210</td>
      <td>0.005262</td>
      <td>-0.005262</td>
      <td>0.005262</td>
      <td>0.462994</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>1.249283e-01</td>
      <td>-0.005189</td>
      <td>0.005189</td>
      <td>0.005189</td>
      <td>0.468183</td>
    </tr>
    <tr>
      <th>1946</th>
      <td>topic 20</td>
      <td>1.730253e-01</td>
      <td>-0.004540</td>
      <td>0.004540</td>
      <td>0.004540</td>
      <td>0.472723</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004071</td>
      <td>0.004071</td>
      <td>0.004071</td>
      <td>0.476794</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003988</td>
      <td>0.003988</td>
      <td>0.003988</td>
      <td>0.480782</td>
    </tr>
    <tr>
      <th>1237</th>
      <td>range</td>
      <td>3.162278e-01</td>
      <td>-0.003965</td>
      <td>0.003965</td>
      <td>0.003965</td>
      <td>0.484746</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003772</td>
      <td>0.003772</td>
      <td>0.003772</td>
      <td>0.488518</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003646</td>
      <td>0.003646</td>
      <td>0.003646</td>
      <td>0.492164</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003249</td>
      <td>0.003249</td>
      <td>0.003249</td>
      <td>0.495413</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003201</td>
      <td>0.003201</td>
      <td>0.003201</td>
      <td>0.498614</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.875756e-230</td>
      <td>-0.003077</td>
      <td>0.003077</td>
      <td>0.003077</td>
      <td>0.501691</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003064</td>
      <td>0.003064</td>
      <td>0.003064</td>
      <td>0.504756</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003051</td>
      <td>0.003051</td>
      <td>0.003051</td>
      <td>0.507807</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>6.114076e-198</td>
      <td>0.003005</td>
      <td>-0.003005</td>
      <td>0.003005</td>
      <td>0.504802</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002944</td>
      <td>0.002944</td>
      <td>0.002944</td>
      <td>0.507746</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 345
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Logitech Bluetooth Headset is a 10!.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7025 0.2975]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085468</td>
      <td>-0.085468</td>
      <td>0.085468</td>
      <td>0.414041</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>-0.029531</td>
      <td>0.029531</td>
      <td>0.029531</td>
      <td>0.443573</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.027889</td>
      <td>-0.027889</td>
      <td>0.027889</td>
      <td>0.415683</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>6.000000e+00</td>
      <td>0.027662</td>
      <td>-0.027662</td>
      <td>0.027662</td>
      <td>0.388022</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.025209</td>
      <td>0.025209</td>
      <td>0.025209</td>
      <td>0.413231</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025194</td>
      <td>0.025194</td>
      <td>0.025194</td>
      <td>0.438425</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018928</td>
      <td>0.018928</td>
      <td>0.018928</td>
      <td>0.457354</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009851</td>
      <td>-0.009851</td>
      <td>0.009851</td>
      <td>0.447503</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007753</td>
      <td>-0.007753</td>
      <td>0.007753</td>
      <td>0.439750</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.600000e+01</td>
      <td>-0.007728</td>
      <td>0.007728</td>
      <td>0.007728</td>
      <td>0.447478</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.061442e-123</td>
      <td>0.007453</td>
      <td>-0.007453</td>
      <td>0.007453</td>
      <td>0.440024</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.007437</td>
      <td>-0.007437</td>
      <td>0.007437</td>
      <td>0.432587</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006562</td>
      <td>-0.006562</td>
      <td>0.006562</td>
      <td>0.426025</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>4.472136e-01</td>
      <td>0.006361</td>
      <td>-0.006361</td>
      <td>0.006361</td>
      <td>0.419665</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005560</td>
      <td>0.005560</td>
      <td>0.005560</td>
      <td>0.425225</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.005297</td>
      <td>-0.005297</td>
      <td>0.005297</td>
      <td>0.419928</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.692503e-237</td>
      <td>0.004954</td>
      <td>-0.004954</td>
      <td>0.004954</td>
      <td>0.414974</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>-0.004745</td>
      <td>0.004745</td>
      <td>0.004745</td>
      <td>0.419720</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004635</td>
      <td>0.004635</td>
      <td>0.004635</td>
      <td>0.424354</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.004438</td>
      <td>-0.004438</td>
      <td>0.004438</td>
      <td>0.419916</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003873</td>
      <td>-0.003873</td>
      <td>0.003873</td>
      <td>0.416043</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003653</td>
      <td>-0.003653</td>
      <td>0.003653</td>
      <td>0.412390</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>this place</td>
      <td>0.000000e+00</td>
      <td>0.003649</td>
      <td>-0.003649</td>
      <td>0.003649</td>
      <td>0.408741</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003615</td>
      <td>0.003615</td>
      <td>0.003615</td>
      <td>0.412356</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003512</td>
      <td>0.003512</td>
      <td>0.003512</td>
      <td>0.415869</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003280</td>
      <td>0.003280</td>
      <td>0.003280</td>
      <td>0.419149</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003193</td>
      <td>0.003193</td>
      <td>0.003193</td>
      <td>0.422341</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003188</td>
      <td>0.003188</td>
      <td>0.003188</td>
      <td>0.425529</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003127</td>
      <td>-0.003127</td>
      <td>0.003127</td>
      <td>0.422402</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003088</td>
      <td>0.003088</td>
      <td>0.003088</td>
      <td>0.425490</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 348
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Light weight, I hardly notice it is there.&#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (trainset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8525 0.1475]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[252]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.074499</td>
      <td>-0.074499</td>
      <td>0.074499</td>
      <td>0.425011</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000</td>
      <td>0.052531</td>
      <td>-0.052531</td>
      <td>0.052531</td>
      <td>0.372481</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.054167</td>
      <td>0.024441</td>
      <td>-0.024441</td>
      <td>0.024441</td>
      <td>0.348039</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000</td>
      <td>0.020328</td>
      <td>-0.020328</td>
      <td>0.020328</td>
      <td>0.327711</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.018378</td>
      <td>0.018378</td>
      <td>0.018378</td>
      <td>0.346090</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000</td>
      <td>0.012584</td>
      <td>-0.012584</td>
      <td>0.012584</td>
      <td>0.333506</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>42.000000</td>
      <td>0.012088</td>
      <td>-0.012088</td>
      <td>0.012088</td>
      <td>0.321418</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>topic 82</td>
      <td>0.012117</td>
      <td>-0.011730</td>
      <td>0.011730</td>
      <td>0.011730</td>
      <td>0.333148</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000</td>
      <td>0.009099</td>
      <td>-0.009099</td>
      <td>0.009099</td>
      <td>0.324049</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.008442</td>
      <td>-0.008442</td>
      <td>0.008442</td>
      <td>0.315607</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007117</td>
      <td>-0.007117</td>
      <td>0.007117</td>
      <td>0.308490</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.007061</td>
      <td>-0.007061</td>
      <td>0.007061</td>
      <td>0.301429</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.447214</td>
      <td>0.006541</td>
      <td>-0.006541</td>
      <td>0.006541</td>
      <td>0.294888</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.005555</td>
      <td>-0.005555</td>
      <td>0.005555</td>
      <td>0.289333</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.447214</td>
      <td>0.004934</td>
      <td>-0.004934</td>
      <td>0.004934</td>
      <td>0.284399</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000</td>
      <td>-0.004876</td>
      <td>0.004876</td>
      <td>0.004876</td>
      <td>0.289274</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004405</td>
      <td>-0.004405</td>
      <td>0.004405</td>
      <td>0.284869</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000</td>
      <td>0.004339</td>
      <td>-0.004339</td>
      <td>0.004339</td>
      <td>0.280530</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000</td>
      <td>0.004143</td>
      <td>-0.004143</td>
      <td>0.004143</td>
      <td>0.276388</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003747</td>
      <td>0.003747</td>
      <td>0.003747</td>
      <td>0.280134</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.003030</td>
      <td>0.003030</td>
      <td>0.003030</td>
      <td>0.283164</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.002958</td>
      <td>-0.002958</td>
      <td>0.002958</td>
      <td>0.280206</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000</td>
      <td>0.002852</td>
      <td>-0.002852</td>
      <td>0.002852</td>
      <td>0.277354</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.002808</td>
      <td>0.002808</td>
      <td>0.002808</td>
      <td>0.280162</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.002801</td>
      <td>0.002801</td>
      <td>0.002801</td>
      <td>0.282963</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.002739</td>
      <td>-0.002739</td>
      <td>0.002739</td>
      <td>0.280224</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.002693</td>
      <td>0.002693</td>
      <td>0.002693</td>
      <td>0.282917</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.002491</td>
      <td>0.002491</td>
      <td>0.002491</td>
      <td>0.285408</td>
    </tr>
    <tr>
      <th>294</th>
      <td>charged</td>
      <td>0.000000</td>
      <td>0.002490</td>
      <td>-0.002490</td>
      <td>0.002490</td>
      <td>0.282918</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002437</td>
      <td>0.002437</td>
      <td>0.002437</td>
      <td>0.285355</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Further-exploration-on-Sentiment_Test-Data">Further exploration on Sentiment_Test Data<a class="anchor-link" href="#Further-exploration-on-Sentiment_Test-Data">&#182;</a></h1><h1 id="Support-Q2-Task-3-Response">Support Q2 Task 3 Response<a class="anchor-link" href="#Support-Q2-Task-3-Response">&#182;</a></h1><p>Explain all predictions that were incorrect of a tree-based model.</p>
<p>Note: this only works on tree-based models, like RF, ET. This cell will crash when using, e.g., MLPClassifier</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[253]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Decompose the predictions into the bias term (which is just the testset mean) and individual feature contributions,</span>
<span class="c1"># in order to understand which features contributed to the difference and by how much.</span>

<span class="k">if</span>  <span class="n">feature_importances</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No Feature importances! Skipping.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>

    <span class="kn">from</span> <span class="nn">treeinterpreter</span> <span class="kn">import</span> <span class="n">treeinterpreter</span> <span class="k">as</span> <span class="n">ti</span>

    <span class="n">prediction</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">contributions</span> <span class="o">=</span> <span class="n">ti</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clf_obj</span><span class="p">,</span> <span class="n">features_test</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">features_test</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">pred_test</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Instance </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="n">test_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">Sentence</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bias (testset mean) </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Truth </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prediction</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature contributions:&quot;</span><span class="p">)</span>
        <span class="n">con</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span>
                                 <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">features_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">A1</span><span class="p">,</span>
                                 <span class="s1">&#39;neg contr&#39;</span><span class="p">:</span> <span class="n">contributions</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span>
                                 <span class="s1">&#39;pos contr&#39;</span><span class="p">:</span> <span class="n">contributions</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
                                 <span class="s1">&#39;abs contr&#39;</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">contributions</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">])})</span>
        <span class="n">con</span> <span class="o">=</span> <span class="n">con</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;abs contr&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">con</span><span class="p">[</span><span class="s1">&#39;pos cumulative&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">con</span><span class="p">[</span><span class="s1">&#39;pos contr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span> <span class="o">+</span> <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">con</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Instance 12
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Not too screamy not to masculine but just right.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8525 0.1475]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.070344</td>
      <td>-0.070344</td>
      <td>0.070344</td>
      <td>0.429166</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.043360</td>
      <td>-0.043360</td>
      <td>0.043360</td>
      <td>0.385807</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000e+00</td>
      <td>0.023045</td>
      <td>-0.023045</td>
      <td>0.023045</td>
      <td>0.362761</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.000000e+01</td>
      <td>0.012180</td>
      <td>-0.012180</td>
      <td>0.012180</td>
      <td>0.350581</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.928571e-01</td>
      <td>0.010566</td>
      <td>-0.010566</td>
      <td>0.010566</td>
      <td>0.340015</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>6.324555e-01</td>
      <td>0.008991</td>
      <td>-0.008991</td>
      <td>0.008991</td>
      <td>0.331025</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.008668</td>
      <td>-0.008668</td>
      <td>0.008668</td>
      <td>0.322357</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.008134</td>
      <td>-0.008134</td>
      <td>0.008134</td>
      <td>0.314223</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008064</td>
      <td>-0.008064</td>
      <td>0.008064</td>
      <td>0.306159</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007379</td>
      <td>-0.007379</td>
      <td>0.007379</td>
      <td>0.298780</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007061</td>
      <td>-0.007061</td>
      <td>0.007061</td>
      <td>0.291719</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.581010e-322</td>
      <td>0.006770</td>
      <td>-0.006770</td>
      <td>0.006770</td>
      <td>0.284949</td>
    </tr>
    <tr>
      <th>1940</th>
      <td>topic 14</td>
      <td>2.196992e-01</td>
      <td>-0.006357</td>
      <td>0.006357</td>
      <td>0.006357</td>
      <td>0.291307</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005100</td>
      <td>-0.005100</td>
      <td>0.005100</td>
      <td>0.286206</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004419</td>
      <td>-0.004419</td>
      <td>0.004419</td>
      <td>0.281787</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.317078e-221</td>
      <td>0.004200</td>
      <td>-0.004200</td>
      <td>0.004200</td>
      <td>0.277587</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003839</td>
      <td>0.003839</td>
      <td>0.003839</td>
      <td>0.281426</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002879</td>
      <td>-0.002879</td>
      <td>0.002879</td>
      <td>0.278547</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002732</td>
      <td>0.002732</td>
      <td>0.002732</td>
      <td>0.281279</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002689</td>
      <td>0.002689</td>
      <td>0.002689</td>
      <td>0.283968</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002685</td>
      <td>0.002685</td>
      <td>0.002685</td>
      <td>0.286653</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002617</td>
      <td>-0.002617</td>
      <td>0.002617</td>
      <td>0.284036</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002575</td>
      <td>0.002575</td>
      <td>0.002575</td>
      <td>0.286611</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>0.000000e+00</td>
      <td>0.002568</td>
      <td>-0.002568</td>
      <td>0.002568</td>
      <td>0.284043</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002544</td>
      <td>0.002544</td>
      <td>0.002544</td>
      <td>0.286588</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002501</td>
      <td>-0.002501</td>
      <td>0.002501</td>
      <td>0.284086</td>
    </tr>
    <tr>
      <th>294</th>
      <td>charged</td>
      <td>0.000000e+00</td>
      <td>0.002490</td>
      <td>-0.002490</td>
      <td>0.002490</td>
      <td>0.281596</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002450</td>
      <td>0.002450</td>
      <td>0.002450</td>
      <td>0.284046</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>3.162278e-01</td>
      <td>0.002411</td>
      <td>-0.002411</td>
      <td>0.002411</td>
      <td>0.281635</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002387</td>
      <td>0.002387</td>
      <td>0.002387</td>
      <td>0.284022</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 36
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;The soundtrack wasn&#39;t terrible, either.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.885 0.115]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-3.000000</td>
      <td>0.147218</td>
      <td>-0.147218</td>
      <td>0.147218</td>
      <td>0.352292</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.000000</td>
      <td>0.119918</td>
      <td>-0.119918</td>
      <td>0.119918</td>
      <td>0.232374</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.390000</td>
      <td>0.035337</td>
      <td>-0.035337</td>
      <td>0.035337</td>
      <td>0.197037</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.372400</td>
      <td>-0.026430</td>
      <td>0.026430</td>
      <td>0.026430</td>
      <td>0.223467</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.022410</td>
      <td>0.022410</td>
      <td>0.022410</td>
      <td>0.245877</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.007850</td>
      <td>-0.007850</td>
      <td>0.007850</td>
      <td>0.238027</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.007737</td>
      <td>-0.007737</td>
      <td>0.007737</td>
      <td>0.230290</td>
    </tr>
    <tr>
      <th>1444</th>
      <td>terrible</td>
      <td>0.447214</td>
      <td>0.007666</td>
      <td>-0.007666</td>
      <td>0.007666</td>
      <td>0.222624</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.005620</td>
      <td>-0.005620</td>
      <td>0.005620</td>
      <td>0.217004</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.005180</td>
      <td>-0.005180</td>
      <td>0.005180</td>
      <td>0.211824</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>41.000000</td>
      <td>0.004487</td>
      <td>-0.004487</td>
      <td>0.004487</td>
      <td>0.207337</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.003705</td>
      <td>-0.003705</td>
      <td>0.003705</td>
      <td>0.203632</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000</td>
      <td>0.003078</td>
      <td>-0.003078</td>
      <td>0.003078</td>
      <td>0.200554</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003054</td>
      <td>0.003054</td>
      <td>0.003054</td>
      <td>0.203608</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.003007</td>
      <td>0.003007</td>
      <td>0.003007</td>
      <td>0.206615</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.002967</td>
      <td>-0.002967</td>
      <td>0.002967</td>
      <td>0.203647</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000</td>
      <td>0.002899</td>
      <td>-0.002899</td>
      <td>0.002899</td>
      <td>0.200748</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.447214</td>
      <td>0.002864</td>
      <td>-0.002864</td>
      <td>0.002864</td>
      <td>0.197885</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000</td>
      <td>0.002748</td>
      <td>-0.002748</td>
      <td>0.002748</td>
      <td>0.195137</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000</td>
      <td>0.002647</td>
      <td>-0.002647</td>
      <td>0.002647</td>
      <td>0.192490</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>0.000000</td>
      <td>0.002476</td>
      <td>-0.002476</td>
      <td>0.002476</td>
      <td>0.190014</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000</td>
      <td>-0.002411</td>
      <td>0.002411</td>
      <td>0.002411</td>
      <td>0.192425</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000</td>
      <td>0.002313</td>
      <td>-0.002313</td>
      <td>0.002313</td>
      <td>0.190112</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002170</td>
      <td>0.002170</td>
      <td>0.002170</td>
      <td>0.192282</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000</td>
      <td>0.002124</td>
      <td>-0.002124</td>
      <td>0.002124</td>
      <td>0.190157</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.002115</td>
      <td>0.002115</td>
      <td>0.002115</td>
      <td>0.192273</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000</td>
      <td>0.002054</td>
      <td>-0.002054</td>
      <td>0.002054</td>
      <td>0.190219</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000</td>
      <td>-0.002041</td>
      <td>0.002041</td>
      <td>0.002041</td>
      <td>0.192260</td>
    </tr>
    <tr>
      <th>1962</th>
      <td>topic 36</td>
      <td>0.451870</td>
      <td>0.001951</td>
      <td>-0.001951</td>
      <td>0.001951</td>
      <td>0.190309</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000</td>
      <td>0.001950</td>
      <td>-0.001950</td>
      <td>0.001950</td>
      <td>0.188359</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 38
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Still, it was the SETS that got a big &#34;10&#34; on my &#34;oy-vey&#34; scale.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.6225 0.3775]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.122146</td>
      <td>0.122146</td>
      <td>0.122146</td>
      <td>0.621656</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.088364</td>
      <td>-0.088364</td>
      <td>0.088364</td>
      <td>0.533292</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.035479</td>
      <td>-0.035479</td>
      <td>0.035479</td>
      <td>0.497813</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.400000e+01</td>
      <td>0.033605</td>
      <td>-0.033605</td>
      <td>0.033605</td>
      <td>0.464208</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025124</td>
      <td>0.025124</td>
      <td>0.025124</td>
      <td>0.489332</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022507</td>
      <td>0.022507</td>
      <td>0.022507</td>
      <td>0.511839</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.020141</td>
      <td>-0.020141</td>
      <td>0.020141</td>
      <td>0.491698</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>0.015610</td>
      <td>-0.015610</td>
      <td>0.015610</td>
      <td>0.476088</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009619</td>
      <td>-0.009619</td>
      <td>0.009619</td>
      <td>0.466469</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008007</td>
      <td>-0.008007</td>
      <td>0.008007</td>
      <td>0.458462</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007648</td>
      <td>-0.007648</td>
      <td>0.007648</td>
      <td>0.450814</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005991</td>
      <td>-0.005991</td>
      <td>0.005991</td>
      <td>0.444823</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005977</td>
      <td>-0.005977</td>
      <td>0.005977</td>
      <td>0.438846</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>7.000000e+00</td>
      <td>-0.005595</td>
      <td>0.005595</td>
      <td>0.005595</td>
      <td>0.444441</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005331</td>
      <td>0.005331</td>
      <td>0.005331</td>
      <td>0.449772</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004827</td>
      <td>-0.004827</td>
      <td>0.004827</td>
      <td>0.444945</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004675</td>
      <td>0.004675</td>
      <td>0.004675</td>
      <td>0.449620</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004244</td>
      <td>0.004244</td>
      <td>0.004244</td>
      <td>0.453864</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003966</td>
      <td>-0.003966</td>
      <td>0.003966</td>
      <td>0.449898</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003411</td>
      <td>-0.003411</td>
      <td>0.003411</td>
      <td>0.446487</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003314</td>
      <td>-0.003314</td>
      <td>0.003314</td>
      <td>0.443173</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.704199e-191</td>
      <td>-0.003112</td>
      <td>0.003112</td>
      <td>0.003112</td>
      <td>0.446285</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003067</td>
      <td>0.003067</td>
      <td>0.003067</td>
      <td>0.449352</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002960</td>
      <td>0.002960</td>
      <td>0.002960</td>
      <td>0.452312</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.915640e-275</td>
      <td>0.002910</td>
      <td>-0.002910</td>
      <td>0.002910</td>
      <td>0.449402</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002884</td>
      <td>0.002884</td>
      <td>0.002884</td>
      <td>0.452286</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002831</td>
      <td>0.002831</td>
      <td>0.002831</td>
      <td>0.455117</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002821</td>
      <td>0.002821</td>
      <td>0.002821</td>
      <td>0.457938</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002754</td>
      <td>-0.002754</td>
      <td>0.002754</td>
      <td>0.455185</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002655</td>
      <td>0.002655</td>
      <td>0.002655</td>
      <td>0.457840</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 43
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The last 15 minutes of movie are also not bad as well.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8725 0.1275]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-3.000000e+00</td>
      <td>0.151700</td>
      <td>-0.151700</td>
      <td>0.151700</td>
      <td>0.347810</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.940000e-01</td>
      <td>0.048324</td>
      <td>-0.048324</td>
      <td>0.048324</td>
      <td>0.299486</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.035476</td>
      <td>-0.035476</td>
      <td>0.035476</td>
      <td>0.264010</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>2.584000e-01</td>
      <td>-0.014589</td>
      <td>0.014589</td>
      <td>0.014589</td>
      <td>0.278598</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.081653e-01</td>
      <td>0.014322</td>
      <td>-0.014322</td>
      <td>0.014322</td>
      <td>0.264276</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.750000e-01</td>
      <td>0.011731</td>
      <td>-0.011731</td>
      <td>0.011731</td>
      <td>0.252545</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.600000e+01</td>
      <td>0.008016</td>
      <td>-0.008016</td>
      <td>0.008016</td>
      <td>0.244529</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007524</td>
      <td>-0.007524</td>
      <td>0.007524</td>
      <td>0.237004</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006239</td>
      <td>-0.006239</td>
      <td>0.006239</td>
      <td>0.230765</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006136</td>
      <td>-0.006136</td>
      <td>0.006136</td>
      <td>0.224629</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005703</td>
      <td>-0.005703</td>
      <td>0.005703</td>
      <td>0.218926</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.005513</td>
      <td>-0.005513</td>
      <td>0.005513</td>
      <td>0.213414</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>3.162278e-01</td>
      <td>-0.005422</td>
      <td>0.005422</td>
      <td>0.005422</td>
      <td>0.218836</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004287</td>
      <td>-0.004287</td>
      <td>0.004287</td>
      <td>0.214549</td>
    </tr>
    <tr>
      <th>28</th>
      <td>all the</td>
      <td>0.000000e+00</td>
      <td>0.003756</td>
      <td>-0.003756</td>
      <td>0.003756</td>
      <td>0.210792</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.003577</td>
      <td>-0.003577</td>
      <td>0.003577</td>
      <td>0.207215</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003307</td>
      <td>0.003307</td>
      <td>0.003307</td>
      <td>0.210522</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.063648e-191</td>
      <td>0.003212</td>
      <td>-0.003212</td>
      <td>0.003212</td>
      <td>0.207310</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003210</td>
      <td>-0.003210</td>
      <td>0.003210</td>
      <td>0.204100</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002920</td>
      <td>0.002920</td>
      <td>0.002920</td>
      <td>0.207020</td>
    </tr>
    <tr>
      <th>635</th>
      <td>had</td>
      <td>0.000000e+00</td>
      <td>-0.002918</td>
      <td>0.002918</td>
      <td>0.002918</td>
      <td>0.209939</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002748</td>
      <td>-0.002748</td>
      <td>0.002748</td>
      <td>0.207191</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002742</td>
      <td>0.002742</td>
      <td>0.002742</td>
      <td>0.209933</td>
    </tr>
    <tr>
      <th>1618</th>
      <td>time</td>
      <td>0.000000e+00</td>
      <td>0.002707</td>
      <td>-0.002707</td>
      <td>0.002707</td>
      <td>0.207226</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002681</td>
      <td>-0.002681</td>
      <td>0.002681</td>
      <td>0.204544</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>5.552848e-12</td>
      <td>0.002389</td>
      <td>-0.002389</td>
      <td>0.002389</td>
      <td>0.202155</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002328</td>
      <td>-0.002328</td>
      <td>0.002328</td>
      <td>0.199827</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002286</td>
      <td>-0.002286</td>
      <td>0.002286</td>
      <td>0.197541</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002224</td>
      <td>-0.002224</td>
      <td>0.002224</td>
      <td>0.195317</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002166</td>
      <td>0.002166</td>
      <td>0.002166</td>
      <td>0.197483</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 48
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;My 8/10 score is mostly for the plot.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.6775 0.3225]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.088209</td>
      <td>-0.088209</td>
      <td>0.088209</td>
      <td>0.411300</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.500000</td>
      <td>-0.042059</td>
      <td>0.042059</td>
      <td>0.042059</td>
      <td>0.453359</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025051</td>
      <td>0.025051</td>
      <td>0.025051</td>
      <td>0.478411</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.019611</td>
      <td>0.019611</td>
      <td>0.019611</td>
      <td>0.498022</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000</td>
      <td>0.016402</td>
      <td>-0.016402</td>
      <td>0.016402</td>
      <td>0.481620</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000</td>
      <td>0.016318</td>
      <td>-0.016318</td>
      <td>0.016318</td>
      <td>0.465302</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000</td>
      <td>0.010589</td>
      <td>-0.010589</td>
      <td>0.010589</td>
      <td>0.454713</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.010043</td>
      <td>-0.010043</td>
      <td>0.010043</td>
      <td>0.444670</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.008605</td>
      <td>-0.008605</td>
      <td>0.008605</td>
      <td>0.436064</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007940</td>
      <td>-0.007940</td>
      <td>0.007940</td>
      <td>0.428125</td>
    </tr>
    <tr>
      <th>2048</th>
      <td>topic 122</td>
      <td>0.608606</td>
      <td>0.006993</td>
      <td>-0.006993</td>
      <td>0.006993</td>
      <td>0.421132</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006538</td>
      <td>-0.006538</td>
      <td>0.006538</td>
      <td>0.414594</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.377964</td>
      <td>0.005779</td>
      <td>-0.005779</td>
      <td>0.005779</td>
      <td>0.408815</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.005419</td>
      <td>-0.005419</td>
      <td>0.005419</td>
      <td>0.403396</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.005325</td>
      <td>0.005325</td>
      <td>0.005325</td>
      <td>0.408721</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000</td>
      <td>0.004876</td>
      <td>-0.004876</td>
      <td>0.004876</td>
      <td>0.403845</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000</td>
      <td>-0.004341</td>
      <td>0.004341</td>
      <td>0.004341</td>
      <td>0.408187</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000</td>
      <td>-0.004330</td>
      <td>0.004330</td>
      <td>0.004330</td>
      <td>0.412517</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.004247</td>
      <td>0.004247</td>
      <td>0.004247</td>
      <td>0.416764</td>
    </tr>
    <tr>
      <th>2080</th>
      <td>topic 154</td>
      <td>0.000000</td>
      <td>0.004234</td>
      <td>-0.004234</td>
      <td>0.004234</td>
      <td>0.412531</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.004173</td>
      <td>0.004173</td>
      <td>0.004173</td>
      <td>0.416703</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.004100</td>
      <td>0.004100</td>
      <td>0.004100</td>
      <td>0.420803</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000</td>
      <td>0.003727</td>
      <td>-0.003727</td>
      <td>0.003727</td>
      <td>0.417076</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003717</td>
      <td>0.003717</td>
      <td>0.003717</td>
      <td>0.420793</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000</td>
      <td>0.003293</td>
      <td>-0.003293</td>
      <td>0.003293</td>
      <td>0.417500</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.003205</td>
      <td>0.003205</td>
      <td>0.003205</td>
      <td>0.420705</td>
    </tr>
    <tr>
      <th>1806</th>
      <td>we were</td>
      <td>0.000000</td>
      <td>0.003169</td>
      <td>-0.003169</td>
      <td>0.003169</td>
      <td>0.417536</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000</td>
      <td>0.003128</td>
      <td>-0.003128</td>
      <td>0.003128</td>
      <td>0.414408</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.003120</td>
      <td>-0.003120</td>
      <td>0.003120</td>
      <td>0.411288</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000</td>
      <td>-0.003065</td>
      <td>0.003065</td>
      <td>0.003065</td>
      <td>0.414352</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 49
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;I won&#39;t say any more - I don&#39;t like spoilers, so I don&#39;t want to be one, but I believe this film is worth your time.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.415 0.585]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>8.000000e+00</td>
      <td>-0.165628</td>
      <td>0.165628</td>
      <td>0.165628</td>
      <td>0.665138</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.010000e-01</td>
      <td>0.072536</td>
      <td>-0.072536</td>
      <td>0.072536</td>
      <td>0.592602</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024311</td>
      <td>0.024311</td>
      <td>0.024311</td>
      <td>0.616913</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.019997</td>
      <td>-0.019997</td>
      <td>0.019997</td>
      <td>0.596916</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.000000e-01</td>
      <td>-0.019510</td>
      <td>0.019510</td>
      <td>0.019510</td>
      <td>0.616427</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>1.042000e-01</td>
      <td>0.018014</td>
      <td>-0.018014</td>
      <td>0.018014</td>
      <td>0.598413</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007963</td>
      <td>-0.007963</td>
      <td>0.007963</td>
      <td>0.590450</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007563</td>
      <td>-0.007563</td>
      <td>0.007563</td>
      <td>0.582887</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.272786e-79</td>
      <td>0.007538</td>
      <td>-0.007538</td>
      <td>0.007538</td>
      <td>0.575348</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005717</td>
      <td>-0.005717</td>
      <td>0.005717</td>
      <td>0.569631</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.180000e+02</td>
      <td>-0.005097</td>
      <td>0.005097</td>
      <td>0.005097</td>
      <td>0.574728</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.496741e-217</td>
      <td>0.005082</td>
      <td>-0.005082</td>
      <td>0.005082</td>
      <td>0.569646</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004881</td>
      <td>0.004881</td>
      <td>0.004881</td>
      <td>0.574527</td>
    </tr>
    <tr>
      <th>2020</th>
      <td>topic 94</td>
      <td>2.029388e-01</td>
      <td>-0.004589</td>
      <td>0.004589</td>
      <td>0.004589</td>
      <td>0.579116</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>1.524986e-01</td>
      <td>-0.004582</td>
      <td>0.004582</td>
      <td>0.004582</td>
      <td>0.583698</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>3.049971e-01</td>
      <td>0.004334</td>
      <td>-0.004334</td>
      <td>0.004334</td>
      <td>0.579364</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004114</td>
      <td>0.004114</td>
      <td>0.004114</td>
      <td>0.583478</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000e+00</td>
      <td>-0.003907</td>
      <td>0.003907</td>
      <td>0.003907</td>
      <td>0.587385</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003874</td>
      <td>-0.003874</td>
      <td>0.003874</td>
      <td>0.583511</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003782</td>
      <td>0.003782</td>
      <td>0.003782</td>
      <td>0.587292</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>1.377877e-01</td>
      <td>0.003666</td>
      <td>-0.003666</td>
      <td>0.003666</td>
      <td>0.583626</td>
    </tr>
    <tr>
      <th>1934</th>
      <td>topic 8</td>
      <td>9.934238e-02</td>
      <td>-0.003596</td>
      <td>0.003596</td>
      <td>0.003596</td>
      <td>0.587221</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>4.574957e-01</td>
      <td>-0.003357</td>
      <td>0.003357</td>
      <td>0.003357</td>
      <td>0.590579</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>0.003287</td>
      <td>-0.003287</td>
      <td>0.003287</td>
      <td>0.587291</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003201</td>
      <td>-0.003201</td>
      <td>0.003201</td>
      <td>0.584090</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>1.524986e-01</td>
      <td>0.003001</td>
      <td>-0.003001</td>
      <td>0.003001</td>
      <td>0.581089</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002921</td>
      <td>-0.002921</td>
      <td>0.002921</td>
      <td>0.578168</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002769</td>
      <td>-0.002769</td>
      <td>0.002769</td>
      <td>0.575399</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002741</td>
      <td>0.002741</td>
      <td>0.002741</td>
      <td>0.578140</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002657</td>
      <td>-0.002657</td>
      <td>0.002657</td>
      <td>0.575483</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 80
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The acting by the whole cast could be put on a scale and balanced perfectly between overacting and underacting.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.265 0.735]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>4.000000</td>
      <td>-0.166441</td>
      <td>0.166441</td>
      <td>0.166441</td>
      <td>0.665951</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.198000</td>
      <td>0.074883</td>
      <td>-0.074883</td>
      <td>0.074883</td>
      <td>0.591068</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.636900</td>
      <td>-0.049434</td>
      <td>0.049434</td>
      <td>0.049434</td>
      <td>0.640503</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.023299</td>
      <td>0.023299</td>
      <td>0.023299</td>
      <td>0.663802</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.020143</td>
      <td>0.020143</td>
      <td>0.020143</td>
      <td>0.683945</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.400000</td>
      <td>-0.017919</td>
      <td>0.017919</td>
      <td>0.017919</td>
      <td>0.701864</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.008601</td>
      <td>-0.008601</td>
      <td>0.008601</td>
      <td>0.693262</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007809</td>
      <td>-0.007809</td>
      <td>0.007809</td>
      <td>0.685453</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006190</td>
      <td>-0.006190</td>
      <td>0.006190</td>
      <td>0.679263</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.005701</td>
      <td>-0.005701</td>
      <td>0.005701</td>
      <td>0.673562</td>
    </tr>
    <tr>
      <th>2031</th>
      <td>topic 105</td>
      <td>0.013766</td>
      <td>-0.005184</td>
      <td>0.005184</td>
      <td>0.005184</td>
      <td>0.678746</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.005128</td>
      <td>-0.005128</td>
      <td>0.005128</td>
      <td>0.673617</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>19.000000</td>
      <td>0.004378</td>
      <td>-0.004378</td>
      <td>0.004378</td>
      <td>0.669239</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.485071</td>
      <td>-0.004173</td>
      <td>0.004173</td>
      <td>0.004173</td>
      <td>0.673412</td>
    </tr>
    <tr>
      <th>2026</th>
      <td>topic 100</td>
      <td>0.063111</td>
      <td>0.004081</td>
      <td>-0.004081</td>
      <td>0.004081</td>
      <td>0.669331</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000</td>
      <td>0.003790</td>
      <td>-0.003790</td>
      <td>0.003790</td>
      <td>0.665541</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>113.000000</td>
      <td>-0.003643</td>
      <td>0.003643</td>
      <td>0.003643</td>
      <td>0.669184</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003349</td>
      <td>0.003349</td>
      <td>0.003349</td>
      <td>0.672533</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000</td>
      <td>0.003288</td>
      <td>-0.003288</td>
      <td>0.003288</td>
      <td>0.669245</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003126</td>
      <td>0.003126</td>
      <td>0.003126</td>
      <td>0.672371</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000</td>
      <td>0.003044</td>
      <td>-0.003044</td>
      <td>0.003044</td>
      <td>0.669327</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.002810</td>
      <td>0.002810</td>
      <td>0.002810</td>
      <td>0.672137</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000</td>
      <td>0.002765</td>
      <td>-0.002765</td>
      <td>0.002765</td>
      <td>0.669372</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.002721</td>
      <td>-0.002721</td>
      <td>0.002721</td>
      <td>0.666651</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000</td>
      <td>-0.002618</td>
      <td>0.002618</td>
      <td>0.002618</td>
      <td>0.669269</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002581</td>
      <td>0.002581</td>
      <td>0.002581</td>
      <td>0.671850</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.009697</td>
      <td>-0.002563</td>
      <td>0.002563</td>
      <td>0.002563</td>
      <td>0.674413</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.002324</td>
      <td>0.002324</td>
      <td>0.002324</td>
      <td>0.676737</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>0.002301</td>
      <td>-0.002301</td>
      <td>0.002301</td>
      <td>0.674437</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>-0.002219</td>
      <td>0.002219</td>
      <td>0.002219</td>
      <td>0.676655</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 81
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;And, FINALLY, after all that, we get to an ending that would&#39;ve been great had it been handled by competent people and not Jerry Falwell.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.43 0.57]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>5.000000e+00</td>
      <td>-0.125719</td>
      <td>0.125719</td>
      <td>0.125719</td>
      <td>0.625228</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.180000e-01</td>
      <td>0.060503</td>
      <td>-0.060503</td>
      <td>0.060503</td>
      <td>0.564725</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.506000e-01</td>
      <td>-0.046574</td>
      <td>0.046574</td>
      <td>0.046574</td>
      <td>0.611299</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.042049</td>
      <td>-0.042049</td>
      <td>0.042049</td>
      <td>0.569250</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.333333e-01</td>
      <td>-0.013384</td>
      <td>0.013384</td>
      <td>0.013384</td>
      <td>0.582634</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+01</td>
      <td>0.009642</td>
      <td>-0.009642</td>
      <td>0.009642</td>
      <td>0.572992</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.008351</td>
      <td>-0.008351</td>
      <td>0.008351</td>
      <td>0.564641</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>topic 78</td>
      <td>2.035140e-01</td>
      <td>0.007925</td>
      <td>-0.007925</td>
      <td>0.007925</td>
      <td>0.556716</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.767767e-01</td>
      <td>-0.006491</td>
      <td>0.006491</td>
      <td>0.006491</td>
      <td>0.563207</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>3.535534e-01</td>
      <td>-0.005481</td>
      <td>0.005481</td>
      <td>0.005481</td>
      <td>0.568688</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.595080e-02</td>
      <td>0.005310</td>
      <td>-0.005310</td>
      <td>0.005310</td>
      <td>0.563378</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005260</td>
      <td>-0.005260</td>
      <td>0.005260</td>
      <td>0.558118</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.671087e-311</td>
      <td>0.003914</td>
      <td>-0.003914</td>
      <td>0.003914</td>
      <td>0.554204</td>
    </tr>
    <tr>
      <th>1887</th>
      <td>would</td>
      <td>1.767767e-01</td>
      <td>0.003673</td>
      <td>-0.003673</td>
      <td>0.003673</td>
      <td>0.550531</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003670</td>
      <td>-0.003670</td>
      <td>0.003670</td>
      <td>0.546862</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>-0.003563</td>
      <td>0.003563</td>
      <td>0.003563</td>
      <td>0.550425</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002911</td>
      <td>0.002911</td>
      <td>0.002911</td>
      <td>0.553336</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.002899</td>
      <td>0.002899</td>
      <td>0.002899</td>
      <td>0.556234</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>7.112190e-108</td>
      <td>0.002812</td>
      <td>-0.002812</td>
      <td>0.002812</td>
      <td>0.553423</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002740</td>
      <td>0.002740</td>
      <td>0.002740</td>
      <td>0.556163</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>5.779010e-147</td>
      <td>0.002726</td>
      <td>-0.002726</td>
      <td>0.002726</td>
      <td>0.553437</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>3.535534e-01</td>
      <td>0.002685</td>
      <td>-0.002685</td>
      <td>0.002685</td>
      <td>0.550752</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002547</td>
      <td>-0.002547</td>
      <td>0.002547</td>
      <td>0.548205</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002545</td>
      <td>0.002545</td>
      <td>0.002545</td>
      <td>0.550751</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.467611e-93</td>
      <td>-0.002280</td>
      <td>0.002280</td>
      <td>0.002280</td>
      <td>0.553031</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002192</td>
      <td>-0.002192</td>
      <td>0.002192</td>
      <td>0.550839</td>
    </tr>
    <tr>
      <th>1941</th>
      <td>topic 15</td>
      <td>0.000000e+00</td>
      <td>0.002181</td>
      <td>-0.002181</td>
      <td>0.002181</td>
      <td>0.548658</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002151</td>
      <td>-0.002151</td>
      <td>0.002151</td>
      <td>0.546506</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002042</td>
      <td>-0.002042</td>
      <td>0.002042</td>
      <td>0.544464</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002034</td>
      <td>0.002034</td>
      <td>0.002034</td>
      <td>0.546497</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 86
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Overall I rate this movie a 10 out of a 1-10 scale.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8175 0.1825]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084876</td>
      <td>-0.084876</td>
      <td>0.084876</td>
      <td>0.414633</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.038362</td>
      <td>-0.038362</td>
      <td>0.038362</td>
      <td>0.376271</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031137</td>
      <td>-0.031137</td>
      <td>0.031137</td>
      <td>0.345133</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024587</td>
      <td>0.024587</td>
      <td>0.024587</td>
      <td>0.369721</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019135</td>
      <td>0.019135</td>
      <td>0.019135</td>
      <td>0.388855</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.015025</td>
      <td>-0.015025</td>
      <td>0.015025</td>
      <td>0.373831</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.014833</td>
      <td>0.014833</td>
      <td>0.014833</td>
      <td>0.388664</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.300000e+01</td>
      <td>0.009890</td>
      <td>-0.009890</td>
      <td>0.009890</td>
      <td>0.378774</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.368967</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008728</td>
      <td>-0.008728</td>
      <td>0.008728</td>
      <td>0.360239</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007906</td>
      <td>-0.007906</td>
      <td>0.007906</td>
      <td>0.352332</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.009491e-199</td>
      <td>0.007416</td>
      <td>-0.007416</td>
      <td>0.007416</td>
      <td>0.344916</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006499</td>
      <td>-0.006499</td>
      <td>0.006499</td>
      <td>0.338418</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005602</td>
      <td>0.005602</td>
      <td>0.005602</td>
      <td>0.344020</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.183029e-189</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.339033</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004552</td>
      <td>-0.004552</td>
      <td>0.004552</td>
      <td>0.334481</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004509</td>
      <td>-0.004509</td>
      <td>0.004509</td>
      <td>0.329972</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004424</td>
      <td>-0.004424</td>
      <td>0.004424</td>
      <td>0.325548</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004350</td>
      <td>0.004350</td>
      <td>0.004350</td>
      <td>0.329898</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.004011</td>
      <td>0.004011</td>
      <td>0.004011</td>
      <td>0.333909</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003967</td>
      <td>-0.003967</td>
      <td>0.003967</td>
      <td>0.329942</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003952</td>
      <td>0.003952</td>
      <td>0.003952</td>
      <td>0.333894</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003741</td>
      <td>0.003741</td>
      <td>0.003741</td>
      <td>0.337635</td>
    </tr>
    <tr>
      <th>2078</th>
      <td>topic 152</td>
      <td>4.283815e-01</td>
      <td>-0.003643</td>
      <td>0.003643</td>
      <td>0.003643</td>
      <td>0.341278</td>
    </tr>
    <tr>
      <th>1121</th>
      <td>out of</td>
      <td>3.779645e-01</td>
      <td>0.003490</td>
      <td>-0.003490</td>
      <td>0.003490</td>
      <td>0.337788</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003384</td>
      <td>-0.003384</td>
      <td>0.003384</td>
      <td>0.334403</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>9.784608e-84</td>
      <td>-0.003315</td>
      <td>0.003315</td>
      <td>0.003315</td>
      <td>0.337718</td>
    </tr>
    <tr>
      <th>1930</th>
      <td>topic 4</td>
      <td>7.178094e-250</td>
      <td>0.003275</td>
      <td>-0.003275</td>
      <td>0.003275</td>
      <td>0.334443</td>
    </tr>
    <tr>
      <th>1120</th>
      <td>out</td>
      <td>3.779645e-01</td>
      <td>0.003248</td>
      <td>-0.003248</td>
      <td>0.003248</td>
      <td>0.331195</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003181</td>
      <td>-0.003181</td>
      <td>0.003181</td>
      <td>0.328014</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 87
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Lifetime does not air it enough, so if anyone knows what store sells it let me know because this is a must-have.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.905 0.095]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.070502</td>
      <td>-0.070502</td>
      <td>0.070502</td>
      <td>0.429008</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.050841</td>
      <td>-0.050841</td>
      <td>0.050841</td>
      <td>0.378167</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031360</td>
      <td>-0.031360</td>
      <td>0.031360</td>
      <td>0.346807</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.200000e+01</td>
      <td>0.026570</td>
      <td>-0.026570</td>
      <td>0.026570</td>
      <td>0.320236</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.140000e+02</td>
      <td>0.016157</td>
      <td>-0.016157</td>
      <td>0.016157</td>
      <td>0.304080</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.011310</td>
      <td>-0.011310</td>
      <td>0.011310</td>
      <td>0.292770</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.009172</td>
      <td>-0.009172</td>
      <td>0.009172</td>
      <td>0.283598</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.961161e-01</td>
      <td>-0.008804</td>
      <td>0.008804</td>
      <td>0.008804</td>
      <td>0.292402</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008414</td>
      <td>-0.008414</td>
      <td>0.008414</td>
      <td>0.283988</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007156</td>
      <td>-0.007156</td>
      <td>0.007156</td>
      <td>0.276832</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006960</td>
      <td>-0.006960</td>
      <td>0.006960</td>
      <td>0.269872</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005384</td>
      <td>-0.005384</td>
      <td>0.005384</td>
      <td>0.264488</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>2.598305e-128</td>
      <td>0.005378</td>
      <td>-0.005378</td>
      <td>0.005378</td>
      <td>0.259110</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>1.961161e-01</td>
      <td>0.004870</td>
      <td>-0.004870</td>
      <td>0.004870</td>
      <td>0.254240</td>
    </tr>
    <tr>
      <th>402</th>
      <td>doe</td>
      <td>1.961161e-01</td>
      <td>-0.004201</td>
      <td>0.004201</td>
      <td>0.004201</td>
      <td>0.258441</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004091</td>
      <td>-0.004091</td>
      <td>0.004091</td>
      <td>0.254349</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.785630e-271</td>
      <td>0.004042</td>
      <td>-0.004042</td>
      <td>0.004042</td>
      <td>0.250308</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>1.961161e-01</td>
      <td>0.003970</td>
      <td>-0.003970</td>
      <td>0.003970</td>
      <td>0.246338</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003915</td>
      <td>0.003915</td>
      <td>0.003915</td>
      <td>0.250253</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.003312</td>
      <td>-0.003312</td>
      <td>0.003312</td>
      <td>0.246941</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000e+00</td>
      <td>0.003274</td>
      <td>-0.003274</td>
      <td>0.003274</td>
      <td>0.243667</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.002987</td>
      <td>-0.002987</td>
      <td>0.002987</td>
      <td>0.240680</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002851</td>
      <td>0.002851</td>
      <td>0.002851</td>
      <td>0.243531</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002837</td>
      <td>-0.002837</td>
      <td>0.002837</td>
      <td>0.240694</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002815</td>
      <td>0.002815</td>
      <td>0.002815</td>
      <td>0.243509</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002814</td>
      <td>-0.002814</td>
      <td>0.002814</td>
      <td>0.240695</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.501965e-146</td>
      <td>-0.002734</td>
      <td>0.002734</td>
      <td>0.002734</td>
      <td>0.243429</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002721</td>
      <td>0.002721</td>
      <td>0.002721</td>
      <td>0.246150</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>0.000000e+00</td>
      <td>0.002692</td>
      <td>-0.002692</td>
      <td>0.002692</td>
      <td>0.243458</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002575</td>
      <td>0.002575</td>
      <td>0.002575</td>
      <td>0.246033</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 90
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Totally different, with loads of understatement and black comedy, this is a film few get to see, but those who do will remember it.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.5325 0.4675]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.110869</td>
      <td>0.110869</td>
      <td>0.110869</td>
      <td>0.610379</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>7.400000e-02</td>
      <td>0.079043</td>
      <td>-0.079043</td>
      <td>0.079043</td>
      <td>0.531336</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.222222e-01</td>
      <td>0.054285</td>
      <td>-0.054285</td>
      <td>0.054285</td>
      <td>0.477050</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026343</td>
      <td>0.026343</td>
      <td>0.026343</td>
      <td>0.503393</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.400000e+01</td>
      <td>0.022615</td>
      <td>-0.022615</td>
      <td>0.022615</td>
      <td>0.480779</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021002</td>
      <td>0.021002</td>
      <td>0.021002</td>
      <td>0.501781</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009543</td>
      <td>-0.009543</td>
      <td>0.009543</td>
      <td>0.492238</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.495259e-154</td>
      <td>0.007755</td>
      <td>-0.007755</td>
      <td>0.007755</td>
      <td>0.484482</td>
    </tr>
    <tr>
      <th>2024</th>
      <td>topic 98</td>
      <td>1.533529e-02</td>
      <td>-0.007040</td>
      <td>0.007040</td>
      <td>0.007040</td>
      <td>0.491523</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006644</td>
      <td>-0.006644</td>
      <td>0.006644</td>
      <td>0.484878</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.006154</td>
      <td>0.006154</td>
      <td>0.006154</td>
      <td>0.491032</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004937</td>
      <td>-0.004937</td>
      <td>0.004937</td>
      <td>0.486095</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004490</td>
      <td>-0.004490</td>
      <td>0.004490</td>
      <td>0.481605</td>
    </tr>
    <tr>
      <th>2109</th>
      <td>topic 183</td>
      <td>4.666634e-08</td>
      <td>-0.004396</td>
      <td>0.004396</td>
      <td>0.004396</td>
      <td>0.486001</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>2.182179e-01</td>
      <td>-0.004136</td>
      <td>0.004136</td>
      <td>0.004136</td>
      <td>0.490137</td>
    </tr>
    <tr>
      <th>2059</th>
      <td>topic 133</td>
      <td>2.146583e-06</td>
      <td>-0.004120</td>
      <td>0.004120</td>
      <td>0.004120</td>
      <td>0.494257</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.182179e-01</td>
      <td>0.004099</td>
      <td>-0.004099</td>
      <td>0.004099</td>
      <td>0.490159</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>2.182179e-01</td>
      <td>-0.004060</td>
      <td>0.004060</td>
      <td>0.004060</td>
      <td>0.494219</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004009</td>
      <td>0.004009</td>
      <td>0.004009</td>
      <td>0.498228</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003857</td>
      <td>0.003857</td>
      <td>0.003857</td>
      <td>0.502085</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>-0.003846</td>
      <td>0.003846</td>
      <td>0.003846</td>
      <td>0.505931</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003668</td>
      <td>0.003668</td>
      <td>0.003668</td>
      <td>0.509599</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003190</td>
      <td>-0.003190</td>
      <td>0.003190</td>
      <td>0.506410</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.033985e-222</td>
      <td>-0.003176</td>
      <td>0.003176</td>
      <td>0.003176</td>
      <td>0.509586</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003129</td>
      <td>0.003129</td>
      <td>0.003129</td>
      <td>0.512715</td>
    </tr>
    <tr>
      <th>1975</th>
      <td>topic 49</td>
      <td>2.403898e-04</td>
      <td>-0.003121</td>
      <td>0.003121</td>
      <td>0.003121</td>
      <td>0.515836</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>2.182179e-01</td>
      <td>0.003040</td>
      <td>-0.003040</td>
      <td>0.003040</td>
      <td>0.512797</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>3.478166e-149</td>
      <td>0.002877</td>
      <td>-0.002877</td>
      <td>0.002877</td>
      <td>0.509920</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.002845</td>
      <td>-0.002845</td>
      <td>0.002845</td>
      <td>0.507074</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>2.182179e-01</td>
      <td>-0.002833</td>
      <td>0.002833</td>
      <td>0.002833</td>
      <td>0.509907</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 92
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;But this movie really got to me.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7575 0.2425]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.086191</td>
      <td>-0.086191</td>
      <td>0.086191</td>
      <td>0.413319</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025373</td>
      <td>0.025373</td>
      <td>0.025373</td>
      <td>0.438692</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.024987</td>
      <td>-0.024987</td>
      <td>0.024987</td>
      <td>0.413705</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019649</td>
      <td>0.019649</td>
      <td>0.019649</td>
      <td>0.433354</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.400000e+01</td>
      <td>0.016793</td>
      <td>-0.016793</td>
      <td>0.016793</td>
      <td>0.416561</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009672</td>
      <td>-0.009672</td>
      <td>0.009672</td>
      <td>0.406889</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.008628</td>
      <td>0.008628</td>
      <td>0.008628</td>
      <td>0.415517</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008613</td>
      <td>-0.008613</td>
      <td>0.008613</td>
      <td>0.406904</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.008376</td>
      <td>0.008376</td>
      <td>0.008376</td>
      <td>0.415279</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008212</td>
      <td>-0.008212</td>
      <td>0.008212</td>
      <td>0.407068</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.748697e-284</td>
      <td>0.007439</td>
      <td>-0.007439</td>
      <td>0.007439</td>
      <td>0.399628</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.000000e-01</td>
      <td>0.007067</td>
      <td>-0.007067</td>
      <td>0.007067</td>
      <td>0.392562</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006567</td>
      <td>-0.006567</td>
      <td>0.006567</td>
      <td>0.385995</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.006481</td>
      <td>-0.006481</td>
      <td>0.006481</td>
      <td>0.379514</td>
    </tr>
    <tr>
      <th>1945</th>
      <td>topic 19</td>
      <td>2.026670e-01</td>
      <td>-0.005948</td>
      <td>0.005948</td>
      <td>0.005948</td>
      <td>0.385462</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>2.130797e-224</td>
      <td>0.005736</td>
      <td>-0.005736</td>
      <td>0.005736</td>
      <td>0.379726</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>3.162278e-01</td>
      <td>0.005585</td>
      <td>-0.005585</td>
      <td>0.005585</td>
      <td>0.374141</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.066739e-161</td>
      <td>0.005295</td>
      <td>-0.005295</td>
      <td>0.005295</td>
      <td>0.368845</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005259</td>
      <td>0.005259</td>
      <td>0.005259</td>
      <td>0.374104</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004460</td>
      <td>-0.004460</td>
      <td>0.004460</td>
      <td>0.369644</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004200</td>
      <td>0.004200</td>
      <td>0.004200</td>
      <td>0.373844</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004121</td>
      <td>-0.004121</td>
      <td>0.004121</td>
      <td>0.369722</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004096</td>
      <td>0.004096</td>
      <td>0.004096</td>
      <td>0.373819</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003874</td>
      <td>0.003874</td>
      <td>0.003874</td>
      <td>0.377693</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003874</td>
      <td>-0.003874</td>
      <td>0.003874</td>
      <td>0.373819</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.142936e-85</td>
      <td>-0.003340</td>
      <td>0.003340</td>
      <td>0.003340</td>
      <td>0.377159</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003311</td>
      <td>-0.003311</td>
      <td>0.003311</td>
      <td>0.373848</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003192</td>
      <td>0.003192</td>
      <td>0.003192</td>
      <td>0.377040</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003186</td>
      <td>-0.003186</td>
      <td>0.003186</td>
      <td>0.373854</td>
    </tr>
    <tr>
      <th>972</th>
      <td>movie</td>
      <td>3.162278e-01</td>
      <td>-0.003165</td>
      <td>0.003165</td>
      <td>0.003165</td>
      <td>0.377019</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 94
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I really hope the team behind this movie makes more movies, and that they will continue to do so in their own, some kinda weird style.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.6775 0.3225]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.160000e-01</td>
      <td>0.078725</td>
      <td>-0.078725</td>
      <td>0.078725</td>
      <td>0.420785</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.188000e-01</td>
      <td>-0.054050</td>
      <td>0.054050</td>
      <td>0.054050</td>
      <td>0.474834</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.600000e+01</td>
      <td>0.031098</td>
      <td>-0.031098</td>
      <td>0.031098</td>
      <td>0.443736</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>8.000000e-02</td>
      <td>0.030365</td>
      <td>-0.030365</td>
      <td>0.030365</td>
      <td>0.413371</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025893</td>
      <td>0.025893</td>
      <td>0.025893</td>
      <td>0.439264</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019251</td>
      <td>0.019251</td>
      <td>0.019251</td>
      <td>0.458515</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.010096</td>
      <td>-0.010096</td>
      <td>0.010096</td>
      <td>0.448419</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.009664</td>
      <td>-0.009664</td>
      <td>0.009664</td>
      <td>0.438754</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.009583</td>
      <td>-0.009583</td>
      <td>0.009583</td>
      <td>0.429172</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008997</td>
      <td>-0.008997</td>
      <td>0.008997</td>
      <td>0.420175</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.273698e-289</td>
      <td>0.007788</td>
      <td>-0.007788</td>
      <td>0.007788</td>
      <td>0.412387</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006886</td>
      <td>-0.006886</td>
      <td>0.006886</td>
      <td>0.405501</td>
    </tr>
    <tr>
      <th>1945</th>
      <td>topic 19</td>
      <td>1.104801e-01</td>
      <td>-0.005181</td>
      <td>0.005181</td>
      <td>0.005181</td>
      <td>0.410682</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.360000e+02</td>
      <td>0.004912</td>
      <td>-0.004912</td>
      <td>0.004912</td>
      <td>0.405770</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.796009e-87</td>
      <td>0.004903</td>
      <td>-0.004903</td>
      <td>0.004903</td>
      <td>0.400867</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>1.961161e-01</td>
      <td>-0.004850</td>
      <td>0.004850</td>
      <td>0.004850</td>
      <td>0.405717</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003962</td>
      <td>0.003962</td>
      <td>0.003962</td>
      <td>0.409680</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003388</td>
      <td>0.003388</td>
      <td>0.003388</td>
      <td>0.413067</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003378</td>
      <td>0.003378</td>
      <td>0.003378</td>
      <td>0.416446</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003337</td>
      <td>-0.003337</td>
      <td>0.003337</td>
      <td>0.413109</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003275</td>
      <td>0.003275</td>
      <td>0.003275</td>
      <td>0.416384</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.486729e-84</td>
      <td>-0.003249</td>
      <td>0.003249</td>
      <td>0.003249</td>
      <td>0.419633</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>2.911661e-229</td>
      <td>0.003188</td>
      <td>-0.003188</td>
      <td>0.003188</td>
      <td>0.416446</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003183</td>
      <td>-0.003183</td>
      <td>0.003183</td>
      <td>0.413262</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003081</td>
      <td>0.003081</td>
      <td>0.003081</td>
      <td>0.416344</td>
    </tr>
    <tr>
      <th>972</th>
      <td>movie</td>
      <td>3.922323e-01</td>
      <td>-0.003026</td>
      <td>0.003026</td>
      <td>0.003026</td>
      <td>0.419370</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002970</td>
      <td>0.002970</td>
      <td>0.002970</td>
      <td>0.422340</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.002911</td>
      <td>-0.002911</td>
      <td>0.002911</td>
      <td>0.419429</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.002854</td>
      <td>-0.002854</td>
      <td>0.002854</td>
      <td>0.416575</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002847</td>
      <td>0.002847</td>
      <td>0.002847</td>
      <td>0.419422</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 98
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Initially the local sites in the film, which was filmed here in Buffalo, intrigued me.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.825 0.175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.083930</td>
      <td>-0.083930</td>
      <td>0.083930</td>
      <td>0.415580</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.500000e+01</td>
      <td>0.033264</td>
      <td>-0.033264</td>
      <td>0.033264</td>
      <td>0.382316</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.032493</td>
      <td>-0.032493</td>
      <td>0.032493</td>
      <td>0.349822</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025033</td>
      <td>0.025033</td>
      <td>0.025033</td>
      <td>0.374855</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019265</td>
      <td>0.019265</td>
      <td>0.019265</td>
      <td>0.394120</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.019090</td>
      <td>-0.019090</td>
      <td>0.019090</td>
      <td>0.375030</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.015186</td>
      <td>0.015186</td>
      <td>0.015186</td>
      <td>0.390216</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009694</td>
      <td>-0.009694</td>
      <td>0.009694</td>
      <td>0.380521</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007627</td>
      <td>-0.007627</td>
      <td>0.007627</td>
      <td>0.372894</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007489</td>
      <td>-0.007489</td>
      <td>0.007489</td>
      <td>0.365405</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.118127e-147</td>
      <td>0.007269</td>
      <td>-0.007269</td>
      <td>0.007269</td>
      <td>0.358136</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.351596</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>6.797261e-238</td>
      <td>0.006388</td>
      <td>-0.006388</td>
      <td>0.006388</td>
      <td>0.345208</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>2.773501e-01</td>
      <td>0.006261</td>
      <td>-0.006261</td>
      <td>0.006261</td>
      <td>0.338948</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.006075</td>
      <td>-0.006075</td>
      <td>0.006075</td>
      <td>0.332873</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005531</td>
      <td>0.005531</td>
      <td>0.005531</td>
      <td>0.338403</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004863</td>
      <td>-0.004863</td>
      <td>0.004863</td>
      <td>0.333540</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.800000e+01</td>
      <td>0.004625</td>
      <td>-0.004625</td>
      <td>0.004625</td>
      <td>0.328915</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>2.773501e-01</td>
      <td>-0.004397</td>
      <td>0.004397</td>
      <td>0.004397</td>
      <td>0.333312</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004328</td>
      <td>-0.004328</td>
      <td>0.004328</td>
      <td>0.328984</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003914</td>
      <td>0.003914</td>
      <td>0.003914</td>
      <td>0.332898</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003868</td>
      <td>0.003868</td>
      <td>0.003868</td>
      <td>0.336765</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003783</td>
      <td>-0.003783</td>
      <td>0.003783</td>
      <td>0.332983</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003727</td>
      <td>0.003727</td>
      <td>0.003727</td>
      <td>0.336710</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003705</td>
      <td>0.003705</td>
      <td>0.003705</td>
      <td>0.340415</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003346</td>
      <td>-0.003346</td>
      <td>0.003346</td>
      <td>0.337069</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003286</td>
      <td>-0.003286</td>
      <td>0.003286</td>
      <td>0.333782</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003223</td>
      <td>-0.003223</td>
      <td>0.003223</td>
      <td>0.330559</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.214784e-214</td>
      <td>-0.003206</td>
      <td>0.003206</td>
      <td>0.003206</td>
      <td>0.333765</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003200</td>
      <td>-0.003200</td>
      <td>0.003200</td>
      <td>0.330565</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 99
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Later I found myself lost in the power of the film.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.975 0.025]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-3.000000e+00</td>
      <td>0.190141</td>
      <td>-0.190141</td>
      <td>0.190141</td>
      <td>0.309368</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.070146</td>
      <td>-0.070146</td>
      <td>0.070146</td>
      <td>0.239222</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-3.182000e-01</td>
      <td>0.057866</td>
      <td>-0.057866</td>
      <td>0.057866</td>
      <td>0.181357</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.025097</td>
      <td>-0.025097</td>
      <td>0.025097</td>
      <td>0.156259</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.300000e+01</td>
      <td>0.022602</td>
      <td>-0.022602</td>
      <td>0.022602</td>
      <td>0.133657</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.021364</td>
      <td>0.021364</td>
      <td>0.021364</td>
      <td>0.155021</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.016898</td>
      <td>-0.016898</td>
      <td>0.016898</td>
      <td>0.138123</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.015830</td>
      <td>0.015830</td>
      <td>0.015830</td>
      <td>0.153953</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008727</td>
      <td>-0.008727</td>
      <td>0.008727</td>
      <td>0.145227</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006686</td>
      <td>-0.006686</td>
      <td>0.006686</td>
      <td>0.138541</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.811626e-155</td>
      <td>0.006068</td>
      <td>-0.006068</td>
      <td>0.006068</td>
      <td>0.132473</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005444</td>
      <td>-0.005444</td>
      <td>0.005444</td>
      <td>0.127029</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003917</td>
      <td>-0.003917</td>
      <td>0.003917</td>
      <td>0.123112</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.373313e-223</td>
      <td>-0.003331</td>
      <td>0.003331</td>
      <td>0.003331</td>
      <td>0.126443</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003242</td>
      <td>0.003242</td>
      <td>0.003242</td>
      <td>0.129685</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003108</td>
      <td>-0.003108</td>
      <td>0.003108</td>
      <td>0.126577</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002749</td>
      <td>0.002749</td>
      <td>0.002749</td>
      <td>0.129326</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002727</td>
      <td>0.002727</td>
      <td>0.002727</td>
      <td>0.132053</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002659</td>
      <td>0.002659</td>
      <td>0.002659</td>
      <td>0.134712</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.002565</td>
      <td>0.002565</td>
      <td>0.002565</td>
      <td>0.137277</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002331</td>
      <td>-0.002331</td>
      <td>0.002331</td>
      <td>0.134946</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002293</td>
      <td>0.002293</td>
      <td>0.002293</td>
      <td>0.137239</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002200</td>
      <td>-0.002200</td>
      <td>0.002200</td>
      <td>0.135038</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.002194</td>
      <td>0.002194</td>
      <td>0.002194</td>
      <td>0.137232</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002087</td>
      <td>0.002087</td>
      <td>0.002087</td>
      <td>0.139319</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002026</td>
      <td>0.002026</td>
      <td>0.002026</td>
      <td>0.141346</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.002009</td>
      <td>-0.002009</td>
      <td>0.002009</td>
      <td>0.139336</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.001996</td>
      <td>0.001996</td>
      <td>0.001996</td>
      <td>0.141332</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.797895e-246</td>
      <td>0.001967</td>
      <td>-0.001967</td>
      <td>0.001967</td>
      <td>0.139366</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.001965</td>
      <td>-0.001965</td>
      <td>0.001965</td>
      <td>0.137400</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 108
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;What this film lacks is a convincing script.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.5275 0.4725]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.100000e-01</td>
      <td>0.066246</td>
      <td>-0.066246</td>
      <td>0.066246</td>
      <td>0.433264</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.000000e-01</td>
      <td>-0.043389</td>
      <td>0.043389</td>
      <td>0.043389</td>
      <td>0.476653</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.019000e-01</td>
      <td>-0.042138</td>
      <td>0.042138</td>
      <td>0.042138</td>
      <td>0.518790</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025105</td>
      <td>0.025105</td>
      <td>0.025105</td>
      <td>0.543895</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020191</td>
      <td>0.020191</td>
      <td>0.020191</td>
      <td>0.564086</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.012619</td>
      <td>-0.012619</td>
      <td>0.012619</td>
      <td>0.551467</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.012619</td>
      <td>-0.012619</td>
      <td>0.012619</td>
      <td>0.538848</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.010936</td>
      <td>-0.010936</td>
      <td>0.010936</td>
      <td>0.527912</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009963</td>
      <td>-0.009963</td>
      <td>0.009963</td>
      <td>0.517949</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.303147e-154</td>
      <td>0.008110</td>
      <td>-0.008110</td>
      <td>0.008110</td>
      <td>0.509839</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.007098</td>
      <td>-0.007098</td>
      <td>0.007098</td>
      <td>0.502741</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.779645e-01</td>
      <td>0.005679</td>
      <td>-0.005679</td>
      <td>0.005679</td>
      <td>0.497062</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.005541</td>
      <td>-0.005541</td>
      <td>0.005541</td>
      <td>0.491521</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005180</td>
      <td>-0.005180</td>
      <td>0.005180</td>
      <td>0.486341</td>
    </tr>
    <tr>
      <th>1823</th>
      <td>what</td>
      <td>3.779645e-01</td>
      <td>0.004952</td>
      <td>-0.004952</td>
      <td>0.004952</td>
      <td>0.481388</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.004486</td>
      <td>-0.004486</td>
      <td>0.004486</td>
      <td>0.476903</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.004270</td>
      <td>-0.004270</td>
      <td>0.004270</td>
      <td>0.472633</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003689</td>
      <td>0.003689</td>
      <td>0.003689</td>
      <td>0.476322</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003580</td>
      <td>0.003580</td>
      <td>0.003580</td>
      <td>0.479902</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003562</td>
      <td>0.003562</td>
      <td>0.003562</td>
      <td>0.483464</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003335</td>
      <td>0.003335</td>
      <td>0.003335</td>
      <td>0.486799</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003334</td>
      <td>0.003334</td>
      <td>0.003334</td>
      <td>0.490132</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.351683e-182</td>
      <td>-0.003227</td>
      <td>0.003227</td>
      <td>0.003227</td>
      <td>0.493360</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003206</td>
      <td>-0.003206</td>
      <td>0.003206</td>
      <td>0.490154</td>
    </tr>
    <tr>
      <th>1806</th>
      <td>we were</td>
      <td>0.000000e+00</td>
      <td>0.003084</td>
      <td>-0.003084</td>
      <td>0.003084</td>
      <td>0.487070</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003062</td>
      <td>0.003062</td>
      <td>0.003062</td>
      <td>0.490131</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.003019</td>
      <td>-0.003019</td>
      <td>0.003019</td>
      <td>0.487112</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002979</td>
      <td>-0.002979</td>
      <td>0.002979</td>
      <td>0.484133</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002843</td>
      <td>-0.002843</td>
      <td>0.002843</td>
      <td>0.481290</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>0.000000e+00</td>
      <td>-0.002798</td>
      <td>0.002798</td>
      <td>0.002798</td>
      <td>0.484088</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 124
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Full of unconvincing cardboard characters it is blandly written by Edward Chodorov, who also produced, and is surprisingly directed by Jean Negulesco from whom one would expect a great deal more.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.255 0.745]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.150363</td>
      <td>0.150363</td>
      <td>0.150363</td>
      <td>0.649873</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.840000e-01</td>
      <td>0.075035</td>
      <td>-0.075035</td>
      <td>0.075035</td>
      <td>0.574838</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.430000e-01</td>
      <td>-0.050984</td>
      <td>0.050984</td>
      <td>0.050984</td>
      <td>0.625822</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023093</td>
      <td>0.023093</td>
      <td>0.023093</td>
      <td>0.648915</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019956</td>
      <td>0.019956</td>
      <td>0.019956</td>
      <td>0.668871</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.366667e-01</td>
      <td>-0.018218</td>
      <td>0.018218</td>
      <td>0.018218</td>
      <td>0.687089</td>
    </tr>
    <tr>
      <th>2109</th>
      <td>topic 183</td>
      <td>4.289479e-01</td>
      <td>-0.013867</td>
      <td>0.013867</td>
      <td>0.013867</td>
      <td>0.700956</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>2.024463e-01</td>
      <td>0.008530</td>
      <td>-0.008530</td>
      <td>0.008530</td>
      <td>0.692426</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.499247e-02</td>
      <td>0.008065</td>
      <td>-0.008065</td>
      <td>0.008065</td>
      <td>0.684362</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006382</td>
      <td>-0.006382</td>
      <td>0.006382</td>
      <td>0.677980</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.100000e+01</td>
      <td>0.005511</td>
      <td>-0.005511</td>
      <td>0.005511</td>
      <td>0.672468</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.848663e-24</td>
      <td>0.005009</td>
      <td>-0.005009</td>
      <td>0.005009</td>
      <td>0.667459</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>2.000000e-01</td>
      <td>-0.004460</td>
      <td>0.004460</td>
      <td>0.004460</td>
      <td>0.671919</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>0.004162</td>
      <td>-0.004162</td>
      <td>0.004162</td>
      <td>0.667757</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>4.000000e-01</td>
      <td>0.004101</td>
      <td>-0.004101</td>
      <td>0.004101</td>
      <td>0.663656</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>2.000000e-01</td>
      <td>-0.003993</td>
      <td>0.003993</td>
      <td>0.003993</td>
      <td>0.667649</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003751</td>
      <td>0.003751</td>
      <td>0.003751</td>
      <td>0.671400</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.970000e+02</td>
      <td>0.003463</td>
      <td>-0.003463</td>
      <td>0.003463</td>
      <td>0.667937</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003423</td>
      <td>-0.003423</td>
      <td>0.003423</td>
      <td>0.664514</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003352</td>
      <td>0.003352</td>
      <td>0.003352</td>
      <td>0.667866</td>
    </tr>
    <tr>
      <th>1887</th>
      <td>would</td>
      <td>2.000000e-01</td>
      <td>0.003302</td>
      <td>-0.003302</td>
      <td>0.003302</td>
      <td>0.664565</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002966</td>
      <td>-0.002966</td>
      <td>0.002966</td>
      <td>0.661599</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002751</td>
      <td>0.002751</td>
      <td>0.002751</td>
      <td>0.664350</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002700</td>
      <td>-0.002700</td>
      <td>0.002700</td>
      <td>0.661649</td>
    </tr>
    <tr>
      <th>808</th>
      <td>it is</td>
      <td>2.000000e-01</td>
      <td>-0.002695</td>
      <td>0.002695</td>
      <td>0.002695</td>
      <td>0.664344</td>
    </tr>
    <tr>
      <th>254</th>
      <td>button</td>
      <td>0.000000e+00</td>
      <td>-0.002638</td>
      <td>0.002638</td>
      <td>0.002638</td>
      <td>0.666982</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002577</td>
      <td>0.002577</td>
      <td>0.002577</td>
      <td>0.669560</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002572</td>
      <td>0.002572</td>
      <td>0.002572</td>
      <td>0.672132</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002560</td>
      <td>0.002560</td>
      <td>0.002560</td>
      <td>0.674692</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.002289</td>
      <td>0.002289</td>
      <td>0.002289</td>
      <td>0.676980</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 125
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;From here on the Widmark character turns unintentionally comical!  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.585 0.415]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.089127</td>
      <td>-0.089127</td>
      <td>0.089127</td>
      <td>0.410383</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>6.250000e-01</td>
      <td>-0.058625</td>
      <td>0.058625</td>
      <td>0.058625</td>
      <td>0.469008</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.026580</td>
      <td>0.026580</td>
      <td>0.026580</td>
      <td>0.495588</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025198</td>
      <td>0.025198</td>
      <td>0.025198</td>
      <td>0.520786</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019777</td>
      <td>0.019777</td>
      <td>0.019777</td>
      <td>0.540563</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>3.269164e-01</td>
      <td>0.014914</td>
      <td>-0.014914</td>
      <td>0.014914</td>
      <td>0.525649</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.014634</td>
      <td>-0.014634</td>
      <td>0.014634</td>
      <td>0.511014</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000e+00</td>
      <td>0.014495</td>
      <td>-0.014495</td>
      <td>0.014495</td>
      <td>0.496519</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.011144</td>
      <td>0.011144</td>
      <td>0.011144</td>
      <td>0.507663</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009840</td>
      <td>-0.009840</td>
      <td>0.009840</td>
      <td>0.497823</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008231</td>
      <td>-0.008231</td>
      <td>0.008231</td>
      <td>0.489592</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007958</td>
      <td>-0.007958</td>
      <td>0.007958</td>
      <td>0.481634</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.007279</td>
      <td>-0.007279</td>
      <td>0.007279</td>
      <td>0.474355</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007234</td>
      <td>-0.007234</td>
      <td>0.007234</td>
      <td>0.467121</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006826</td>
      <td>-0.006826</td>
      <td>0.006826</td>
      <td>0.460295</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005356</td>
      <td>0.005356</td>
      <td>0.005356</td>
      <td>0.465651</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005302</td>
      <td>-0.005302</td>
      <td>0.005302</td>
      <td>0.460348</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004641</td>
      <td>0.004641</td>
      <td>0.004641</td>
      <td>0.464989</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004133</td>
      <td>0.004133</td>
      <td>0.004133</td>
      <td>0.469122</td>
    </tr>
    <tr>
      <th>2091</th>
      <td>topic 165</td>
      <td>0.000000e+00</td>
      <td>0.004083</td>
      <td>-0.004083</td>
      <td>0.004083</td>
      <td>0.465039</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>-0.004060</td>
      <td>0.004060</td>
      <td>0.004060</td>
      <td>0.469099</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004016</td>
      <td>0.004016</td>
      <td>0.004016</td>
      <td>0.473116</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000e+00</td>
      <td>-0.003972</td>
      <td>0.003972</td>
      <td>0.003972</td>
      <td>0.477088</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003906</td>
      <td>0.003906</td>
      <td>0.003906</td>
      <td>0.480994</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003875</td>
      <td>0.003875</td>
      <td>0.003875</td>
      <td>0.484869</td>
    </tr>
    <tr>
      <th>1929</th>
      <td>topic 3</td>
      <td>9.221578e-13</td>
      <td>-0.003829</td>
      <td>0.003829</td>
      <td>0.003829</td>
      <td>0.488698</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003796</td>
      <td>-0.003796</td>
      <td>0.003796</td>
      <td>0.484902</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003487</td>
      <td>-0.003487</td>
      <td>0.003487</td>
      <td>0.481415</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003416</td>
      <td>-0.003416</td>
      <td>0.003416</td>
      <td>0.477999</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003275</td>
      <td>0.003275</td>
      <td>0.003275</td>
      <td>0.481274</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 139
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;i wouldnt see this movie again for free.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.35 0.65]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.090591</td>
      <td>0.090591</td>
      <td>0.090591</td>
      <td>0.590100</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.550000e-01</td>
      <td>0.074669</td>
      <td>-0.074669</td>
      <td>0.074669</td>
      <td>0.515432</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.106000e-01</td>
      <td>-0.041405</td>
      <td>0.041405</td>
      <td>0.041405</td>
      <td>0.556837</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025702</td>
      <td>0.025702</td>
      <td>0.025702</td>
      <td>0.582539</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>4.000000e-01</td>
      <td>-0.025270</td>
      <td>0.025270</td>
      <td>0.025270</td>
      <td>0.607809</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021905</td>
      <td>0.021905</td>
      <td>0.021905</td>
      <td>0.629713</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.011147</td>
      <td>-0.011147</td>
      <td>0.011147</td>
      <td>0.618566</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.010410</td>
      <td>-0.010410</td>
      <td>0.010410</td>
      <td>0.608156</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009856</td>
      <td>-0.009856</td>
      <td>0.009856</td>
      <td>0.598300</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.008175</td>
      <td>-0.008175</td>
      <td>0.008175</td>
      <td>0.590125</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.200000e+01</td>
      <td>-0.007980</td>
      <td>0.007980</td>
      <td>0.007980</td>
      <td>0.598105</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.007300</td>
      <td>-0.007300</td>
      <td>0.007300</td>
      <td>0.590806</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006449</td>
      <td>-0.006449</td>
      <td>0.006449</td>
      <td>0.584356</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.006316</td>
      <td>0.006316</td>
      <td>0.006316</td>
      <td>0.590673</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.197406e-102</td>
      <td>0.005577</td>
      <td>-0.005577</td>
      <td>0.005577</td>
      <td>0.585096</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>3.779645e-01</td>
      <td>0.005058</td>
      <td>-0.005058</td>
      <td>0.005058</td>
      <td>0.580037</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.004003</td>
      <td>0.004003</td>
      <td>0.004003</td>
      <td>0.584040</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003950</td>
      <td>-0.003950</td>
      <td>0.003950</td>
      <td>0.580091</td>
    </tr>
    <tr>
      <th>316</th>
      <td>clear</td>
      <td>0.000000e+00</td>
      <td>0.003769</td>
      <td>-0.003769</td>
      <td>0.003769</td>
      <td>0.576321</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003712</td>
      <td>0.003712</td>
      <td>0.003712</td>
      <td>0.580033</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003289</td>
      <td>-0.003289</td>
      <td>0.003289</td>
      <td>0.576744</td>
    </tr>
    <tr>
      <th>1887</th>
      <td>would</td>
      <td>0.000000e+00</td>
      <td>-0.003194</td>
      <td>0.003194</td>
      <td>0.003194</td>
      <td>0.579938</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003184</td>
      <td>0.003184</td>
      <td>0.003184</td>
      <td>0.583122</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.090980e-84</td>
      <td>-0.003147</td>
      <td>0.003147</td>
      <td>0.003147</td>
      <td>0.586269</td>
    </tr>
    <tr>
      <th>972</th>
      <td>movie</td>
      <td>3.779645e-01</td>
      <td>-0.003032</td>
      <td>0.003032</td>
      <td>0.003032</td>
      <td>0.589301</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.003008</td>
      <td>-0.003008</td>
      <td>0.003008</td>
      <td>0.586293</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002975</td>
      <td>0.002975</td>
      <td>0.002975</td>
      <td>0.589268</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002843</td>
      <td>0.002843</td>
      <td>0.002843</td>
      <td>0.592111</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002745</td>
      <td>-0.002745</td>
      <td>0.002745</td>
      <td>0.589367</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002737</td>
      <td>0.002737</td>
      <td>0.002737</td>
      <td>0.592103</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 141
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;This second appearance of Mickey Mouse (following the silent PLANE CRAZY earlier that year) is probably his most famous film--mostly because it was so ground-breaking.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8375 0.1625]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.824000e-01</td>
      <td>0.127894</td>
      <td>-0.127894</td>
      <td>0.127894</td>
      <td>0.371616</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.079526</td>
      <td>-0.079526</td>
      <td>0.079526</td>
      <td>0.292090</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023399</td>
      <td>0.023399</td>
      <td>0.023399</td>
      <td>0.315489</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.020444</td>
      <td>-0.020444</td>
      <td>0.020444</td>
      <td>0.295045</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.714286e-02</td>
      <td>0.019779</td>
      <td>-0.019779</td>
      <td>0.019779</td>
      <td>0.275266</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018083</td>
      <td>0.018083</td>
      <td>0.018083</td>
      <td>0.293349</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009531</td>
      <td>-0.009531</td>
      <td>0.009531</td>
      <td>0.283819</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>topic 86</td>
      <td>2.313578e-01</td>
      <td>-0.008775</td>
      <td>0.008775</td>
      <td>0.008775</td>
      <td>0.292594</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007312</td>
      <td>-0.007312</td>
      <td>0.007312</td>
      <td>0.285282</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.662635e-154</td>
      <td>0.007024</td>
      <td>-0.007024</td>
      <td>0.007024</td>
      <td>0.278258</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006255</td>
      <td>-0.006255</td>
      <td>0.006255</td>
      <td>0.272003</td>
    </tr>
    <tr>
      <th>967</th>
      <td>most</td>
      <td>2.357023e-01</td>
      <td>-0.005457</td>
      <td>0.005457</td>
      <td>0.005457</td>
      <td>0.277460</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.690000e+02</td>
      <td>-0.004483</td>
      <td>0.004483</td>
      <td>0.004483</td>
      <td>0.281943</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.107405e-208</td>
      <td>0.004343</td>
      <td>-0.004343</td>
      <td>0.004343</td>
      <td>0.277600</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003811</td>
      <td>0.003811</td>
      <td>0.003811</td>
      <td>0.281411</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.003673</td>
      <td>0.003673</td>
      <td>0.003673</td>
      <td>0.285084</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.357023e-01</td>
      <td>0.003655</td>
      <td>-0.003655</td>
      <td>0.003655</td>
      <td>0.281430</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003598</td>
      <td>-0.003598</td>
      <td>0.003598</td>
      <td>0.277832</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003555</td>
      <td>0.003555</td>
      <td>0.003555</td>
      <td>0.281387</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.827349e-222</td>
      <td>-0.003291</td>
      <td>0.003291</td>
      <td>0.003291</td>
      <td>0.284678</td>
    </tr>
    <tr>
      <th>1762</th>
      <td>wa so</td>
      <td>2.357023e-01</td>
      <td>-0.003232</td>
      <td>0.003232</td>
      <td>0.003232</td>
      <td>0.287909</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>6.000000e+00</td>
      <td>0.003015</td>
      <td>-0.003015</td>
      <td>0.003015</td>
      <td>0.284895</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002928</td>
      <td>0.002928</td>
      <td>0.002928</td>
      <td>0.287823</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.002924</td>
      <td>0.002924</td>
      <td>0.002924</td>
      <td>0.290747</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>2.357023e-01</td>
      <td>0.002841</td>
      <td>-0.002841</td>
      <td>0.002841</td>
      <td>0.287906</td>
    </tr>
    <tr>
      <th>1205</th>
      <td>portrayal</td>
      <td>0.000000e+00</td>
      <td>0.002779</td>
      <td>-0.002779</td>
      <td>0.002779</td>
      <td>0.285127</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002772</td>
      <td>0.002772</td>
      <td>0.002772</td>
      <td>0.287899</td>
    </tr>
    <tr>
      <th>1005</th>
      <td>never</td>
      <td>0.000000e+00</td>
      <td>0.002738</td>
      <td>-0.002738</td>
      <td>0.002738</td>
      <td>0.285161</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002716</td>
      <td>0.002716</td>
      <td>0.002716</td>
      <td>0.287876</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002710</td>
      <td>0.002710</td>
      <td>0.002710</td>
      <td>0.290586</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 154
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It&#39;s a shame to see good actors like Thomerson and James make a living in a mess like this.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3775 0.6225]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.171769</td>
      <td>0.171769</td>
      <td>0.171769</td>
      <td>0.671279</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.220000e-01</td>
      <td>0.070224</td>
      <td>-0.070224</td>
      <td>0.070224</td>
      <td>0.601055</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024538</td>
      <td>0.024538</td>
      <td>0.024538</td>
      <td>0.625592</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021398</td>
      <td>0.021398</td>
      <td>0.021398</td>
      <td>0.646990</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.182000e-01</td>
      <td>-0.019122</td>
      <td>0.019122</td>
      <td>0.019122</td>
      <td>0.666112</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.900000e+01</td>
      <td>0.013604</td>
      <td>-0.013604</td>
      <td>0.013604</td>
      <td>0.652508</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.300000e+01</td>
      <td>0.011227</td>
      <td>-0.011227</td>
      <td>0.011227</td>
      <td>0.641282</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>7.267134e-05</td>
      <td>0.010676</td>
      <td>-0.010676</td>
      <td>0.010676</td>
      <td>0.630606</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.625000e-01</td>
      <td>0.010494</td>
      <td>-0.010494</td>
      <td>0.010494</td>
      <td>0.620112</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008232</td>
      <td>-0.008232</td>
      <td>0.008232</td>
      <td>0.611880</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.731479e-158</td>
      <td>0.007966</td>
      <td>-0.007966</td>
      <td>0.007966</td>
      <td>0.603915</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006137</td>
      <td>-0.006137</td>
      <td>0.006137</td>
      <td>0.597778</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.005759</td>
      <td>0.005759</td>
      <td>0.005759</td>
      <td>0.603537</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>6.044926e-02</td>
      <td>0.005124</td>
      <td>-0.005124</td>
      <td>0.005124</td>
      <td>0.598413</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004075</td>
      <td>0.004075</td>
      <td>0.004075</td>
      <td>0.602488</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>2.425356e-01</td>
      <td>-0.003859</td>
      <td>0.003859</td>
      <td>0.003859</td>
      <td>0.606347</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003814</td>
      <td>-0.003814</td>
      <td>0.003814</td>
      <td>0.602532</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003366</td>
      <td>0.003366</td>
      <td>0.003366</td>
      <td>0.605898</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003212</td>
      <td>0.003212</td>
      <td>0.003212</td>
      <td>0.609111</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003024</td>
      <td>-0.003024</td>
      <td>0.003024</td>
      <td>0.606087</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>2.425356e-01</td>
      <td>-0.002767</td>
      <td>0.002767</td>
      <td>0.002767</td>
      <td>0.608853</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002761</td>
      <td>-0.002761</td>
      <td>0.002761</td>
      <td>0.606093</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>4.850713e-01</td>
      <td>-0.002751</td>
      <td>0.002751</td>
      <td>0.002751</td>
      <td>0.608843</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>2.425356e-01</td>
      <td>-0.002674</td>
      <td>0.002674</td>
      <td>0.002674</td>
      <td>0.611518</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002667</td>
      <td>0.002667</td>
      <td>0.002667</td>
      <td>0.614185</td>
    </tr>
    <tr>
      <th>254</th>
      <td>button</td>
      <td>0.000000e+00</td>
      <td>-0.002630</td>
      <td>0.002630</td>
      <td>0.002630</td>
      <td>0.616815</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002604</td>
      <td>-0.002604</td>
      <td>0.002604</td>
      <td>0.614211</td>
    </tr>
    <tr>
      <th>1315</th>
      <td>see</td>
      <td>2.425356e-01</td>
      <td>0.002590</td>
      <td>-0.002590</td>
      <td>0.002590</td>
      <td>0.611622</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002554</td>
      <td>0.002554</td>
      <td>0.002554</td>
      <td>0.614175</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.075624e-21</td>
      <td>-0.002524</td>
      <td>0.002524</td>
      <td>0.002524</td>
      <td>0.616700</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 167
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;The CG opening sequence in space looked like it could have been created on Microsoft Slideshow for God&#39;s sake!  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.38 0.62]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.165883</td>
      <td>0.165883</td>
      <td>0.165883</td>
      <td>0.665393</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.200000e-01</td>
      <td>0.072539</td>
      <td>-0.072539</td>
      <td>0.072539</td>
      <td>0.592854</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.848000e-01</td>
      <td>-0.048762</td>
      <td>0.048762</td>
      <td>0.048762</td>
      <td>0.641617</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.035987</td>
      <td>-0.035987</td>
      <td>0.035987</td>
      <td>0.605630</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.900000e+01</td>
      <td>0.026576</td>
      <td>-0.026576</td>
      <td>0.026576</td>
      <td>0.579054</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024391</td>
      <td>0.024391</td>
      <td>0.024391</td>
      <td>0.603445</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>6.000000e+00</td>
      <td>0.019655</td>
      <td>-0.019655</td>
      <td>0.019655</td>
      <td>0.583789</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019470</td>
      <td>0.019470</td>
      <td>0.019470</td>
      <td>0.603259</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.016032</td>
      <td>0.016032</td>
      <td>0.016032</td>
      <td>0.619291</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.120000e+02</td>
      <td>0.009054</td>
      <td>-0.009054</td>
      <td>0.009054</td>
      <td>0.610237</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008676</td>
      <td>-0.008676</td>
      <td>0.008676</td>
      <td>0.601561</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008230</td>
      <td>-0.008230</td>
      <td>0.008230</td>
      <td>0.593331</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007415</td>
      <td>-0.007415</td>
      <td>0.007415</td>
      <td>0.585916</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.886751e-01</td>
      <td>-0.006933</td>
      <td>0.006933</td>
      <td>0.006933</td>
      <td>0.592849</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006370</td>
      <td>-0.006370</td>
      <td>0.006370</td>
      <td>0.586479</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005235</td>
      <td>-0.005235</td>
      <td>0.005235</td>
      <td>0.581244</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005090</td>
      <td>-0.005090</td>
      <td>0.005090</td>
      <td>0.576154</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004061</td>
      <td>0.004061</td>
      <td>0.004061</td>
      <td>0.580216</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003865</td>
      <td>-0.003865</td>
      <td>0.003865</td>
      <td>0.576351</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>2.886751e-01</td>
      <td>-0.003863</td>
      <td>0.003863</td>
      <td>0.003863</td>
      <td>0.580214</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>6.955105e-21</td>
      <td>-0.003728</td>
      <td>0.003728</td>
      <td>0.003728</td>
      <td>0.583943</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003637</td>
      <td>0.003637</td>
      <td>0.003637</td>
      <td>0.587579</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003580</td>
      <td>0.003580</td>
      <td>0.003580</td>
      <td>0.591159</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003015</td>
      <td>0.003015</td>
      <td>0.003015</td>
      <td>0.594174</td>
    </tr>
    <tr>
      <th>2043</th>
      <td>topic 117</td>
      <td>2.279711e-04</td>
      <td>0.002992</td>
      <td>-0.002992</td>
      <td>0.002992</td>
      <td>0.591182</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>2.886751e-01</td>
      <td>-0.002990</td>
      <td>0.002990</td>
      <td>0.002990</td>
      <td>0.594172</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.002748</td>
      <td>-0.002748</td>
      <td>0.002748</td>
      <td>0.591424</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002725</td>
      <td>0.002725</td>
      <td>0.002725</td>
      <td>0.594149</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002700</td>
      <td>0.002700</td>
      <td>0.002700</td>
      <td>0.596849</td>
    </tr>
    <tr>
      <th>659</th>
      <td>have been</td>
      <td>2.886751e-01</td>
      <td>-0.002672</td>
      <td>0.002672</td>
      <td>0.002672</td>
      <td>0.599521</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 177
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;The film&#39;s sole bright spot was Jonah Hill (who will look almost unrecognizable to fans of the recent Superbad due to the amount of weight he lost in the interim).  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8625 0.1375]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.188925</td>
      <td>-0.188925</td>
      <td>0.188925</td>
      <td>0.310585</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>8.700000e-02</td>
      <td>0.066470</td>
      <td>-0.066470</td>
      <td>0.066470</td>
      <td>0.244115</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023164</td>
      <td>0.023164</td>
      <td>0.023164</td>
      <td>0.267279</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.437500e-01</td>
      <td>0.018906</td>
      <td>-0.018906</td>
      <td>0.018906</td>
      <td>0.248373</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016049</td>
      <td>0.016049</td>
      <td>0.016049</td>
      <td>0.264422</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.000000e+01</td>
      <td>0.015227</td>
      <td>-0.015227</td>
      <td>0.015227</td>
      <td>0.249195</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.650000e+02</td>
      <td>0.011617</td>
      <td>-0.011617</td>
      <td>0.011617</td>
      <td>0.237577</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008799</td>
      <td>-0.008799</td>
      <td>0.008799</td>
      <td>0.228778</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007792</td>
      <td>-0.007792</td>
      <td>0.007792</td>
      <td>0.220986</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.815484e-15</td>
      <td>0.006399</td>
      <td>-0.006399</td>
      <td>0.006399</td>
      <td>0.214587</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>0.006063</td>
      <td>-0.006063</td>
      <td>0.006063</td>
      <td>0.208524</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005683</td>
      <td>-0.005683</td>
      <td>0.005683</td>
      <td>0.202841</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>1.531000e-01</td>
      <td>-0.004786</td>
      <td>0.004786</td>
      <td>0.004786</td>
      <td>0.207627</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>2.000000e-01</td>
      <td>-0.004682</td>
      <td>0.004682</td>
      <td>0.004682</td>
      <td>0.212310</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>7.064417e-105</td>
      <td>0.004260</td>
      <td>-0.004260</td>
      <td>0.004260</td>
      <td>0.208050</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>8.938500e-93</td>
      <td>0.003867</td>
      <td>-0.003867</td>
      <td>0.003867</td>
      <td>0.204183</td>
    </tr>
    <tr>
      <th>2111</th>
      <td>topic 185</td>
      <td>2.132966e-02</td>
      <td>-0.003548</td>
      <td>0.003548</td>
      <td>0.003548</td>
      <td>0.207731</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003542</td>
      <td>0.003542</td>
      <td>0.003542</td>
      <td>0.211273</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003346</td>
      <td>-0.003346</td>
      <td>0.003346</td>
      <td>0.207927</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.003342</td>
      <td>-0.003342</td>
      <td>0.003342</td>
      <td>0.204585</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.143554e-223</td>
      <td>-0.003166</td>
      <td>0.003166</td>
      <td>0.003166</td>
      <td>0.207751</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.002970</td>
      <td>0.002970</td>
      <td>0.002970</td>
      <td>0.210722</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002650</td>
      <td>0.002650</td>
      <td>0.002650</td>
      <td>0.213371</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002516</td>
      <td>-0.002516</td>
      <td>0.002516</td>
      <td>0.210855</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002513</td>
      <td>-0.002513</td>
      <td>0.002513</td>
      <td>0.208342</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002493</td>
      <td>0.002493</td>
      <td>0.002493</td>
      <td>0.210835</td>
    </tr>
    <tr>
      <th>1389</th>
      <td>spot</td>
      <td>2.000000e-01</td>
      <td>-0.002422</td>
      <td>0.002422</td>
      <td>0.002422</td>
      <td>0.213257</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002374</td>
      <td>0.002374</td>
      <td>0.002374</td>
      <td>0.215631</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002335</td>
      <td>0.002335</td>
      <td>0.002335</td>
      <td>0.217966</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002245</td>
      <td>0.002245</td>
      <td>0.002245</td>
      <td>0.220211</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 183
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;It failed to convey the broad sweep of landscapes that were a great part of the original.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.4275 0.5725]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.084702</td>
      <td>0.084702</td>
      <td>0.084702</td>
      <td>0.584212</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.820000e-01</td>
      <td>0.069293</td>
      <td>-0.069293</td>
      <td>0.069293</td>
      <td>0.514919</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.767000e-01</td>
      <td>-0.040404</td>
      <td>0.040404</td>
      <td>0.040404</td>
      <td>0.555323</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026473</td>
      <td>0.026473</td>
      <td>0.026473</td>
      <td>0.581796</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021931</td>
      <td>0.021931</td>
      <td>0.021931</td>
      <td>0.603727</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.843750e-01</td>
      <td>0.020145</td>
      <td>-0.020145</td>
      <td>0.020145</td>
      <td>0.583582</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.700000e+01</td>
      <td>0.018171</td>
      <td>-0.018171</td>
      <td>0.018171</td>
      <td>0.565411</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>2.581989e-01</td>
      <td>-0.014022</td>
      <td>0.014022</td>
      <td>0.014022</td>
      <td>0.579433</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009685</td>
      <td>-0.009685</td>
      <td>0.009685</td>
      <td>0.569748</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.100000e+01</td>
      <td>0.008039</td>
      <td>-0.008039</td>
      <td>0.008039</td>
      <td>0.561709</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006447</td>
      <td>-0.006447</td>
      <td>0.006447</td>
      <td>0.555262</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.005891</td>
      <td>-0.005891</td>
      <td>0.005891</td>
      <td>0.549371</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>2.581989e-01</td>
      <td>-0.005597</td>
      <td>0.005597</td>
      <td>0.005597</td>
      <td>0.554968</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.434271e-02</td>
      <td>0.005512</td>
      <td>-0.005512</td>
      <td>0.005512</td>
      <td>0.549456</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005494</td>
      <td>-0.005494</td>
      <td>0.005494</td>
      <td>0.543962</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.427349e-309</td>
      <td>0.005254</td>
      <td>-0.005254</td>
      <td>0.005254</td>
      <td>0.538708</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004569</td>
      <td>-0.004569</td>
      <td>0.004569</td>
      <td>0.534139</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004482</td>
      <td>0.004482</td>
      <td>0.004482</td>
      <td>0.538621</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003775</td>
      <td>-0.003775</td>
      <td>0.003775</td>
      <td>0.534846</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003600</td>
      <td>0.003600</td>
      <td>0.003600</td>
      <td>0.538447</td>
    </tr>
    <tr>
      <th>1077</th>
      <td>of the</td>
      <td>2.581989e-01</td>
      <td>0.003559</td>
      <td>-0.003559</td>
      <td>0.003559</td>
      <td>0.534887</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003472</td>
      <td>0.003472</td>
      <td>0.003472</td>
      <td>0.538360</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003203</td>
      <td>0.003203</td>
      <td>0.003203</td>
      <td>0.541562</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003189</td>
      <td>-0.003189</td>
      <td>0.003189</td>
      <td>0.538374</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003166</td>
      <td>-0.003166</td>
      <td>0.003166</td>
      <td>0.535208</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003136</td>
      <td>0.003136</td>
      <td>0.003136</td>
      <td>0.538344</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003119</td>
      <td>0.003119</td>
      <td>0.003119</td>
      <td>0.541463</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003078</td>
      <td>0.003078</td>
      <td>0.003078</td>
      <td>0.544540</td>
    </tr>
    <tr>
      <th>595</th>
      <td>going back</td>
      <td>0.000000e+00</td>
      <td>-0.003021</td>
      <td>0.003021</td>
      <td>0.003021</td>
      <td>0.547561</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003014</td>
      <td>0.003014</td>
      <td>0.003014</td>
      <td>0.550576</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 196
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The characters were all funny and had the peculiarity of not having a true lead character.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.505 0.495]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>6.000000</td>
      <td>-0.142703</td>
      <td>0.142703</td>
      <td>0.142703</td>
      <td>0.642213</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.239000</td>
      <td>0.063946</td>
      <td>-0.063946</td>
      <td>0.063946</td>
      <td>0.578267</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000</td>
      <td>0.047610</td>
      <td>-0.047610</td>
      <td>0.047610</td>
      <td>0.530656</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.212350</td>
      <td>-0.020753</td>
      <td>0.020753</td>
      <td>0.020753</td>
      <td>0.551409</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>16.000000</td>
      <td>0.007942</td>
      <td>-0.007942</td>
      <td>0.007942</td>
      <td>0.543467</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.300000</td>
      <td>0.007803</td>
      <td>-0.007803</td>
      <td>0.007803</td>
      <td>0.535664</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007403</td>
      <td>-0.007403</td>
      <td>0.007403</td>
      <td>0.528261</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.007031</td>
      <td>-0.007031</td>
      <td>0.007031</td>
      <td>0.521230</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.288700</td>
      <td>-0.005730</td>
      <td>0.005730</td>
      <td>0.005730</td>
      <td>0.526959</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.005261</td>
      <td>-0.005261</td>
      <td>0.005261</td>
      <td>0.521698</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000</td>
      <td>0.004353</td>
      <td>-0.004353</td>
      <td>0.004353</td>
      <td>0.517345</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.003877</td>
      <td>-0.003877</td>
      <td>0.003877</td>
      <td>0.513468</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000</td>
      <td>0.003788</td>
      <td>-0.003788</td>
      <td>0.003788</td>
      <td>0.509680</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.258199</td>
      <td>0.003696</td>
      <td>-0.003696</td>
      <td>0.003696</td>
      <td>0.505984</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>0.389348</td>
      <td>0.003649</td>
      <td>-0.003649</td>
      <td>0.003649</td>
      <td>0.502335</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003131</td>
      <td>0.003131</td>
      <td>0.003131</td>
      <td>0.505466</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000</td>
      <td>0.002924</td>
      <td>-0.002924</td>
      <td>0.002924</td>
      <td>0.502542</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000</td>
      <td>0.002862</td>
      <td>-0.002862</td>
      <td>0.002862</td>
      <td>0.499680</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.002695</td>
      <td>-0.002695</td>
      <td>0.002695</td>
      <td>0.496985</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000</td>
      <td>-0.002616</td>
      <td>0.002616</td>
      <td>0.002616</td>
      <td>0.499601</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.002606</td>
      <td>0.002606</td>
      <td>0.002606</td>
      <td>0.502208</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.002517</td>
      <td>0.504725</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000</td>
      <td>-0.002514</td>
      <td>0.002514</td>
      <td>0.002514</td>
      <td>0.507238</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000</td>
      <td>0.002457</td>
      <td>-0.002457</td>
      <td>0.002457</td>
      <td>0.504782</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.002345</td>
      <td>0.002345</td>
      <td>0.002345</td>
      <td>0.507127</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000</td>
      <td>0.002310</td>
      <td>-0.002310</td>
      <td>0.002310</td>
      <td>0.504817</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.002184</td>
      <td>-0.002184</td>
      <td>0.002184</td>
      <td>0.502634</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000</td>
      <td>-0.002173</td>
      <td>0.002173</td>
      <td>0.002173</td>
      <td>0.504806</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000</td>
      <td>-0.002146</td>
      <td>0.002146</td>
      <td>0.002146</td>
      <td>0.506953</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002132</td>
      <td>0.002132</td>
      <td>0.002132</td>
      <td>0.509085</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 199
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Her lines seem to have been WRITTEN by a fifteen year old, though they are trying oh so, so hard to sound like how a fifteen year old would really, um, you know, well... talk.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.595 0.405]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.110215</td>
      <td>0.110215</td>
      <td>0.110215</td>
      <td>0.609724</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>7.000000e-02</td>
      <td>0.081303</td>
      <td>-0.081303</td>
      <td>0.081303</td>
      <td>0.528422</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.500000e+01</td>
      <td>0.027649</td>
      <td>-0.027649</td>
      <td>0.027649</td>
      <td>0.500772</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.016667e-01</td>
      <td>0.026412</td>
      <td>-0.026412</td>
      <td>0.026412</td>
      <td>0.474361</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025881</td>
      <td>0.025881</td>
      <td>0.025881</td>
      <td>0.500242</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>8.000000e+00</td>
      <td>0.024275</td>
      <td>-0.024275</td>
      <td>0.024275</td>
      <td>0.475966</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022096</td>
      <td>0.022096</td>
      <td>0.022096</td>
      <td>0.498062</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.360000e-02</td>
      <td>0.013786</td>
      <td>-0.013786</td>
      <td>0.013786</td>
      <td>0.484276</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>9.000000e+00</td>
      <td>0.010528</td>
      <td>-0.010528</td>
      <td>0.010528</td>
      <td>0.473748</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009721</td>
      <td>-0.009721</td>
      <td>0.009721</td>
      <td>0.464027</td>
    </tr>
    <tr>
      <th>2053</th>
      <td>topic 127</td>
      <td>1.203019e-01</td>
      <td>0.009327</td>
      <td>-0.009327</td>
      <td>0.009327</td>
      <td>0.454701</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008095</td>
      <td>-0.008095</td>
      <td>0.008095</td>
      <td>0.446606</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.756718e-79</td>
      <td>0.007804</td>
      <td>-0.007804</td>
      <td>0.007804</td>
      <td>0.438802</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>topic 78</td>
      <td>9.895492e-03</td>
      <td>0.007051</td>
      <td>-0.007051</td>
      <td>0.007051</td>
      <td>0.431751</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006658</td>
      <td>-0.006658</td>
      <td>0.006658</td>
      <td>0.425093</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006165</td>
      <td>-0.006165</td>
      <td>0.006165</td>
      <td>0.418929</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005345</td>
      <td>0.005345</td>
      <td>0.005345</td>
      <td>0.424274</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>topic 86</td>
      <td>2.968450e-01</td>
      <td>-0.005226</td>
      <td>0.005226</td>
      <td>0.005226</td>
      <td>0.429500</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.221394e-23</td>
      <td>0.004971</td>
      <td>-0.004971</td>
      <td>0.004971</td>
      <td>0.424528</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004329</td>
      <td>0.004329</td>
      <td>0.004329</td>
      <td>0.428857</td>
    </tr>
    <tr>
      <th>2059</th>
      <td>topic 133</td>
      <td>5.692796e-04</td>
      <td>-0.004293</td>
      <td>0.004293</td>
      <td>0.004293</td>
      <td>0.433151</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>1.490712e-01</td>
      <td>-0.004119</td>
      <td>0.004119</td>
      <td>0.004119</td>
      <td>0.437269</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004094</td>
      <td>0.004094</td>
      <td>0.004094</td>
      <td>0.441363</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004062</td>
      <td>-0.004062</td>
      <td>0.004062</td>
      <td>0.437301</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003896</td>
      <td>0.003896</td>
      <td>0.003896</td>
      <td>0.441197</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003661</td>
      <td>-0.003661</td>
      <td>0.003661</td>
      <td>0.437536</td>
    </tr>
    <tr>
      <th>1896</th>
      <td>year</td>
      <td>2.981424e-01</td>
      <td>0.003649</td>
      <td>-0.003649</td>
      <td>0.003649</td>
      <td>0.433887</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.770000e+02</td>
      <td>-0.003478</td>
      <td>0.003478</td>
      <td>0.003478</td>
      <td>0.437365</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003268</td>
      <td>0.003268</td>
      <td>0.003268</td>
      <td>0.440633</td>
    </tr>
    <tr>
      <th>2090</th>
      <td>topic 164</td>
      <td>5.387937e-03</td>
      <td>0.003140</td>
      <td>-0.003140</td>
      <td>0.003140</td>
      <td>0.437494</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 208
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;And the accents are absolutely abysmal!  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.6625 0.3375]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.095050</td>
      <td>-0.095050</td>
      <td>0.095050</td>
      <td>0.404460</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026117</td>
      <td>0.026117</td>
      <td>0.026117</td>
      <td>0.430577</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.020004</td>
      <td>0.020004</td>
      <td>0.020004</td>
      <td>0.450580</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018717</td>
      <td>0.018717</td>
      <td>0.018717</td>
      <td>0.469297</td>
    </tr>
    <tr>
      <th>2054</th>
      <td>topic 128</td>
      <td>5.407041e-01</td>
      <td>-0.011807</td>
      <td>0.011807</td>
      <td>0.011807</td>
      <td>0.481104</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.010203</td>
      <td>-0.010203</td>
      <td>0.010203</td>
      <td>0.470901</td>
    </tr>
    <tr>
      <th>9</th>
      <td>absolutely</td>
      <td>5.000000e-01</td>
      <td>-0.010103</td>
      <td>0.010103</td>
      <td>0.010103</td>
      <td>0.481004</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.009299</td>
      <td>0.009299</td>
      <td>0.009299</td>
      <td>0.490303</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>6.000000e+00</td>
      <td>0.008243</td>
      <td>-0.008243</td>
      <td>0.008243</td>
      <td>0.482060</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.031218e-177</td>
      <td>0.007743</td>
      <td>-0.007743</td>
      <td>0.007743</td>
      <td>0.474317</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007511</td>
      <td>-0.007511</td>
      <td>0.007511</td>
      <td>0.466806</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.500000e-01</td>
      <td>0.007410</td>
      <td>-0.007410</td>
      <td>0.007410</td>
      <td>0.459396</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.100000e+01</td>
      <td>0.007005</td>
      <td>-0.007005</td>
      <td>0.007005</td>
      <td>0.452391</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006420</td>
      <td>-0.006420</td>
      <td>0.006420</td>
      <td>0.445971</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.006018</td>
      <td>0.006018</td>
      <td>0.006018</td>
      <td>0.451988</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.005846</td>
      <td>-0.005846</td>
      <td>0.005846</td>
      <td>0.446142</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.005688</td>
      <td>0.005688</td>
      <td>0.005688</td>
      <td>0.451829</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005258</td>
      <td>0.005258</td>
      <td>0.005258</td>
      <td>0.457088</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004869</td>
      <td>-0.004869</td>
      <td>0.004869</td>
      <td>0.452218</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004163</td>
      <td>-0.004163</td>
      <td>0.004163</td>
      <td>0.448055</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004117</td>
      <td>0.004117</td>
      <td>0.004117</td>
      <td>0.452172</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003953</td>
      <td>-0.003953</td>
      <td>0.003953</td>
      <td>0.448219</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003869</td>
      <td>-0.003869</td>
      <td>0.003869</td>
      <td>0.444350</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003609</td>
      <td>0.003609</td>
      <td>0.003609</td>
      <td>0.447960</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003336</td>
      <td>-0.003336</td>
      <td>0.003336</td>
      <td>0.444624</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003314</td>
      <td>0.003314</td>
      <td>0.003314</td>
      <td>0.447938</td>
    </tr>
    <tr>
      <th>1929</th>
      <td>topic 3</td>
      <td>0.000000e+00</td>
      <td>-0.003254</td>
      <td>0.003254</td>
      <td>0.003254</td>
      <td>0.451192</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003200</td>
      <td>-0.003200</td>
      <td>0.003200</td>
      <td>0.447992</td>
    </tr>
    <tr>
      <th>1400</th>
      <td>stay</td>
      <td>0.000000e+00</td>
      <td>-0.003106</td>
      <td>0.003106</td>
      <td>0.003106</td>
      <td>0.451097</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003064</td>
      <td>0.003064</td>
      <td>0.003064</td>
      <td>0.454162</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 213
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Go watch it!  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7625 0.2375]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.085085</td>
      <td>-0.085085</td>
      <td>0.085085</td>
      <td>0.414425</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.000000</td>
      <td>0.034645</td>
      <td>-0.034645</td>
      <td>0.034645</td>
      <td>0.379780</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025424</td>
      <td>0.025424</td>
      <td>0.025424</td>
      <td>0.405204</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000</td>
      <td>0.025381</td>
      <td>-0.025381</td>
      <td>0.025381</td>
      <td>0.379824</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000</td>
      <td>-0.023863</td>
      <td>0.023863</td>
      <td>0.023863</td>
      <td>0.403687</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.018988</td>
      <td>0.018988</td>
      <td>0.018988</td>
      <td>0.422675</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>-0.014042</td>
      <td>0.014042</td>
      <td>0.014042</td>
      <td>0.436717</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009688</td>
      <td>-0.009688</td>
      <td>0.009688</td>
      <td>0.427029</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.009012</td>
      <td>-0.009012</td>
      <td>0.009012</td>
      <td>0.418017</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.007670</td>
      <td>-0.007670</td>
      <td>0.007670</td>
      <td>0.410348</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007511</td>
      <td>-0.007511</td>
      <td>0.007511</td>
      <td>0.402836</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006518</td>
      <td>-0.006518</td>
      <td>0.006518</td>
      <td>0.396318</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>0.000014</td>
      <td>-0.005598</td>
      <td>0.005598</td>
      <td>0.005598</td>
      <td>0.401917</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>0.005099</td>
      <td>-0.005099</td>
      <td>0.005099</td>
      <td>0.396818</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000</td>
      <td>0.005010</td>
      <td>-0.005010</td>
      <td>0.005010</td>
      <td>0.391808</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004954</td>
      <td>-0.004954</td>
      <td>0.004954</td>
      <td>0.386854</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.004726</td>
      <td>-0.004726</td>
      <td>0.004726</td>
      <td>0.382128</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.004647</td>
      <td>0.004647</td>
      <td>0.004647</td>
      <td>0.386775</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>14.000000</td>
      <td>0.004515</td>
      <td>-0.004515</td>
      <td>0.004515</td>
      <td>0.382260</td>
    </tr>
    <tr>
      <th>1174</th>
      <td>place</td>
      <td>0.000000</td>
      <td>0.004318</td>
      <td>-0.004318</td>
      <td>0.004318</td>
      <td>0.377942</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000</td>
      <td>0.004213</td>
      <td>-0.004213</td>
      <td>0.004213</td>
      <td>0.373729</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.004088</td>
      <td>0.004088</td>
      <td>0.004088</td>
      <td>0.377817</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000</td>
      <td>0.003923</td>
      <td>-0.003923</td>
      <td>0.003923</td>
      <td>0.373894</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.003718</td>
      <td>0.003718</td>
      <td>0.003718</td>
      <td>0.377612</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003531</td>
      <td>0.003531</td>
      <td>0.003531</td>
      <td>0.381142</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000</td>
      <td>0.003530</td>
      <td>-0.003530</td>
      <td>0.003530</td>
      <td>0.377612</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003426</td>
      <td>0.003426</td>
      <td>0.003426</td>
      <td>0.381038</td>
    </tr>
    <tr>
      <th>1400</th>
      <td>stay</td>
      <td>0.000000</td>
      <td>-0.003357</td>
      <td>0.003357</td>
      <td>0.003357</td>
      <td>0.384395</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000015</td>
      <td>-0.003321</td>
      <td>0.003321</td>
      <td>0.003321</td>
      <td>0.387716</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000</td>
      <td>-0.003263</td>
      <td>0.003263</td>
      <td>0.003263</td>
      <td>0.390979</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 219
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Don&#39;t miss it.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8675 0.1325]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.0000</td>
      <td>0.171403</td>
      <td>-0.171403</td>
      <td>0.171403</td>
      <td>0.328107</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.4190</td>
      <td>0.037054</td>
      <td>-0.037054</td>
      <td>0.037054</td>
      <td>0.291053</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.0000</td>
      <td>0.029418</td>
      <td>-0.029418</td>
      <td>0.029418</td>
      <td>0.261635</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.0000</td>
      <td>-0.022221</td>
      <td>0.022221</td>
      <td>0.022221</td>
      <td>0.283856</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>16.0000</td>
      <td>0.015006</td>
      <td>-0.015006</td>
      <td>0.015006</td>
      <td>0.268850</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.0000</td>
      <td>0.013142</td>
      <td>-0.013142</td>
      <td>0.013142</td>
      <td>0.255708</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.1139</td>
      <td>0.011933</td>
      <td>-0.011933</td>
      <td>0.011933</td>
      <td>0.243775</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.0000</td>
      <td>0.008762</td>
      <td>-0.008762</td>
      <td>0.008762</td>
      <td>0.235013</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.0000</td>
      <td>0.008690</td>
      <td>-0.008690</td>
      <td>0.008690</td>
      <td>0.226323</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.0000</td>
      <td>0.008369</td>
      <td>-0.008369</td>
      <td>0.008369</td>
      <td>0.217954</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.0000</td>
      <td>0.006490</td>
      <td>-0.006490</td>
      <td>0.006490</td>
      <td>0.211464</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.0000</td>
      <td>0.005417</td>
      <td>-0.005417</td>
      <td>0.005417</td>
      <td>0.206047</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.5000</td>
      <td>0.004461</td>
      <td>-0.004461</td>
      <td>0.004461</td>
      <td>0.201586</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.0000</td>
      <td>0.003925</td>
      <td>-0.003925</td>
      <td>0.003925</td>
      <td>0.197661</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.0000</td>
      <td>0.003773</td>
      <td>-0.003773</td>
      <td>0.003773</td>
      <td>0.193888</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.0000</td>
      <td>-0.003483</td>
      <td>0.003483</td>
      <td>0.003483</td>
      <td>0.197371</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.0000</td>
      <td>0.003432</td>
      <td>-0.003432</td>
      <td>0.003432</td>
      <td>0.193939</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.0000</td>
      <td>-0.003141</td>
      <td>0.003141</td>
      <td>0.003141</td>
      <td>0.197081</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.0000</td>
      <td>0.003003</td>
      <td>-0.003003</td>
      <td>0.003003</td>
      <td>0.194078</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.0000</td>
      <td>-0.002889</td>
      <td>0.002889</td>
      <td>0.002889</td>
      <td>0.196967</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.0000</td>
      <td>-0.002882</td>
      <td>0.002882</td>
      <td>0.002882</td>
      <td>0.199849</td>
    </tr>
    <tr>
      <th>1908</th>
      <td>you ll</td>
      <td>0.0000</td>
      <td>0.002713</td>
      <td>-0.002713</td>
      <td>0.002713</td>
      <td>0.197137</td>
    </tr>
    <tr>
      <th>254</th>
      <td>button</td>
      <td>0.0000</td>
      <td>-0.002666</td>
      <td>0.002666</td>
      <td>0.002666</td>
      <td>0.199802</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.0000</td>
      <td>-0.002499</td>
      <td>0.002499</td>
      <td>0.002499</td>
      <td>0.202302</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.0000</td>
      <td>-0.002448</td>
      <td>0.002448</td>
      <td>0.002448</td>
      <td>0.204750</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.0000</td>
      <td>0.002445</td>
      <td>-0.002445</td>
      <td>0.002445</td>
      <td>0.202304</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.0000</td>
      <td>-0.002347</td>
      <td>0.002347</td>
      <td>0.002347</td>
      <td>0.204651</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.0000</td>
      <td>-0.002327</td>
      <td>0.002327</td>
      <td>0.002327</td>
      <td>0.206978</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>0.0000</td>
      <td>-0.002190</td>
      <td>0.002190</td>
      <td>0.002190</td>
      <td>0.209168</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.5000</td>
      <td>-0.002162</td>
      <td>0.002162</td>
      <td>0.002162</td>
      <td>0.211329</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 233
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;I know that Jim O&#39;Connor was very energetic and that nobody could be as much as him, but George was well dull.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.675 0.325]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.800000e-01</td>
      <td>0.076981</td>
      <td>-0.076981</td>
      <td>0.076981</td>
      <td>0.422529</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>-0.027344</td>
      <td>0.027344</td>
      <td>0.027344</td>
      <td>0.449873</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025140</td>
      <td>0.025140</td>
      <td>0.025140</td>
      <td>0.475013</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019531</td>
      <td>0.019531</td>
      <td>0.019531</td>
      <td>0.494544</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.200000e+01</td>
      <td>0.015096</td>
      <td>-0.015096</td>
      <td>0.015096</td>
      <td>0.479448</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.861111e-01</td>
      <td>0.013498</td>
      <td>-0.013498</td>
      <td>0.013498</td>
      <td>0.465949</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.070000e-02</td>
      <td>0.010489</td>
      <td>-0.010489</td>
      <td>0.010489</td>
      <td>0.455460</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009669</td>
      <td>-0.009669</td>
      <td>0.009669</td>
      <td>0.445790</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.008831</td>
      <td>-0.008831</td>
      <td>0.008831</td>
      <td>0.436959</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007427</td>
      <td>-0.007427</td>
      <td>0.007427</td>
      <td>0.429532</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.007245</td>
      <td>-0.007245</td>
      <td>0.007245</td>
      <td>0.422288</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006674</td>
      <td>-0.006674</td>
      <td>0.006674</td>
      <td>0.415614</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006413</td>
      <td>-0.006413</td>
      <td>0.006413</td>
      <td>0.409201</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>4.472136e-01</td>
      <td>-0.005303</td>
      <td>0.005303</td>
      <td>0.005303</td>
      <td>0.414504</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005066</td>
      <td>0.005066</td>
      <td>0.005066</td>
      <td>0.419570</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004835</td>
      <td>-0.004835</td>
      <td>0.004835</td>
      <td>0.414735</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>2.236068e-01</td>
      <td>-0.004689</td>
      <td>0.004689</td>
      <td>0.004689</td>
      <td>0.419424</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003846</td>
      <td>0.003846</td>
      <td>0.003846</td>
      <td>0.423270</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003771</td>
      <td>0.003771</td>
      <td>0.003771</td>
      <td>0.427041</td>
    </tr>
    <tr>
      <th>2023</th>
      <td>topic 97</td>
      <td>5.496492e-01</td>
      <td>0.003690</td>
      <td>-0.003690</td>
      <td>0.003690</td>
      <td>0.423351</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003663</td>
      <td>0.003663</td>
      <td>0.003663</td>
      <td>0.427014</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003458</td>
      <td>0.003458</td>
      <td>0.003458</td>
      <td>0.430471</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003369</td>
      <td>0.003369</td>
      <td>0.003369</td>
      <td>0.433841</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>6.351955e-144</td>
      <td>-0.003261</td>
      <td>0.003261</td>
      <td>0.003261</td>
      <td>0.437101</td>
    </tr>
    <tr>
      <th>1618</th>
      <td>time</td>
      <td>0.000000e+00</td>
      <td>0.003133</td>
      <td>-0.003133</td>
      <td>0.003133</td>
      <td>0.433969</td>
    </tr>
    <tr>
      <th>344</th>
      <td>could</td>
      <td>2.236068e-01</td>
      <td>-0.003128</td>
      <td>0.003128</td>
      <td>0.003128</td>
      <td>0.437097</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003062</td>
      <td>-0.003062</td>
      <td>0.003062</td>
      <td>0.434035</td>
    </tr>
    <tr>
      <th>692</th>
      <td>him</td>
      <td>2.236068e-01</td>
      <td>-0.003053</td>
      <td>0.003053</td>
      <td>0.003053</td>
      <td>0.437088</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003032</td>
      <td>-0.003032</td>
      <td>0.003032</td>
      <td>0.434056</td>
    </tr>
    <tr>
      <th>1932</th>
      <td>topic 6</td>
      <td>0.000000e+00</td>
      <td>0.002898</td>
      <td>-0.002898</td>
      <td>0.002898</td>
      <td>0.431158</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 242
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;There&#39;s barely a boring moment in the film and there are plenty of humorous parts.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9075 0.0925]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.165313</td>
      <td>-0.165313</td>
      <td>0.165313</td>
      <td>0.334197</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.570000e-01</td>
      <td>0.065721</td>
      <td>-0.065721</td>
      <td>0.065721</td>
      <td>0.268476</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-2.500000e-01</td>
      <td>0.043606</td>
      <td>-0.043606</td>
      <td>0.043606</td>
      <td>0.224870</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023223</td>
      <td>0.023223</td>
      <td>0.023223</td>
      <td>0.248093</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.500000e+01</td>
      <td>0.022289</td>
      <td>-0.022289</td>
      <td>0.022289</td>
      <td>0.225804</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016567</td>
      <td>0.016567</td>
      <td>0.016567</td>
      <td>0.242370</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009094</td>
      <td>-0.009094</td>
      <td>0.009094</td>
      <td>0.233276</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.257055e-153</td>
      <td>0.006573</td>
      <td>-0.006573</td>
      <td>0.006573</td>
      <td>0.226703</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005973</td>
      <td>-0.005973</td>
      <td>0.005973</td>
      <td>0.220730</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.005812</td>
      <td>-0.005812</td>
      <td>0.005812</td>
      <td>0.214918</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>4.850713e-01</td>
      <td>0.005576</td>
      <td>-0.005576</td>
      <td>0.005576</td>
      <td>0.209342</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004637</td>
      <td>-0.004637</td>
      <td>0.004637</td>
      <td>0.204705</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.400000e+01</td>
      <td>0.004256</td>
      <td>-0.004256</td>
      <td>0.004256</td>
      <td>0.200449</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003467</td>
      <td>0.003467</td>
      <td>0.003467</td>
      <td>0.203916</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.506795e-221</td>
      <td>-0.003291</td>
      <td>0.003291</td>
      <td>0.003291</td>
      <td>0.207207</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003126</td>
      <td>-0.003126</td>
      <td>0.003126</td>
      <td>0.204080</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002964</td>
      <td>0.002964</td>
      <td>0.002964</td>
      <td>0.207044</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002877</td>
      <td>-0.002877</td>
      <td>0.002877</td>
      <td>0.204167</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002724</td>
      <td>0.002724</td>
      <td>0.002724</td>
      <td>0.206891</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002648</td>
      <td>0.002648</td>
      <td>0.002648</td>
      <td>0.209539</td>
    </tr>
    <tr>
      <th>291</th>
      <td>character</td>
      <td>0.000000e+00</td>
      <td>0.002475</td>
      <td>-0.002475</td>
      <td>0.002475</td>
      <td>0.207065</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002453</td>
      <td>-0.002453</td>
      <td>0.002453</td>
      <td>0.204611</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002354</td>
      <td>0.002354</td>
      <td>0.002354</td>
      <td>0.206965</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002342</td>
      <td>0.002342</td>
      <td>0.002342</td>
      <td>0.209308</td>
    </tr>
    <tr>
      <th>1637</th>
      <td>to it</td>
      <td>0.000000e+00</td>
      <td>0.002342</td>
      <td>-0.002342</td>
      <td>0.002342</td>
      <td>0.206966</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>7.779892e-245</td>
      <td>0.002263</td>
      <td>-0.002263</td>
      <td>0.002263</td>
      <td>0.204703</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002109</td>
      <td>-0.002109</td>
      <td>0.002109</td>
      <td>0.202594</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002107</td>
      <td>-0.002107</td>
      <td>0.002107</td>
      <td>0.200486</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.002081</td>
      <td>-0.002081</td>
      <td>0.002081</td>
      <td>0.198405</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002007</td>
      <td>0.002007</td>
      <td>0.002007</td>
      <td>0.200412</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 247
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The least said about the acting the better.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.4125 0.5875]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.167712</td>
      <td>0.167712</td>
      <td>0.167712</td>
      <td>0.667222</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.930000e-01</td>
      <td>0.072413</td>
      <td>-0.072413</td>
      <td>0.072413</td>
      <td>0.594808</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>6.666667e-02</td>
      <td>0.039341</td>
      <td>-0.039341</td>
      <td>0.039341</td>
      <td>0.555468</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.404000e-01</td>
      <td>-0.031638</td>
      <td>0.031638</td>
      <td>0.031638</td>
      <td>0.587106</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.025849</td>
      <td>-0.025849</td>
      <td>0.025849</td>
      <td>0.561257</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025604</td>
      <td>0.025604</td>
      <td>0.025604</td>
      <td>0.586861</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020931</td>
      <td>0.020931</td>
      <td>0.020931</td>
      <td>0.607792</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009236</td>
      <td>-0.009236</td>
      <td>0.009236</td>
      <td>0.598556</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008939</td>
      <td>-0.008939</td>
      <td>0.008939</td>
      <td>0.589617</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007607</td>
      <td>-0.007607</td>
      <td>0.007607</td>
      <td>0.582010</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006678</td>
      <td>-0.006678</td>
      <td>0.006678</td>
      <td>0.575332</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005427</td>
      <td>-0.005427</td>
      <td>0.005427</td>
      <td>0.569905</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.216659e-195</td>
      <td>0.005167</td>
      <td>-0.005167</td>
      <td>0.005167</td>
      <td>0.564738</td>
    </tr>
    <tr>
      <th>2031</th>
      <td>topic 105</td>
      <td>1.044358e-02</td>
      <td>-0.005149</td>
      <td>0.005149</td>
      <td>0.005149</td>
      <td>0.569888</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.005094</td>
      <td>-0.005094</td>
      <td>0.005094</td>
      <td>0.564794</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004480</td>
      <td>-0.004480</td>
      <td>0.004480</td>
      <td>0.560314</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.500000e+01</td>
      <td>0.004348</td>
      <td>-0.004348</td>
      <td>0.004348</td>
      <td>0.555966</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003975</td>
      <td>0.003975</td>
      <td>0.003975</td>
      <td>0.559941</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003581</td>
      <td>0.003581</td>
      <td>0.003581</td>
      <td>0.563521</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003195</td>
      <td>0.003195</td>
      <td>0.003195</td>
      <td>0.566716</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003075</td>
      <td>-0.003075</td>
      <td>0.003075</td>
      <td>0.563641</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003038</td>
      <td>-0.003038</td>
      <td>0.003038</td>
      <td>0.560604</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002962</td>
      <td>0.002962</td>
      <td>0.002962</td>
      <td>0.563566</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.002946</td>
      <td>0.002946</td>
      <td>0.002946</td>
      <td>0.566512</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002923</td>
      <td>0.002923</td>
      <td>0.002923</td>
      <td>0.569435</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002909</td>
      <td>-0.002909</td>
      <td>0.002909</td>
      <td>0.566526</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>7.727532e-03</td>
      <td>-0.002889</td>
      <td>0.002889</td>
      <td>0.002889</td>
      <td>0.569416</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002861</td>
      <td>0.002861</td>
      <td>0.002861</td>
      <td>0.572276</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002813</td>
      <td>0.002813</td>
      <td>0.002813</td>
      <td>0.575089</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002798</td>
      <td>-0.002798</td>
      <td>0.002798</td>
      <td>0.572291</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 249
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I believe every one should see this movie as I think few people outside of South Africa understand its past and what is being attempted in the Truth and Reconciliation process.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7125 0.2875]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>7.600000e-02</td>
      <td>0.078014</td>
      <td>-0.078014</td>
      <td>0.078014</td>
      <td>0.421496</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.500000e-01</td>
      <td>0.056706</td>
      <td>-0.056706</td>
      <td>0.056706</td>
      <td>0.364790</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.182000e-01</td>
      <td>-0.048026</td>
      <td>0.048026</td>
      <td>0.048026</td>
      <td>0.412816</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025883</td>
      <td>0.025883</td>
      <td>0.025883</td>
      <td>0.438699</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.100000e+01</td>
      <td>0.024062</td>
      <td>-0.024062</td>
      <td>0.024062</td>
      <td>0.414637</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018885</td>
      <td>0.018885</td>
      <td>0.018885</td>
      <td>0.433522</td>
    </tr>
    <tr>
      <th>2096</th>
      <td>topic 170</td>
      <td>3.892664e-04</td>
      <td>-0.012706</td>
      <td>0.012706</td>
      <td>0.012706</td>
      <td>0.446229</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.780000e+02</td>
      <td>0.010725</td>
      <td>-0.010725</td>
      <td>0.010725</td>
      <td>0.435504</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009906</td>
      <td>-0.009906</td>
      <td>0.009906</td>
      <td>0.425597</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.609383e-137</td>
      <td>0.007550</td>
      <td>-0.007550</td>
      <td>0.007550</td>
      <td>0.418047</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006419</td>
      <td>-0.006419</td>
      <td>0.006419</td>
      <td>0.411628</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.006289</td>
      <td>-0.006289</td>
      <td>0.006289</td>
      <td>0.405339</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.041241e-01</td>
      <td>0.005717</td>
      <td>-0.005717</td>
      <td>0.005717</td>
      <td>0.399622</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>topic 78</td>
      <td>1.726945e-01</td>
      <td>0.005585</td>
      <td>-0.005585</td>
      <td>0.005585</td>
      <td>0.394037</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005561</td>
      <td>0.005561</td>
      <td>0.005561</td>
      <td>0.399598</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>6.000000e+00</td>
      <td>-0.005177</td>
      <td>0.005177</td>
      <td>0.005177</td>
      <td>0.404775</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.109191e-138</td>
      <td>0.004932</td>
      <td>-0.004932</td>
      <td>0.004932</td>
      <td>0.399843</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004627</td>
      <td>-0.004627</td>
      <td>0.004627</td>
      <td>0.395216</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.004195</td>
      <td>-0.004195</td>
      <td>0.004195</td>
      <td>0.391021</td>
    </tr>
    <tr>
      <th>196</th>
      <td>being</td>
      <td>2.041241e-01</td>
      <td>-0.003737</td>
      <td>0.003737</td>
      <td>0.003737</td>
      <td>0.394758</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003710</td>
      <td>0.003710</td>
      <td>0.003710</td>
      <td>0.398469</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003535</td>
      <td>0.003535</td>
      <td>0.003535</td>
      <td>0.402003</td>
    </tr>
    <tr>
      <th>2003</th>
      <td>topic 77</td>
      <td>6.908195e-03</td>
      <td>0.003328</td>
      <td>-0.003328</td>
      <td>0.003328</td>
      <td>0.398676</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>9.809991e-90</td>
      <td>-0.003177</td>
      <td>0.003177</td>
      <td>0.003177</td>
      <td>0.401852</td>
    </tr>
    <tr>
      <th>1932</th>
      <td>topic 6</td>
      <td>0.000000e+00</td>
      <td>0.003173</td>
      <td>-0.003173</td>
      <td>0.003173</td>
      <td>0.398679</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>3.128247e-193</td>
      <td>0.003159</td>
      <td>-0.003159</td>
      <td>0.003159</td>
      <td>0.395520</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003111</td>
      <td>0.003111</td>
      <td>0.003111</td>
      <td>0.398631</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003097</td>
      <td>0.003097</td>
      <td>0.003097</td>
      <td>0.401728</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002983</td>
      <td>0.002983</td>
      <td>0.002983</td>
      <td>0.404711</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.002966</td>
      <td>-0.002966</td>
      <td>0.002966</td>
      <td>0.401744</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 250
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Nothing short of magnificent photography/cinematography in this film.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.57 0.43]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.144950</td>
      <td>0.144950</td>
      <td>0.144950</td>
      <td>0.644460</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.847000e-01</td>
      <td>0.120108</td>
      <td>-0.120108</td>
      <td>0.120108</td>
      <td>0.524352</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.070423</td>
      <td>-0.070423</td>
      <td>0.070423</td>
      <td>0.453929</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.039323</td>
      <td>-0.039323</td>
      <td>0.039323</td>
      <td>0.414606</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.000000e-01</td>
      <td>-0.023600</td>
      <td>0.023600</td>
      <td>0.023600</td>
      <td>0.438205</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019517</td>
      <td>0.019517</td>
      <td>0.019517</td>
      <td>0.457723</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007642</td>
      <td>-0.007642</td>
      <td>0.007642</td>
      <td>0.450081</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.257718e-153</td>
      <td>0.007151</td>
      <td>-0.007151</td>
      <td>0.007151</td>
      <td>0.442930</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>7.100000e+01</td>
      <td>-0.006707</td>
      <td>0.006707</td>
      <td>0.006707</td>
      <td>0.449636</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.005949</td>
      <td>-0.005949</td>
      <td>0.005949</td>
      <td>0.443687</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005080</td>
      <td>-0.005080</td>
      <td>0.005080</td>
      <td>0.438607</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.004563</td>
      <td>0.004563</td>
      <td>0.004563</td>
      <td>0.443170</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004247</td>
      <td>0.004247</td>
      <td>0.004247</td>
      <td>0.447417</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.004034</td>
      <td>-0.004034</td>
      <td>0.004034</td>
      <td>0.443383</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.061221e-19</td>
      <td>0.003993</td>
      <td>-0.003993</td>
      <td>0.003993</td>
      <td>0.439390</td>
    </tr>
    <tr>
      <th>501</th>
      <td>film</td>
      <td>3.333333e-01</td>
      <td>-0.003865</td>
      <td>0.003865</td>
      <td>0.003865</td>
      <td>0.443254</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003736</td>
      <td>0.003736</td>
      <td>0.003736</td>
      <td>0.446990</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>0.003426</td>
      <td>-0.003426</td>
      <td>0.003426</td>
      <td>0.443564</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>3.333333e-01</td>
      <td>0.003228</td>
      <td>-0.003228</td>
      <td>0.003228</td>
      <td>0.440337</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>0.000000e+00</td>
      <td>-0.003056</td>
      <td>0.003056</td>
      <td>0.003056</td>
      <td>0.443393</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003049</td>
      <td>0.003049</td>
      <td>0.003049</td>
      <td>0.446441</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.002926</td>
      <td>-0.002926</td>
      <td>0.002926</td>
      <td>0.443515</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.002917</td>
      <td>-0.002917</td>
      <td>0.002917</td>
      <td>0.440598</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002654</td>
      <td>0.002654</td>
      <td>0.002654</td>
      <td>0.443252</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002633</td>
      <td>0.002633</td>
      <td>0.002633</td>
      <td>0.445885</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>0.000000e+00</td>
      <td>-0.002612</td>
      <td>0.002612</td>
      <td>0.002612</td>
      <td>0.448497</td>
    </tr>
    <tr>
      <th>543</th>
      <td>forced</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.450997</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.453497</td>
    </tr>
    <tr>
      <th>130</th>
      <td>aren</td>
      <td>0.000000e+00</td>
      <td>-0.002479</td>
      <td>0.002479</td>
      <td>0.002479</td>
      <td>0.455976</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>7.579207e-222</td>
      <td>-0.002457</td>
      <td>0.002457</td>
      <td>0.002457</td>
      <td>0.458433</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 252
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Don&#39;t be afraid of subtitles........ its worth a little aversion therapy 10/10  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8575 0.1425]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.410000e-01</td>
      <td>0.063723</td>
      <td>-0.063723</td>
      <td>0.063723</td>
      <td>0.435787</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-1.796000e-01</td>
      <td>0.052496</td>
      <td>-0.052496</td>
      <td>0.052496</td>
      <td>0.383291</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.625000e-01</td>
      <td>0.046714</td>
      <td>-0.046714</td>
      <td>0.046714</td>
      <td>0.336577</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.024273</td>
      <td>-0.024273</td>
      <td>0.024273</td>
      <td>0.312303</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023929</td>
      <td>0.023929</td>
      <td>0.023929</td>
      <td>0.336233</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009301</td>
      <td>-0.009301</td>
      <td>0.009301</td>
      <td>0.326932</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007752</td>
      <td>-0.007752</td>
      <td>0.007752</td>
      <td>0.319180</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.266785e-137</td>
      <td>0.007321</td>
      <td>-0.007321</td>
      <td>0.007321</td>
      <td>0.311859</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006110</td>
      <td>-0.006110</td>
      <td>0.006110</td>
      <td>0.305749</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006055</td>
      <td>-0.006055</td>
      <td>0.006055</td>
      <td>0.299694</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>3.333333e-01</td>
      <td>-0.005933</td>
      <td>0.005933</td>
      <td>0.005933</td>
      <td>0.305627</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+01</td>
      <td>0.005468</td>
      <td>-0.005468</td>
      <td>0.005468</td>
      <td>0.300160</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004428</td>
      <td>-0.004428</td>
      <td>0.004428</td>
      <td>0.295731</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.000000e+01</td>
      <td>0.004381</td>
      <td>-0.004381</td>
      <td>0.004381</td>
      <td>0.291350</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>3.333333e-01</td>
      <td>-0.004150</td>
      <td>0.004150</td>
      <td>0.004150</td>
      <td>0.295500</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>3.333333e-01</td>
      <td>0.004128</td>
      <td>-0.004128</td>
      <td>0.004128</td>
      <td>0.291372</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.003896</td>
      <td>-0.003896</td>
      <td>0.003896</td>
      <td>0.287477</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003782</td>
      <td>-0.003782</td>
      <td>0.003782</td>
      <td>0.283695</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.003548</td>
      <td>0.003548</td>
      <td>0.003548</td>
      <td>0.287242</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000e+00</td>
      <td>0.003493</td>
      <td>-0.003493</td>
      <td>0.003493</td>
      <td>0.283750</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.003399</td>
      <td>-0.003399</td>
      <td>0.003399</td>
      <td>0.280351</td>
    </tr>
    <tr>
      <th>275</th>
      <td>can not</td>
      <td>0.000000e+00</td>
      <td>0.003323</td>
      <td>-0.003323</td>
      <td>0.003323</td>
      <td>0.277028</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.339605e-221</td>
      <td>-0.003218</td>
      <td>0.003218</td>
      <td>0.003218</td>
      <td>0.280246</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003161</td>
      <td>0.003161</td>
      <td>0.003161</td>
      <td>0.283407</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.003121</td>
      <td>0.003121</td>
      <td>0.003121</td>
      <td>0.286528</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003013</td>
      <td>-0.003013</td>
      <td>0.003013</td>
      <td>0.283515</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002927</td>
      <td>0.002927</td>
      <td>0.002927</td>
      <td>0.286442</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.002846</td>
      <td>-0.002846</td>
      <td>0.002846</td>
      <td>0.283595</td>
    </tr>
    <tr>
      <th>1306</th>
      <td>scene</td>
      <td>0.000000e+00</td>
      <td>-0.002840</td>
      <td>0.002840</td>
      <td>0.002840</td>
      <td>0.286435</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002833</td>
      <td>0.002833</td>
      <td>0.002833</td>
      <td>0.289268</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 257
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Macbeth (Jason Connery) moved me to tears with his final monolog (out brief candle, out)He gave the sphere of moral decay and dark forces a human face, which makes it the more interesting.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7825 0.2175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>8.200000e-02</td>
      <td>0.081140</td>
      <td>-0.081140</td>
      <td>0.081140</td>
      <td>0.418370</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-1.548000e-01</td>
      <td>0.057758</td>
      <td>-0.057758</td>
      <td>0.057758</td>
      <td>0.360612</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024218</td>
      <td>0.024218</td>
      <td>0.024218</td>
      <td>0.384829</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.300000e+01</td>
      <td>0.019453</td>
      <td>-0.019453</td>
      <td>0.019453</td>
      <td>0.365376</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019058</td>
      <td>0.019058</td>
      <td>0.019058</td>
      <td>0.384434</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.214286e-01</td>
      <td>0.011181</td>
      <td>-0.011181</td>
      <td>0.011181</td>
      <td>0.373253</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>7.000000e+00</td>
      <td>0.010693</td>
      <td>-0.010693</td>
      <td>0.010693</td>
      <td>0.362560</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009991</td>
      <td>-0.009991</td>
      <td>0.009991</td>
      <td>0.352570</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>-0.009412</td>
      <td>0.009412</td>
      <td>0.009412</td>
      <td>0.361982</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007383</td>
      <td>-0.007383</td>
      <td>0.007383</td>
      <td>0.354599</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006453</td>
      <td>-0.006453</td>
      <td>0.006453</td>
      <td>0.348146</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005897</td>
      <td>-0.005897</td>
      <td>0.005897</td>
      <td>0.342249</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.196062e-86</td>
      <td>0.004652</td>
      <td>-0.004652</td>
      <td>0.004652</td>
      <td>0.337596</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>2.132007e-01</td>
      <td>-0.004490</td>
      <td>0.004490</td>
      <td>0.004490</td>
      <td>0.342087</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>2.664601e-05</td>
      <td>0.004147</td>
      <td>-0.004147</td>
      <td>0.004147</td>
      <td>0.337940</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004136</td>
      <td>-0.004136</td>
      <td>0.004136</td>
      <td>0.333804</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.900000e+02</td>
      <td>0.003966</td>
      <td>-0.003966</td>
      <td>0.003966</td>
      <td>0.329838</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>2.132007e-01</td>
      <td>0.003759</td>
      <td>-0.003759</td>
      <td>0.003759</td>
      <td>0.326080</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.003751</td>
      <td>0.003751</td>
      <td>0.003751</td>
      <td>0.329831</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003687</td>
      <td>0.003687</td>
      <td>0.003687</td>
      <td>0.333518</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003483</td>
      <td>0.003483</td>
      <td>0.003483</td>
      <td>0.337001</td>
    </tr>
    <tr>
      <th>1834</th>
      <td>which</td>
      <td>2.132007e-01</td>
      <td>-0.003461</td>
      <td>0.003461</td>
      <td>0.003461</td>
      <td>0.340462</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>2.456165e-109</td>
      <td>0.003284</td>
      <td>-0.003284</td>
      <td>0.003284</td>
      <td>0.337178</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003218</td>
      <td>-0.003218</td>
      <td>0.003218</td>
      <td>0.333960</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003211</td>
      <td>0.003211</td>
      <td>0.003211</td>
      <td>0.337171</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>6.527753e-129</td>
      <td>-0.003206</td>
      <td>0.003206</td>
      <td>0.003206</td>
      <td>0.340377</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>2.132007e-01</td>
      <td>-0.003187</td>
      <td>0.003187</td>
      <td>0.003187</td>
      <td>0.343564</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003007</td>
      <td>-0.003007</td>
      <td>0.003007</td>
      <td>0.340556</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.002938</td>
      <td>-0.002938</td>
      <td>0.002938</td>
      <td>0.337619</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002913</td>
      <td>0.002913</td>
      <td>0.002913</td>
      <td>0.340532</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 258
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Helen Baxendale is a very credible lady Macbeth who can be very cheerfull at times and sometimes she just looks like a naughty girl, but deadly in her taste for blood and evil.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.97 0.03]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-4.000000e+00</td>
      <td>0.160179</td>
      <td>-0.160179</td>
      <td>0.160179</td>
      <td>0.339331</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-7.469000e-01</td>
      <td>0.124613</td>
      <td>-0.124613</td>
      <td>0.124613</td>
      <td>0.214718</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>4.700000e-02</td>
      <td>0.062844</td>
      <td>-0.062844</td>
      <td>0.062844</td>
      <td>0.151874</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.260000e-01</td>
      <td>0.031953</td>
      <td>-0.031953</td>
      <td>0.031953</td>
      <td>0.119922</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.019977</td>
      <td>0.019977</td>
      <td>0.019977</td>
      <td>0.139899</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.780000e+02</td>
      <td>0.016099</td>
      <td>-0.016099</td>
      <td>0.016099</td>
      <td>0.123800</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.015093</td>
      <td>0.015093</td>
      <td>0.015093</td>
      <td>0.138893</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008405</td>
      <td>-0.008405</td>
      <td>0.008405</td>
      <td>0.130488</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.300000e+01</td>
      <td>0.008086</td>
      <td>-0.008086</td>
      <td>0.008086</td>
      <td>0.122402</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.953648e-79</td>
      <td>0.005802</td>
      <td>-0.005802</td>
      <td>0.005802</td>
      <td>0.116600</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005414</td>
      <td>-0.005414</td>
      <td>0.005414</td>
      <td>0.111186</td>
    </tr>
    <tr>
      <th>2033</th>
      <td>topic 107</td>
      <td>3.435891e-02</td>
      <td>-0.003960</td>
      <td>0.003960</td>
      <td>0.003960</td>
      <td>0.115145</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>7.038477e-215</td>
      <td>0.003918</td>
      <td>-0.003918</td>
      <td>0.003918</td>
      <td>0.111227</td>
    </tr>
    <tr>
      <th>118</th>
      <td>anyone</td>
      <td>0.000000e+00</td>
      <td>0.003573</td>
      <td>-0.003573</td>
      <td>0.003573</td>
      <td>0.107654</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.107786e-174</td>
      <td>-0.003354</td>
      <td>0.003354</td>
      <td>0.003354</td>
      <td>0.111009</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>3.779645e-01</td>
      <td>-0.002804</td>
      <td>0.002804</td>
      <td>0.002804</td>
      <td>0.113813</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002789</td>
      <td>0.002789</td>
      <td>0.002789</td>
      <td>0.116602</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>1.889822e-01</td>
      <td>0.002708</td>
      <td>-0.002708</td>
      <td>0.002708</td>
      <td>0.113894</td>
    </tr>
    <tr>
      <th>1619</th>
      <td>time and</td>
      <td>1.889822e-01</td>
      <td>-0.002643</td>
      <td>0.002643</td>
      <td>0.002643</td>
      <td>0.116538</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002553</td>
      <td>0.002553</td>
      <td>0.002553</td>
      <td>0.119091</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002483</td>
      <td>-0.002483</td>
      <td>0.002483</td>
      <td>0.116608</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002294</td>
      <td>-0.002294</td>
      <td>0.002294</td>
      <td>0.114314</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002274</td>
      <td>0.002274</td>
      <td>0.002274</td>
      <td>0.116588</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.001996</td>
      <td>-0.001996</td>
      <td>0.001996</td>
      <td>0.114592</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.001971</td>
      <td>0.001971</td>
      <td>0.001971</td>
      <td>0.116563</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.001887</td>
      <td>0.001887</td>
      <td>0.001887</td>
      <td>0.118450</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>topic 26</td>
      <td>1.088819e-54</td>
      <td>0.001759</td>
      <td>-0.001759</td>
      <td>0.001759</td>
      <td>0.116691</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.001712</td>
      <td>-0.001712</td>
      <td>0.001712</td>
      <td>0.114979</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>1.678644e-23</td>
      <td>0.001691</td>
      <td>-0.001691</td>
      <td>0.001691</td>
      <td>0.113287</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.001682</td>
      <td>-0.001682</td>
      <td>0.001682</td>
      <td>0.111606</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 271
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Raw and sublimely moving.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8275 0.1725]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.090063</td>
      <td>-0.090063</td>
      <td>0.090063</td>
      <td>0.409447</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-0.230769</td>
      <td>0.065467</td>
      <td>-0.065467</td>
      <td>0.065467</td>
      <td>0.343980</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025959</td>
      <td>0.025959</td>
      <td>0.025959</td>
      <td>0.369939</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>4.000000</td>
      <td>0.018939</td>
      <td>-0.018939</td>
      <td>0.018939</td>
      <td>0.351000</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.018912</td>
      <td>0.018912</td>
      <td>0.018912</td>
      <td>0.369911</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009989</td>
      <td>-0.009989</td>
      <td>0.009989</td>
      <td>0.359922</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>27.000000</td>
      <td>0.009022</td>
      <td>-0.009022</td>
      <td>0.009022</td>
      <td>0.350900</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>1.000000</td>
      <td>-0.008345</td>
      <td>0.008345</td>
      <td>0.008345</td>
      <td>0.359245</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007357</td>
      <td>-0.007357</td>
      <td>0.007357</td>
      <td>0.351888</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>-0.006226</td>
      <td>0.006226</td>
      <td>0.006226</td>
      <td>0.358114</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.005953</td>
      <td>-0.005953</td>
      <td>0.005953</td>
      <td>0.352162</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.005930</td>
      <td>-0.005930</td>
      <td>0.005930</td>
      <td>0.346232</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.005212</td>
      <td>0.005212</td>
      <td>0.005212</td>
      <td>0.351444</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000</td>
      <td>0.005047</td>
      <td>-0.005047</td>
      <td>0.005047</td>
      <td>0.346397</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004612</td>
      <td>-0.004612</td>
      <td>0.004612</td>
      <td>0.341785</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000</td>
      <td>0.004050</td>
      <td>-0.004050</td>
      <td>0.004050</td>
      <td>0.337735</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>0.004044</td>
      <td>-0.004044</td>
      <td>0.004044</td>
      <td>0.333691</td>
    </tr>
    <tr>
      <th>219</th>
      <td>bland</td>
      <td>0.000000</td>
      <td>-0.003994</td>
      <td>0.003994</td>
      <td>0.003994</td>
      <td>0.337685</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000</td>
      <td>0.003950</td>
      <td>-0.003950</td>
      <td>0.003950</td>
      <td>0.333735</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000</td>
      <td>0.003871</td>
      <td>-0.003871</td>
      <td>0.003871</td>
      <td>0.329864</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003745</td>
      <td>0.003745</td>
      <td>0.003745</td>
      <td>0.333608</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000</td>
      <td>0.003744</td>
      <td>-0.003744</td>
      <td>0.003744</td>
      <td>0.329865</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.003665</td>
      <td>0.003665</td>
      <td>0.003665</td>
      <td>0.333530</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.003597</td>
      <td>-0.003597</td>
      <td>0.003597</td>
      <td>0.329933</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003480</td>
      <td>0.003480</td>
      <td>0.003480</td>
      <td>0.333413</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000</td>
      <td>0.003304</td>
      <td>-0.003304</td>
      <td>0.003304</td>
      <td>0.330109</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.003298</td>
      <td>0.003298</td>
      <td>0.003298</td>
      <td>0.333407</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003266</td>
      <td>0.003266</td>
      <td>0.003266</td>
      <td>0.336673</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.003046</td>
      <td>-0.003046</td>
      <td>0.003046</td>
      <td>0.333628</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000</td>
      <td>0.003026</td>
      <td>-0.003026</td>
      <td>0.003026</td>
      <td>0.330601</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 273
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;All of the main players are mesmerising.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7775 0.2225]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.088601</td>
      <td>-0.088601</td>
      <td>0.088601</td>
      <td>0.410909</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025297</td>
      <td>0.025297</td>
      <td>0.025297</td>
      <td>0.436205</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000</td>
      <td>0.023215</td>
      <td>-0.023215</td>
      <td>0.023215</td>
      <td>0.412991</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.019693</td>
      <td>0.019693</td>
      <td>0.019693</td>
      <td>0.432683</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.166667</td>
      <td>0.015628</td>
      <td>-0.015628</td>
      <td>0.015628</td>
      <td>0.417055</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>42.000000</td>
      <td>0.014105</td>
      <td>-0.014105</td>
      <td>0.014105</td>
      <td>0.402951</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.393144</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.008349</td>
      <td>-0.008349</td>
      <td>0.008349</td>
      <td>0.384795</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.007839</td>
      <td>-0.007839</td>
      <td>0.007839</td>
      <td>0.376956</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>-0.007602</td>
      <td>0.007602</td>
      <td>0.007602</td>
      <td>0.384559</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007538</td>
      <td>-0.007538</td>
      <td>0.007538</td>
      <td>0.377021</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006601</td>
      <td>-0.006601</td>
      <td>0.006601</td>
      <td>0.370420</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000</td>
      <td>0.005668</td>
      <td>-0.005668</td>
      <td>0.005668</td>
      <td>0.364752</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.005441</td>
      <td>0.005441</td>
      <td>0.005441</td>
      <td>0.370193</td>
    </tr>
    <tr>
      <th>1791</th>
      <td>watching</td>
      <td>0.000000</td>
      <td>0.005379</td>
      <td>-0.005379</td>
      <td>0.005379</td>
      <td>0.364814</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.005073</td>
      <td>-0.005073</td>
      <td>0.005073</td>
      <td>0.359741</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.004425</td>
      <td>0.004425</td>
      <td>0.004425</td>
      <td>0.364166</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>0.004374</td>
      <td>-0.004374</td>
      <td>0.004374</td>
      <td>0.359793</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000</td>
      <td>0.004366</td>
      <td>-0.004366</td>
      <td>0.004366</td>
      <td>0.355427</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.004217</td>
      <td>0.004217</td>
      <td>0.004217</td>
      <td>0.359643</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003965</td>
      <td>0.003965</td>
      <td>0.003965</td>
      <td>0.363608</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.003941</td>
      <td>0.003941</td>
      <td>0.003941</td>
      <td>0.367549</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003703</td>
      <td>0.003703</td>
      <td>0.003703</td>
      <td>0.371252</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000</td>
      <td>-0.003595</td>
      <td>0.003595</td>
      <td>0.003595</td>
      <td>0.374847</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.003485</td>
      <td>-0.003485</td>
      <td>0.003485</td>
      <td>0.371362</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000</td>
      <td>-0.003322</td>
      <td>0.003322</td>
      <td>0.003322</td>
      <td>0.374684</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000</td>
      <td>0.003320</td>
      <td>-0.003320</td>
      <td>0.003320</td>
      <td>0.371364</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000</td>
      <td>0.003285</td>
      <td>-0.003285</td>
      <td>0.003285</td>
      <td>0.368079</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.003279</td>
      <td>0.003279</td>
      <td>0.003279</td>
      <td>0.371357</td>
    </tr>
    <tr>
      <th>1077</th>
      <td>of the</td>
      <td>0.408248</td>
      <td>0.003277</td>
      <td>-0.003277</td>
      <td>0.003277</td>
      <td>0.368080</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 274
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Tom Wilkinson broke my heart at the end... and everyone else&#39;s judging by the amount of fumbling for hankies and hands going up to faces among males and females alike.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.97 0.03]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.166937</td>
      <td>-0.166937</td>
      <td>0.166937</td>
      <td>0.332573</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.080264</td>
      <td>-0.080264</td>
      <td>0.080264</td>
      <td>0.252310</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.215000e-01</td>
      <td>0.077403</td>
      <td>-0.077403</td>
      <td>0.077403</td>
      <td>0.174906</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.024404</td>
      <td>-0.024404</td>
      <td>0.024404</td>
      <td>0.150502</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.021877</td>
      <td>0.021877</td>
      <td>0.021877</td>
      <td>0.172379</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016306</td>
      <td>0.016306</td>
      <td>0.016306</td>
      <td>0.188685</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.690000e+02</td>
      <td>0.014321</td>
      <td>-0.014321</td>
      <td>0.014321</td>
      <td>0.174365</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.000000e+01</td>
      <td>0.010770</td>
      <td>-0.010770</td>
      <td>0.010770</td>
      <td>0.163595</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009413</td>
      <td>-0.009413</td>
      <td>0.009413</td>
      <td>0.154182</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.037544e-270</td>
      <td>0.006517</td>
      <td>-0.006517</td>
      <td>0.006517</td>
      <td>0.147665</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005552</td>
      <td>-0.005552</td>
      <td>0.005552</td>
      <td>0.142113</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>5.570860e-01</td>
      <td>-0.005339</td>
      <td>0.005339</td>
      <td>0.005339</td>
      <td>0.147452</td>
    </tr>
    <tr>
      <th>1981</th>
      <td>topic 55</td>
      <td>1.618457e-01</td>
      <td>-0.004260</td>
      <td>0.004260</td>
      <td>0.004260</td>
      <td>0.151712</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.963626e-204</td>
      <td>0.004007</td>
      <td>-0.004007</td>
      <td>0.004007</td>
      <td>0.147705</td>
    </tr>
    <tr>
      <th>2005</th>
      <td>topic 79</td>
      <td>8.703752e-03</td>
      <td>-0.003370</td>
      <td>0.003370</td>
      <td>0.003370</td>
      <td>0.151075</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003350</td>
      <td>0.003350</td>
      <td>0.003350</td>
      <td>0.154424</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003207</td>
      <td>0.003207</td>
      <td>0.003207</td>
      <td>0.157631</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.002950</td>
      <td>-0.002950</td>
      <td>0.002950</td>
      <td>0.154681</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002804</td>
      <td>-0.002804</td>
      <td>0.002804</td>
      <td>0.151878</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002694</td>
      <td>0.002694</td>
      <td>0.002694</td>
      <td>0.154572</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002603</td>
      <td>0.002603</td>
      <td>0.002603</td>
      <td>0.157174</td>
    </tr>
    <tr>
      <th>347</th>
      <td>could not</td>
      <td>0.000000e+00</td>
      <td>0.002493</td>
      <td>-0.002493</td>
      <td>0.002493</td>
      <td>0.154682</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002416</td>
      <td>-0.002416</td>
      <td>0.002416</td>
      <td>0.152266</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002336</td>
      <td>0.002336</td>
      <td>0.002336</td>
      <td>0.154601</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002310</td>
      <td>0.002310</td>
      <td>0.002310</td>
      <td>0.156912</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>1.447161e-28</td>
      <td>0.002288</td>
      <td>-0.002288</td>
      <td>0.002288</td>
      <td>0.154624</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.002223</td>
      <td>-0.002223</td>
      <td>0.002223</td>
      <td>0.152401</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002186</td>
      <td>-0.002186</td>
      <td>0.002186</td>
      <td>0.150215</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002178</td>
      <td>0.002178</td>
      <td>0.002178</td>
      <td>0.152393</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002177</td>
      <td>0.002177</td>
      <td>0.002177</td>
      <td>0.154570</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 279
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The aerial scenes were well-done.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.825 0.175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.088071</td>
      <td>-0.088071</td>
      <td>0.088071</td>
      <td>0.411439</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.037143</td>
      <td>-0.037143</td>
      <td>0.037143</td>
      <td>0.374296</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031544</td>
      <td>-0.031544</td>
      <td>0.031544</td>
      <td>0.342752</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024862</td>
      <td>0.024862</td>
      <td>0.024862</td>
      <td>0.367614</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019673</td>
      <td>0.019673</td>
      <td>0.019673</td>
      <td>0.387288</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.016449</td>
      <td>-0.016449</td>
      <td>0.016449</td>
      <td>0.370839</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009929</td>
      <td>-0.009929</td>
      <td>0.009929</td>
      <td>0.360910</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008736</td>
      <td>-0.008736</td>
      <td>0.008736</td>
      <td>0.352174</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007449</td>
      <td>-0.007449</td>
      <td>0.007449</td>
      <td>0.344725</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007374</td>
      <td>-0.007374</td>
      <td>0.007374</td>
      <td>0.337351</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.007312</td>
      <td>0.007312</td>
      <td>0.007312</td>
      <td>0.344663</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006435</td>
      <td>-0.006435</td>
      <td>0.006435</td>
      <td>0.338228</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005635</td>
      <td>0.005635</td>
      <td>0.005635</td>
      <td>0.343863</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.500000e+01</td>
      <td>0.005325</td>
      <td>-0.005325</td>
      <td>0.005325</td>
      <td>0.338538</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004613</td>
      <td>-0.004613</td>
      <td>0.004613</td>
      <td>0.333924</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004489</td>
      <td>-0.004489</td>
      <td>0.004489</td>
      <td>0.329436</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004264</td>
      <td>0.004264</td>
      <td>0.004264</td>
      <td>0.333700</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004043</td>
      <td>0.004043</td>
      <td>0.004043</td>
      <td>0.337743</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003974</td>
      <td>0.003974</td>
      <td>0.003974</td>
      <td>0.341717</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>3.607859e-23</td>
      <td>0.003853</td>
      <td>-0.003853</td>
      <td>0.003853</td>
      <td>0.337864</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003766</td>
      <td>0.003766</td>
      <td>0.003766</td>
      <td>0.341630</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003752</td>
      <td>-0.003752</td>
      <td>0.003752</td>
      <td>0.337878</td>
    </tr>
    <tr>
      <th>1618</th>
      <td>time</td>
      <td>0.000000e+00</td>
      <td>0.003640</td>
      <td>-0.003640</td>
      <td>0.003640</td>
      <td>0.334238</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003291</td>
      <td>-0.003291</td>
      <td>0.003291</td>
      <td>0.330947</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003284</td>
      <td>-0.003284</td>
      <td>0.003284</td>
      <td>0.327662</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003265</td>
      <td>-0.003265</td>
      <td>0.003265</td>
      <td>0.324397</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003250</td>
      <td>0.003250</td>
      <td>0.003250</td>
      <td>0.327648</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.003205</td>
      <td>-0.003205</td>
      <td>0.003205</td>
      <td>0.324443</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>0.000000e+00</td>
      <td>-0.003192</td>
      <td>0.003192</td>
      <td>0.003192</td>
      <td>0.327634</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003168</td>
      <td>-0.003168</td>
      <td>0.003168</td>
      <td>0.324467</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 281
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The film gives meaning to the phrase, &#34;Never in the history of human conflict has so much been owed by so many to so few.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9525 0.0475]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.187000</td>
      <td>-0.187000</td>
      <td>0.187000</td>
      <td>0.312509</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.073426</td>
      <td>-0.073426</td>
      <td>0.073426</td>
      <td>0.239084</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-3.182000e-01</td>
      <td>0.061080</td>
      <td>-0.061080</td>
      <td>0.061080</td>
      <td>0.178003</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022053</td>
      <td>0.022053</td>
      <td>0.022053</td>
      <td>0.200057</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016064</td>
      <td>0.016064</td>
      <td>0.016064</td>
      <td>0.216121</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.250000e-01</td>
      <td>0.014898</td>
      <td>-0.014898</td>
      <td>0.014898</td>
      <td>0.201223</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.230000e+02</td>
      <td>0.014716</td>
      <td>-0.014716</td>
      <td>0.014716</td>
      <td>0.186508</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.011822</td>
      <td>-0.011822</td>
      <td>0.011822</td>
      <td>0.174686</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008908</td>
      <td>-0.008908</td>
      <td>0.008908</td>
      <td>0.165778</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006958</td>
      <td>-0.006958</td>
      <td>0.006958</td>
      <td>0.158820</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.965161e-152</td>
      <td>0.006293</td>
      <td>-0.006293</td>
      <td>0.006293</td>
      <td>0.152527</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005547</td>
      <td>-0.005547</td>
      <td>0.005547</td>
      <td>0.146980</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>0.000000e+00</td>
      <td>0.004363</td>
      <td>-0.004363</td>
      <td>0.004363</td>
      <td>0.142618</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>3.651484e-01</td>
      <td>0.004147</td>
      <td>-0.004147</td>
      <td>0.004147</td>
      <td>0.138471</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003917</td>
      <td>-0.003917</td>
      <td>0.003917</td>
      <td>0.134554</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003284</td>
      <td>0.003284</td>
      <td>0.003284</td>
      <td>0.137838</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.034132e-219</td>
      <td>-0.003256</td>
      <td>0.003256</td>
      <td>0.003256</td>
      <td>0.141094</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002849</td>
      <td>-0.002849</td>
      <td>0.002849</td>
      <td>0.138245</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002720</td>
      <td>0.002720</td>
      <td>0.002720</td>
      <td>0.140966</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002702</td>
      <td>0.002702</td>
      <td>0.002702</td>
      <td>0.143668</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.002533</td>
      <td>-0.002533</td>
      <td>0.002533</td>
      <td>0.141135</td>
    </tr>
    <tr>
      <th>192</th>
      <td>been</td>
      <td>1.825742e-01</td>
      <td>0.002373</td>
      <td>-0.002373</td>
      <td>0.002373</td>
      <td>0.138761</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002373</td>
      <td>-0.002373</td>
      <td>0.002373</td>
      <td>0.136388</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002293</td>
      <td>0.002293</td>
      <td>0.002293</td>
      <td>0.138681</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002240</td>
      <td>0.002240</td>
      <td>0.002240</td>
      <td>0.140921</td>
    </tr>
    <tr>
      <th>1005</th>
      <td>never</td>
      <td>1.825742e-01</td>
      <td>0.002191</td>
      <td>-0.002191</td>
      <td>0.002191</td>
      <td>0.138730</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002179</td>
      <td>-0.002179</td>
      <td>0.002179</td>
      <td>0.136550</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002068</td>
      <td>0.002068</td>
      <td>0.002068</td>
      <td>0.138619</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002057</td>
      <td>0.002057</td>
      <td>0.002057</td>
      <td>0.140675</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002024</td>
      <td>0.002024</td>
      <td>0.002024</td>
      <td>0.142700</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 290
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Punishment Park is a brilliant piece of cinema.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.3325 0.6675]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>4.000000</td>
      <td>-0.158075</td>
      <td>0.158075</td>
      <td>0.158075</td>
      <td>0.657585</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.900000</td>
      <td>-0.064362</td>
      <td>0.064362</td>
      <td>0.064362</td>
      <td>0.721947</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.317000</td>
      <td>0.062794</td>
      <td>-0.062794</td>
      <td>0.062794</td>
      <td>0.659153</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.023765</td>
      <td>0.023765</td>
      <td>0.023765</td>
      <td>0.682918</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.020818</td>
      <td>0.020818</td>
      <td>0.020818</td>
      <td>0.703736</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.153100</td>
      <td>0.017621</td>
      <td>-0.017621</td>
      <td>0.017621</td>
      <td>0.686115</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000</td>
      <td>0.013905</td>
      <td>-0.013905</td>
      <td>0.013905</td>
      <td>0.672210</td>
    </tr>
    <tr>
      <th>1171</th>
      <td>piece of</td>
      <td>0.500000</td>
      <td>0.009727</td>
      <td>-0.009727</td>
      <td>0.009727</td>
      <td>0.662483</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.008592</td>
      <td>-0.008592</td>
      <td>0.008592</td>
      <td>0.653891</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.007665</td>
      <td>-0.007665</td>
      <td>0.007665</td>
      <td>0.646226</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007475</td>
      <td>-0.007475</td>
      <td>0.007475</td>
      <td>0.638751</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006097</td>
      <td>-0.006097</td>
      <td>0.006097</td>
      <td>0.632654</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.005116</td>
      <td>-0.005116</td>
      <td>0.005116</td>
      <td>0.627538</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000</td>
      <td>-0.004879</td>
      <td>0.004879</td>
      <td>0.004879</td>
      <td>0.632417</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.004492</td>
      <td>0.004492</td>
      <td>0.004492</td>
      <td>0.636909</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>0.004316</td>
      <td>-0.004316</td>
      <td>0.004316</td>
      <td>0.632593</td>
    </tr>
    <tr>
      <th>1114</th>
      <td>other</td>
      <td>0.000000</td>
      <td>0.003995</td>
      <td>-0.003995</td>
      <td>0.003995</td>
      <td>0.628598</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003645</td>
      <td>0.003645</td>
      <td>0.003645</td>
      <td>0.632243</td>
    </tr>
    <tr>
      <th>2093</th>
      <td>topic 167</td>
      <td>0.021067</td>
      <td>0.003428</td>
      <td>-0.003428</td>
      <td>0.003428</td>
      <td>0.628815</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000</td>
      <td>0.003203</td>
      <td>-0.003203</td>
      <td>0.003203</td>
      <td>0.625612</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>0.000000</td>
      <td>-0.002982</td>
      <td>0.002982</td>
      <td>0.002982</td>
      <td>0.628594</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000</td>
      <td>0.002825</td>
      <td>-0.002825</td>
      <td>0.002825</td>
      <td>0.625769</td>
    </tr>
    <tr>
      <th>965</th>
      <td>more</td>
      <td>0.000000</td>
      <td>-0.002816</td>
      <td>0.002816</td>
      <td>0.002816</td>
      <td>0.628586</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000</td>
      <td>-0.002816</td>
      <td>0.002816</td>
      <td>0.002816</td>
      <td>0.631401</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000</td>
      <td>0.002641</td>
      <td>-0.002641</td>
      <td>0.002641</td>
      <td>0.628760</td>
    </tr>
    <tr>
      <th>1170</th>
      <td>piece</td>
      <td>0.500000</td>
      <td>0.002598</td>
      <td>-0.002598</td>
      <td>0.002598</td>
      <td>0.626162</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002561</td>
      <td>0.002561</td>
      <td>0.002561</td>
      <td>0.628723</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.002548</td>
      <td>0.002548</td>
      <td>0.002548</td>
      <td>0.631271</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.002533</td>
      <td>0.002533</td>
      <td>0.002533</td>
      <td>0.633805</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.002527</td>
      <td>0.002527</td>
      <td>0.002527</td>
      <td>0.636332</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 291
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Shot in the Southern California desert using his patent faux documentary style, Watkins creates a film like no other.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.5325 0.4675]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.107593</td>
      <td>0.107593</td>
      <td>0.107593</td>
      <td>0.607103</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.110000e-01</td>
      <td>0.074584</td>
      <td>-0.074584</td>
      <td>0.074584</td>
      <td>0.532519</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.083333e-02</td>
      <td>0.039380</td>
      <td>-0.039380</td>
      <td>0.039380</td>
      <td>0.493140</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026163</td>
      <td>0.026163</td>
      <td>0.026163</td>
      <td>0.519303</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.400000e-01</td>
      <td>-0.024435</td>
      <td>0.024435</td>
      <td>0.024435</td>
      <td>0.543738</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022503</td>
      <td>0.022503</td>
      <td>0.022503</td>
      <td>0.566241</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.900000e+01</td>
      <td>0.020899</td>
      <td>-0.020899</td>
      <td>0.020899</td>
      <td>0.545342</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>0.015765</td>
      <td>-0.015765</td>
      <td>0.015765</td>
      <td>0.529577</td>
    </tr>
    <tr>
      <th>2104</th>
      <td>topic 178</td>
      <td>8.961491e-04</td>
      <td>0.015757</td>
      <td>-0.015757</td>
      <td>0.015757</td>
      <td>0.513819</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009946</td>
      <td>-0.009946</td>
      <td>0.009946</td>
      <td>0.503873</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009330</td>
      <td>-0.009330</td>
      <td>0.009330</td>
      <td>0.494543</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.546135e-155</td>
      <td>0.008010</td>
      <td>-0.008010</td>
      <td>0.008010</td>
      <td>0.486533</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006840</td>
      <td>-0.006840</td>
      <td>0.006840</td>
      <td>0.479693</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006697</td>
      <td>-0.006697</td>
      <td>0.006697</td>
      <td>0.472996</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.006099</td>
      <td>-0.006099</td>
      <td>0.006099</td>
      <td>0.466897</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.005827</td>
      <td>-0.005827</td>
      <td>0.005827</td>
      <td>0.461069</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005296</td>
      <td>-0.005296</td>
      <td>0.005296</td>
      <td>0.455773</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.004442</td>
      <td>0.004442</td>
      <td>0.004442</td>
      <td>0.460215</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004404</td>
      <td>0.004404</td>
      <td>0.004404</td>
      <td>0.464619</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004122</td>
      <td>0.004122</td>
      <td>0.004122</td>
      <td>0.468741</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.004004</td>
      <td>0.004004</td>
      <td>0.004004</td>
      <td>0.472744</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>2.425408e-04</td>
      <td>-0.003444</td>
      <td>0.003444</td>
      <td>0.003444</td>
      <td>0.476188</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>3.162278e-01</td>
      <td>-0.003333</td>
      <td>0.003333</td>
      <td>0.003333</td>
      <td>0.479521</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003290</td>
      <td>0.003290</td>
      <td>0.003290</td>
      <td>0.482811</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003282</td>
      <td>0.003282</td>
      <td>0.003282</td>
      <td>0.486093</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003168</td>
      <td>0.003168</td>
      <td>0.003168</td>
      <td>0.489260</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.015453e-223</td>
      <td>-0.003106</td>
      <td>0.003106</td>
      <td>0.003106</td>
      <td>0.492366</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>4.209498e-28</td>
      <td>0.003037</td>
      <td>-0.003037</td>
      <td>0.003037</td>
      <td>0.489330</td>
    </tr>
    <tr>
      <th>693</th>
      <td>his</td>
      <td>3.162278e-01</td>
      <td>-0.003002</td>
      <td>0.003002</td>
      <td>0.003002</td>
      <td>0.492331</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002946</td>
      <td>0.002946</td>
      <td>0.002946</td>
      <td>0.495278</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 293
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I advise you to look out for it.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8425 0.1575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084934</td>
      <td>-0.084934</td>
      <td>0.084934</td>
      <td>0.414576</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.038506</td>
      <td>-0.038506</td>
      <td>0.038506</td>
      <td>0.376069</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031765</td>
      <td>-0.031765</td>
      <td>0.031765</td>
      <td>0.344304</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025506</td>
      <td>0.025506</td>
      <td>0.025506</td>
      <td>0.369810</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.400000e+01</td>
      <td>0.022525</td>
      <td>-0.022525</td>
      <td>0.022525</td>
      <td>0.347285</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019017</td>
      <td>0.019017</td>
      <td>0.019017</td>
      <td>0.366302</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009784</td>
      <td>-0.009784</td>
      <td>0.009784</td>
      <td>0.356518</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.009081</td>
      <td>-0.009081</td>
      <td>0.009081</td>
      <td>0.347436</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.007948</td>
      <td>0.007948</td>
      <td>0.007948</td>
      <td>0.355384</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.623937e-242</td>
      <td>0.007472</td>
      <td>-0.007472</td>
      <td>0.007472</td>
      <td>0.347913</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007420</td>
      <td>-0.007420</td>
      <td>0.007420</td>
      <td>0.340493</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006495</td>
      <td>-0.006495</td>
      <td>0.006495</td>
      <td>0.333998</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005630</td>
      <td>0.005630</td>
      <td>0.005630</td>
      <td>0.339628</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.005444</td>
      <td>-0.005444</td>
      <td>0.005444</td>
      <td>0.334184</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.005356</td>
      <td>-0.005356</td>
      <td>0.005356</td>
      <td>0.328829</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.902506e-242</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.323841</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.004874</td>
      <td>-0.004874</td>
      <td>0.004874</td>
      <td>0.318968</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004619</td>
      <td>-0.004619</td>
      <td>0.004619</td>
      <td>0.314349</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004389</td>
      <td>0.004389</td>
      <td>0.004389</td>
      <td>0.318738</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004344</td>
      <td>0.004344</td>
      <td>0.004344</td>
      <td>0.323083</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.004328</td>
      <td>0.004328</td>
      <td>0.004328</td>
      <td>0.327410</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004309</td>
      <td>-0.004309</td>
      <td>0.004309</td>
      <td>0.323102</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.004141</td>
      <td>-0.004141</td>
      <td>0.004141</td>
      <td>0.318960</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003988</td>
      <td>0.003988</td>
      <td>0.003988</td>
      <td>0.322948</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003934</td>
      <td>0.003934</td>
      <td>0.003934</td>
      <td>0.326882</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003618</td>
      <td>-0.003618</td>
      <td>0.003618</td>
      <td>0.323264</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003380</td>
      <td>-0.003380</td>
      <td>0.003380</td>
      <td>0.319884</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003365</td>
      <td>-0.003365</td>
      <td>0.003365</td>
      <td>0.316519</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003312</td>
      <td>0.003312</td>
      <td>0.003312</td>
      <td>0.319831</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003301</td>
      <td>0.003301</td>
      <td>0.003301</td>
      <td>0.323132</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 311
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Lame would be the best way to describe it.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.46 0.54]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.100005</td>
      <td>0.100005</td>
      <td>0.100005</td>
      <td>0.599514</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.000000e-01</td>
      <td>0.074027</td>
      <td>-0.074027</td>
      <td>0.074027</td>
      <td>0.525488</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025730</td>
      <td>0.025730</td>
      <td>0.025730</td>
      <td>0.551217</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022417</td>
      <td>0.022417</td>
      <td>0.022417</td>
      <td>0.573634</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.400000e-01</td>
      <td>-0.019025</td>
      <td>0.019025</td>
      <td>0.019025</td>
      <td>0.592659</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000e+00</td>
      <td>0.011691</td>
      <td>-0.011691</td>
      <td>0.011691</td>
      <td>0.580968</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.500000e-01</td>
      <td>0.010076</td>
      <td>-0.010076</td>
      <td>0.010076</td>
      <td>0.570892</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009693</td>
      <td>-0.009693</td>
      <td>0.009693</td>
      <td>0.561199</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008808</td>
      <td>-0.008808</td>
      <td>0.008808</td>
      <td>0.552391</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.267225e-227</td>
      <td>0.007706</td>
      <td>-0.007706</td>
      <td>0.007706</td>
      <td>0.544685</td>
    </tr>
    <tr>
      <th>1887</th>
      <td>would</td>
      <td>3.015113e-01</td>
      <td>0.007503</td>
      <td>-0.007503</td>
      <td>0.007503</td>
      <td>0.537182</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006619</td>
      <td>-0.006619</td>
      <td>0.006619</td>
      <td>0.530563</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.400000e+01</td>
      <td>0.006608</td>
      <td>-0.006608</td>
      <td>0.006608</td>
      <td>0.523955</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.006190</td>
      <td>-0.006190</td>
      <td>0.006190</td>
      <td>0.517764</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006116</td>
      <td>-0.006116</td>
      <td>0.006116</td>
      <td>0.511648</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.005570</td>
      <td>0.005570</td>
      <td>0.005570</td>
      <td>0.517218</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.558525e-184</td>
      <td>0.005343</td>
      <td>-0.005343</td>
      <td>0.005343</td>
      <td>0.511875</td>
    </tr>
    <tr>
      <th>1470</th>
      <td>the best</td>
      <td>3.015113e-01</td>
      <td>-0.005012</td>
      <td>0.005012</td>
      <td>0.005012</td>
      <td>0.516887</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004765</td>
      <td>-0.004765</td>
      <td>0.004765</td>
      <td>0.512121</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003901</td>
      <td>-0.003901</td>
      <td>0.003901</td>
      <td>0.508220</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003738</td>
      <td>0.003738</td>
      <td>0.003738</td>
      <td>0.511958</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003668</td>
      <td>0.003668</td>
      <td>0.003668</td>
      <td>0.515625</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003407</td>
      <td>0.003407</td>
      <td>0.003407</td>
      <td>0.519032</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003267</td>
      <td>-0.003267</td>
      <td>0.003267</td>
      <td>0.515765</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003236</td>
      <td>0.003236</td>
      <td>0.003236</td>
      <td>0.519001</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>9.737766e-115</td>
      <td>-0.003057</td>
      <td>0.003057</td>
      <td>0.003057</td>
      <td>0.522058</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003025</td>
      <td>0.003025</td>
      <td>0.003025</td>
      <td>0.525082</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002914</td>
      <td>-0.002914</td>
      <td>0.002914</td>
      <td>0.522168</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002857</td>
      <td>0.002857</td>
      <td>0.002857</td>
      <td>0.525025</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002785</td>
      <td>0.002785</td>
      <td>0.002785</td>
      <td>0.527810</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 317
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;You can find better movies at youtube.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.315 0.685]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.152482</td>
      <td>0.152482</td>
      <td>0.152482</td>
      <td>0.651992</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.260000e-01</td>
      <td>0.073061</td>
      <td>-0.073061</td>
      <td>0.073061</td>
      <td>0.578931</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.000000e-01</td>
      <td>-0.031009</td>
      <td>0.031009</td>
      <td>0.031009</td>
      <td>0.609940</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.404000e-01</td>
      <td>-0.025990</td>
      <td>0.025990</td>
      <td>0.025990</td>
      <td>0.635930</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024907</td>
      <td>0.024907</td>
      <td>0.024907</td>
      <td>0.660837</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021400</td>
      <td>0.021400</td>
      <td>0.021400</td>
      <td>0.682236</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.019319</td>
      <td>-0.019319</td>
      <td>0.019319</td>
      <td>0.662918</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009242</td>
      <td>-0.009242</td>
      <td>0.009242</td>
      <td>0.653676</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008992</td>
      <td>-0.008992</td>
      <td>0.008992</td>
      <td>0.644684</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007789</td>
      <td>-0.007789</td>
      <td>0.007789</td>
      <td>0.636895</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.007067</td>
      <td>-0.007067</td>
      <td>0.007067</td>
      <td>0.629829</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.273946e-184</td>
      <td>0.005563</td>
      <td>-0.005563</td>
      <td>0.005563</td>
      <td>0.624265</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005185</td>
      <td>-0.005185</td>
      <td>0.005185</td>
      <td>0.619081</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004453</td>
      <td>0.004453</td>
      <td>0.004453</td>
      <td>0.623534</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>3.779645e-01</td>
      <td>0.003592</td>
      <td>-0.003592</td>
      <td>0.003592</td>
      <td>0.619942</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003556</td>
      <td>0.003556</td>
      <td>0.003556</td>
      <td>0.623498</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003300</td>
      <td>-0.003300</td>
      <td>0.003300</td>
      <td>0.620198</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003212</td>
      <td>-0.003212</td>
      <td>0.003212</td>
      <td>0.616986</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003114</td>
      <td>0.003114</td>
      <td>0.003114</td>
      <td>0.620100</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003022</td>
      <td>-0.003022</td>
      <td>0.003022</td>
      <td>0.617078</td>
    </tr>
    <tr>
      <th>972</th>
      <td>movie</td>
      <td>3.779645e-01</td>
      <td>-0.002995</td>
      <td>0.002995</td>
      <td>0.002995</td>
      <td>0.620073</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.770057e-83</td>
      <td>-0.002882</td>
      <td>0.002882</td>
      <td>0.002882</td>
      <td>0.622955</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002840</td>
      <td>0.002840</td>
      <td>0.002840</td>
      <td>0.625795</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002831</td>
      <td>-0.002831</td>
      <td>0.002831</td>
      <td>0.622964</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002635</td>
      <td>0.002635</td>
      <td>0.002635</td>
      <td>0.625600</td>
    </tr>
    <tr>
      <th>206</th>
      <td>better</td>
      <td>3.779645e-01</td>
      <td>0.002556</td>
      <td>-0.002556</td>
      <td>0.002556</td>
      <td>0.623044</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002545</td>
      <td>0.002545</td>
      <td>0.002545</td>
      <td>0.625589</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002509</td>
      <td>0.002509</td>
      <td>0.002509</td>
      <td>0.628098</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.630598</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002432</td>
      <td>0.002432</td>
      <td>0.002432</td>
      <td>0.633030</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 334
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It&#39;s one of the movies I need to see whenever it comes on TV...never mind the fact that I already have it memorized!  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7375 0.2625]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085291</td>
      <td>-0.085291</td>
      <td>0.085291</td>
      <td>0.414219</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.300000e+01</td>
      <td>0.035279</td>
      <td>-0.035279</td>
      <td>0.035279</td>
      <td>0.378941</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024431</td>
      <td>0.024431</td>
      <td>0.024431</td>
      <td>0.403372</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.024115</td>
      <td>-0.024115</td>
      <td>0.024115</td>
      <td>0.379257</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.023418</td>
      <td>0.023418</td>
      <td>0.023418</td>
      <td>0.402675</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018647</td>
      <td>0.018647</td>
      <td>0.018647</td>
      <td>0.421322</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>-0.016746</td>
      <td>0.016746</td>
      <td>0.016746</td>
      <td>0.438068</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009708</td>
      <td>-0.009708</td>
      <td>0.009708</td>
      <td>0.428360</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008141</td>
      <td>-0.008141</td>
      <td>0.008141</td>
      <td>0.420220</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.008129</td>
      <td>-0.008129</td>
      <td>0.008129</td>
      <td>0.412090</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008123</td>
      <td>-0.008123</td>
      <td>0.008123</td>
      <td>0.403967</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.048603e-216</td>
      <td>0.007420</td>
      <td>-0.007420</td>
      <td>0.007420</td>
      <td>0.396548</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006389</td>
      <td>-0.006389</td>
      <td>0.006389</td>
      <td>0.390158</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.006094</td>
      <td>-0.006094</td>
      <td>0.006094</td>
      <td>0.384064</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005481</td>
      <td>0.005481</td>
      <td>0.005481</td>
      <td>0.389545</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>4.401322e-66</td>
      <td>0.004868</td>
      <td>-0.004868</td>
      <td>0.004868</td>
      <td>0.384678</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004584</td>
      <td>0.004584</td>
      <td>0.004584</td>
      <td>0.389261</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.004406</td>
      <td>-0.004406</td>
      <td>0.004406</td>
      <td>0.384855</td>
    </tr>
    <tr>
      <th>2036</th>
      <td>topic 110</td>
      <td>2.198056e-01</td>
      <td>-0.004018</td>
      <td>0.004018</td>
      <td>0.004018</td>
      <td>0.388873</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003906</td>
      <td>-0.003906</td>
      <td>0.003906</td>
      <td>0.384967</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>1.856953e-01</td>
      <td>-0.003826</td>
      <td>0.003826</td>
      <td>0.003826</td>
      <td>0.388793</td>
    </tr>
    <tr>
      <th>1935</th>
      <td>topic 9</td>
      <td>6.354942e-02</td>
      <td>-0.003622</td>
      <td>0.003622</td>
      <td>0.003622</td>
      <td>0.392415</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003588</td>
      <td>0.003588</td>
      <td>0.003588</td>
      <td>0.396003</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>this place</td>
      <td>0.000000e+00</td>
      <td>0.003552</td>
      <td>-0.003552</td>
      <td>0.003552</td>
      <td>0.392452</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003475</td>
      <td>0.003475</td>
      <td>0.003475</td>
      <td>0.395926</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.397802e-90</td>
      <td>-0.003280</td>
      <td>0.003280</td>
      <td>0.003280</td>
      <td>0.399206</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003179</td>
      <td>-0.003179</td>
      <td>0.003179</td>
      <td>0.396028</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.180000e+02</td>
      <td>0.003121</td>
      <td>-0.003121</td>
      <td>0.003121</td>
      <td>0.392907</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003110</td>
      <td>0.003110</td>
      <td>0.003110</td>
      <td>0.396017</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003094</td>
      <td>0.003094</td>
      <td>0.003094</td>
      <td>0.399111</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 343
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Tom Wilkinson&#39;s character is a man who is not prepared for the ordeal that is about to begin, but he takes the matter in hand as the story progresses, and this great actor gives a performance that makes you feel the character&#39;s anguish and suffering.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.63 0.37]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.040000e-01</td>
      <td>0.059899</td>
      <td>-0.059899</td>
      <td>0.059899</td>
      <td>0.439611</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>8.000000e-01</td>
      <td>-0.057277</td>
      <td>0.057277</td>
      <td>0.057277</td>
      <td>0.496888</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.053656</td>
      <td>-0.053656</td>
      <td>0.053656</td>
      <td>0.443231</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.463000e-01</td>
      <td>-0.017443</td>
      <td>0.017443</td>
      <td>0.017443</td>
      <td>0.460674</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>4.500000e+01</td>
      <td>0.011125</td>
      <td>-0.011125</td>
      <td>0.011125</td>
      <td>0.449549</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.443376e-01</td>
      <td>-0.010494</td>
      <td>0.010494</td>
      <td>0.010494</td>
      <td>0.460043</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>2.981117e-01</td>
      <td>0.008102</td>
      <td>-0.008102</td>
      <td>0.008102</td>
      <td>0.451941</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.870193e-02</td>
      <td>0.008052</td>
      <td>-0.008052</td>
      <td>0.008052</td>
      <td>0.443889</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.007485</td>
      <td>-0.007485</td>
      <td>0.007485</td>
      <td>0.436404</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006678</td>
      <td>-0.006678</td>
      <td>0.006678</td>
      <td>0.429726</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.006043</td>
      <td>-0.006043</td>
      <td>0.006043</td>
      <td>0.423683</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.005527</td>
      <td>0.005527</td>
      <td>0.005527</td>
      <td>0.429210</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>9.353892e-11</td>
      <td>0.004550</td>
      <td>-0.004550</td>
      <td>0.004550</td>
      <td>0.424660</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.646640e-19</td>
      <td>0.004316</td>
      <td>-0.004316</td>
      <td>0.004316</td>
      <td>0.420344</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>2.886751e-01</td>
      <td>0.004268</td>
      <td>-0.004268</td>
      <td>0.004268</td>
      <td>0.416076</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.003006</td>
      <td>-0.003006</td>
      <td>0.003006</td>
      <td>0.413070</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002901</td>
      <td>0.002901</td>
      <td>0.002901</td>
      <td>0.415971</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.199406e-23</td>
      <td>-0.002868</td>
      <td>0.002868</td>
      <td>0.002868</td>
      <td>0.418840</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002862</td>
      <td>0.002862</td>
      <td>0.002862</td>
      <td>0.421702</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002829</td>
      <td>0.002829</td>
      <td>0.002829</td>
      <td>0.424530</td>
    </tr>
    <tr>
      <th>1806</th>
      <td>we were</td>
      <td>0.000000e+00</td>
      <td>0.002793</td>
      <td>-0.002793</td>
      <td>0.002793</td>
      <td>0.421737</td>
    </tr>
    <tr>
      <th>76</th>
      <td>and it</td>
      <td>0.000000e+00</td>
      <td>-0.002775</td>
      <td>0.002775</td>
      <td>0.002775</td>
      <td>0.424512</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002770</td>
      <td>-0.002770</td>
      <td>0.002770</td>
      <td>0.421742</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>2.886751e-01</td>
      <td>-0.002745</td>
      <td>0.002745</td>
      <td>0.002745</td>
      <td>0.424487</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>4.330127e-01</td>
      <td>0.002737</td>
      <td>-0.002737</td>
      <td>0.002737</td>
      <td>0.421751</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002690</td>
      <td>0.002690</td>
      <td>0.002690</td>
      <td>0.424441</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>2.705360e-268</td>
      <td>0.002671</td>
      <td>-0.002671</td>
      <td>0.002671</td>
      <td>0.421769</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002607</td>
      <td>-0.002607</td>
      <td>0.002607</td>
      <td>0.419162</td>
    </tr>
    <tr>
      <th>2103</th>
      <td>topic 177</td>
      <td>0.000000e+00</td>
      <td>0.002551</td>
      <td>-0.002551</td>
      <td>0.002551</td>
      <td>0.416611</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002550</td>
      <td>-0.002550</td>
      <td>0.002550</td>
      <td>0.414061</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 351
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;But I thought his acting was skilled.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7175 0.2825]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.089221</td>
      <td>-0.089221</td>
      <td>0.089221</td>
      <td>0.410289</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025687</td>
      <td>0.025687</td>
      <td>0.025687</td>
      <td>0.435976</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019605</td>
      <td>0.019605</td>
      <td>0.019605</td>
      <td>0.455581</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.900000e+01</td>
      <td>0.018995</td>
      <td>-0.018995</td>
      <td>0.018995</td>
      <td>0.436585</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.017584</td>
      <td>-0.017584</td>
      <td>0.017584</td>
      <td>0.419001</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.017107</td>
      <td>0.017107</td>
      <td>0.017107</td>
      <td>0.436109</td>
    </tr>
    <tr>
      <th>2109</th>
      <td>topic 183</td>
      <td>4.672551e-05</td>
      <td>-0.013545</td>
      <td>0.013545</td>
      <td>0.013545</td>
      <td>0.449654</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009564</td>
      <td>-0.009564</td>
      <td>0.009564</td>
      <td>0.440090</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008444</td>
      <td>-0.008444</td>
      <td>0.008444</td>
      <td>0.431646</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007572</td>
      <td>-0.007572</td>
      <td>0.007572</td>
      <td>0.424074</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007269</td>
      <td>-0.007269</td>
      <td>0.007269</td>
      <td>0.416805</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006598</td>
      <td>-0.006598</td>
      <td>0.006598</td>
      <td>0.410208</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.005798</td>
      <td>-0.005798</td>
      <td>0.005798</td>
      <td>0.404409</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005225</td>
      <td>0.005225</td>
      <td>0.005225</td>
      <td>0.409634</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.873984e-33</td>
      <td>0.005171</td>
      <td>-0.005171</td>
      <td>0.005171</td>
      <td>0.404462</td>
    </tr>
    <tr>
      <th>2031</th>
      <td>topic 105</td>
      <td>1.403064e-02</td>
      <td>-0.004737</td>
      <td>0.004737</td>
      <td>0.004737</td>
      <td>0.409200</td>
    </tr>
    <tr>
      <th>2101</th>
      <td>topic 175</td>
      <td>2.834431e-02</td>
      <td>-0.004481</td>
      <td>0.004481</td>
      <td>0.004481</td>
      <td>0.413681</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.500000e-01</td>
      <td>0.004370</td>
      <td>-0.004370</td>
      <td>0.004370</td>
      <td>0.409312</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004205</td>
      <td>0.004205</td>
      <td>0.004205</td>
      <td>0.413517</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004188</td>
      <td>-0.004188</td>
      <td>0.004188</td>
      <td>0.409329</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004172</td>
      <td>-0.004172</td>
      <td>0.004172</td>
      <td>0.405157</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004037</td>
      <td>0.004037</td>
      <td>0.004037</td>
      <td>0.409194</td>
    </tr>
    <tr>
      <th>2102</th>
      <td>topic 176</td>
      <td>3.605901e-02</td>
      <td>-0.003906</td>
      <td>0.003906</td>
      <td>0.003906</td>
      <td>0.413100</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003695</td>
      <td>0.003695</td>
      <td>0.003695</td>
      <td>0.416795</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003612</td>
      <td>-0.003612</td>
      <td>0.003612</td>
      <td>0.413183</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003342</td>
      <td>0.003342</td>
      <td>0.003342</td>
      <td>0.416525</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>9.911623e-03</td>
      <td>-0.003334</td>
      <td>0.003334</td>
      <td>0.003334</td>
      <td>0.419859</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003320</td>
      <td>-0.003320</td>
      <td>0.003320</td>
      <td>0.416539</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003228</td>
      <td>-0.003228</td>
      <td>0.003228</td>
      <td>0.413310</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003226</td>
      <td>-0.003226</td>
      <td>0.003226</td>
      <td>0.410084</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 358
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;A standout scene.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8475 0.1525]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084835</td>
      <td>-0.084835</td>
      <td>0.084835</td>
      <td>0.414675</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.000000e+00</td>
      <td>0.039786</td>
      <td>-0.039786</td>
      <td>0.039786</td>
      <td>0.374889</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031186</td>
      <td>-0.031186</td>
      <td>0.031186</td>
      <td>0.343703</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025506</td>
      <td>0.025506</td>
      <td>0.025506</td>
      <td>0.369209</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.900000e+01</td>
      <td>0.021227</td>
      <td>-0.021227</td>
      <td>0.021227</td>
      <td>0.347983</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019646</td>
      <td>0.019646</td>
      <td>0.019646</td>
      <td>0.367629</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.357822</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008591</td>
      <td>-0.008591</td>
      <td>0.008591</td>
      <td>0.349231</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007530</td>
      <td>-0.007530</td>
      <td>0.007530</td>
      <td>0.341701</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007173</td>
      <td>-0.007173</td>
      <td>0.007173</td>
      <td>0.334528</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.006782</td>
      <td>0.006782</td>
      <td>0.006782</td>
      <td>0.341311</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.334771</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.005600</td>
      <td>-0.005600</td>
      <td>0.005600</td>
      <td>0.329171</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.005489</td>
      <td>0.005489</td>
      <td>0.005489</td>
      <td>0.334659</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004968</td>
      <td>-0.004968</td>
      <td>0.004968</td>
      <td>0.329691</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004875</td>
      <td>-0.004875</td>
      <td>0.004875</td>
      <td>0.324816</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004669</td>
      <td>-0.004669</td>
      <td>0.004669</td>
      <td>0.320147</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004449</td>
      <td>-0.004449</td>
      <td>0.004449</td>
      <td>0.315698</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.004412</td>
      <td>-0.004412</td>
      <td>0.004412</td>
      <td>0.311286</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004401</td>
      <td>0.004401</td>
      <td>0.004401</td>
      <td>0.315686</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.004365</td>
      <td>0.004365</td>
      <td>0.004365</td>
      <td>0.320051</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.004117</td>
      <td>0.004117</td>
      <td>0.004117</td>
      <td>0.324168</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>3.607859e-23</td>
      <td>0.004059</td>
      <td>-0.004059</td>
      <td>0.004059</td>
      <td>0.320110</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.004017</td>
      <td>0.004017</td>
      <td>0.004017</td>
      <td>0.324126</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003708</td>
      <td>-0.003708</td>
      <td>0.003708</td>
      <td>0.320418</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.003571</td>
      <td>-0.003571</td>
      <td>0.003571</td>
      <td>0.316847</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003380</td>
      <td>-0.003380</td>
      <td>0.003380</td>
      <td>0.313467</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003365</td>
      <td>-0.003365</td>
      <td>0.003365</td>
      <td>0.310102</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>0.000000e+00</td>
      <td>0.003327</td>
      <td>-0.003327</td>
      <td>0.003327</td>
      <td>0.306775</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003312</td>
      <td>0.003312</td>
      <td>0.003312</td>
      <td>0.310087</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 359
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;This scene is very strong and unpleasant.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.7425 0.2575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>3.010000e-01</td>
      <td>0.055568</td>
      <td>-0.055568</td>
      <td>0.055568</td>
      <td>0.443942</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-4.333333e-02</td>
      <td>0.044732</td>
      <td>-0.044732</td>
      <td>0.044732</td>
      <td>0.399210</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.025992</td>
      <td>-0.025992</td>
      <td>0.025992</td>
      <td>0.373217</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022442</td>
      <td>0.022442</td>
      <td>0.022442</td>
      <td>0.395660</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018890</td>
      <td>0.018890</td>
      <td>0.018890</td>
      <td>0.414550</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>topic 82</td>
      <td>4.546117e-01</td>
      <td>-0.018280</td>
      <td>0.018280</td>
      <td>0.018280</td>
      <td>0.432830</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.300000e+01</td>
      <td>0.012000</td>
      <td>-0.012000</td>
      <td>0.012000</td>
      <td>0.420830</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009851</td>
      <td>-0.009851</td>
      <td>0.009851</td>
      <td>0.410979</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.250699e-228</td>
      <td>0.007475</td>
      <td>-0.007475</td>
      <td>0.007475</td>
      <td>0.403505</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>1.646692e-02</td>
      <td>0.007470</td>
      <td>-0.007470</td>
      <td>0.007470</td>
      <td>0.396035</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006400</td>
      <td>-0.006400</td>
      <td>0.006400</td>
      <td>0.389634</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.910000e-02</td>
      <td>0.006173</td>
      <td>-0.006173</td>
      <td>0.006173</td>
      <td>0.383462</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.779645e-01</td>
      <td>0.005815</td>
      <td>-0.005815</td>
      <td>0.005815</td>
      <td>0.377647</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005150</td>
      <td>-0.005150</td>
      <td>0.005150</td>
      <td>0.372497</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004619</td>
      <td>-0.004619</td>
      <td>0.004619</td>
      <td>0.367878</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.004567</td>
      <td>-0.004567</td>
      <td>0.004567</td>
      <td>0.363310</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004142</td>
      <td>-0.004142</td>
      <td>0.004142</td>
      <td>0.359168</td>
    </tr>
    <tr>
      <th>792</th>
      <td>is very</td>
      <td>3.779645e-01</td>
      <td>-0.004047</td>
      <td>0.004047</td>
      <td>0.004047</td>
      <td>0.363215</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003928</td>
      <td>0.003928</td>
      <td>0.003928</td>
      <td>0.367143</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003890</td>
      <td>0.003890</td>
      <td>0.003890</td>
      <td>0.371033</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003873</td>
      <td>0.003873</td>
      <td>0.003873</td>
      <td>0.374906</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003686</td>
      <td>0.003686</td>
      <td>0.003686</td>
      <td>0.378593</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.496147e-26</td>
      <td>0.003465</td>
      <td>-0.003465</td>
      <td>0.003465</td>
      <td>0.375128</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003360</td>
      <td>-0.003360</td>
      <td>0.003360</td>
      <td>0.371768</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003328</td>
      <td>0.003328</td>
      <td>0.003328</td>
      <td>0.375096</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003015</td>
      <td>-0.003015</td>
      <td>0.003015</td>
      <td>0.372081</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.002966</td>
      <td>-0.002966</td>
      <td>0.002966</td>
      <td>0.369115</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.002964</td>
      <td>0.002964</td>
      <td>0.002964</td>
      <td>0.372079</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.002931</td>
      <td>-0.002931</td>
      <td>0.002931</td>
      <td>0.369147</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002913</td>
      <td>0.002913</td>
      <td>0.002913</td>
      <td>0.372060</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 364
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;This movie is also revealing.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8275 0.1725]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085051</td>
      <td>-0.085051</td>
      <td>0.085051</td>
      <td>0.414459</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.038228</td>
      <td>-0.038228</td>
      <td>0.038228</td>
      <td>0.376231</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.032310</td>
      <td>-0.032310</td>
      <td>0.032310</td>
      <td>0.343921</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025506</td>
      <td>0.025506</td>
      <td>0.025506</td>
      <td>0.369427</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019599</td>
      <td>0.019599</td>
      <td>0.019599</td>
      <td>0.389026</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.100000e+01</td>
      <td>0.018156</td>
      <td>-0.018156</td>
      <td>0.018156</td>
      <td>0.370870</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.361063</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.779645e-01</td>
      <td>0.009207</td>
      <td>-0.009207</td>
      <td>0.009207</td>
      <td>0.351856</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.008123</td>
      <td>0.008123</td>
      <td>0.008123</td>
      <td>0.359979</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007516</td>
      <td>-0.007516</td>
      <td>0.007516</td>
      <td>0.352463</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007273</td>
      <td>-0.007273</td>
      <td>0.007273</td>
      <td>0.345191</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.338651</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005630</td>
      <td>0.005630</td>
      <td>0.005630</td>
      <td>0.344281</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.005455</td>
      <td>-0.005455</td>
      <td>0.005455</td>
      <td>0.338827</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.005450</td>
      <td>0.005450</td>
      <td>0.005450</td>
      <td>0.344277</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.725238e-185</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.339290</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004875</td>
      <td>-0.004875</td>
      <td>0.004875</td>
      <td>0.334415</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004716</td>
      <td>-0.004716</td>
      <td>0.004716</td>
      <td>0.329699</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004401</td>
      <td>0.004401</td>
      <td>0.004401</td>
      <td>0.334100</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004352</td>
      <td>-0.004352</td>
      <td>0.004352</td>
      <td>0.329748</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.004325</td>
      <td>0.004325</td>
      <td>0.004325</td>
      <td>0.334073</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.004103</td>
      <td>0.004103</td>
      <td>0.004103</td>
      <td>0.338176</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.004085</td>
      <td>-0.004085</td>
      <td>0.004085</td>
      <td>0.334091</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.004049</td>
      <td>-0.004049</td>
      <td>0.004049</td>
      <td>0.330041</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003896</td>
      <td>0.003896</td>
      <td>0.003896</td>
      <td>0.333938</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003847</td>
      <td>-0.003847</td>
      <td>0.003847</td>
      <td>0.330091</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003652</td>
      <td>0.003652</td>
      <td>0.003652</td>
      <td>0.333742</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.833923e-79</td>
      <td>-0.003371</td>
      <td>0.003371</td>
      <td>0.003371</td>
      <td>0.337113</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>0.000000e+00</td>
      <td>0.003327</td>
      <td>-0.003327</td>
      <td>0.003327</td>
      <td>0.333786</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>2.028003e-05</td>
      <td>0.003278</td>
      <td>-0.003278</td>
      <td>0.003278</td>
      <td>0.330508</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 368
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;PS the only scene in the movie that was cool is when the central character finds her room blown up.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.5175 0.4825]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>1.000000e+00</td>
      <td>-0.107779</td>
      <td>0.107779</td>
      <td>0.107779</td>
      <td>0.607288</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.080000e-01</td>
      <td>0.081582</td>
      <td>-0.081582</td>
      <td>0.081582</td>
      <td>0.525706</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.182000e-01</td>
      <td>-0.032103</td>
      <td>0.032103</td>
      <td>0.032103</td>
      <td>0.557810</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.166667e-01</td>
      <td>0.027603</td>
      <td>-0.027603</td>
      <td>0.027603</td>
      <td>0.530207</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.000000e+01</td>
      <td>0.026604</td>
      <td>-0.026604</td>
      <td>0.026604</td>
      <td>0.503603</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025843</td>
      <td>0.025843</td>
      <td>0.025843</td>
      <td>0.529445</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.022241</td>
      <td>0.022241</td>
      <td>0.022241</td>
      <td>0.551686</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>2.310930e-01</td>
      <td>0.018640</td>
      <td>-0.018640</td>
      <td>0.018640</td>
      <td>0.533046</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009562</td>
      <td>-0.009562</td>
      <td>0.009562</td>
      <td>0.523484</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009025</td>
      <td>-0.009025</td>
      <td>0.009025</td>
      <td>0.514458</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007795</td>
      <td>-0.007795</td>
      <td>0.007795</td>
      <td>0.506663</td>
    </tr>
    <tr>
      <th>1941</th>
      <td>topic 15</td>
      <td>5.485036e-05</td>
      <td>0.007363</td>
      <td>-0.007363</td>
      <td>0.007363</td>
      <td>0.499300</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006902</td>
      <td>-0.006902</td>
      <td>0.006902</td>
      <td>0.492397</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>2.294157e-01</td>
      <td>-0.005590</td>
      <td>0.005590</td>
      <td>0.005590</td>
      <td>0.497987</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.294157e-01</td>
      <td>0.005366</td>
      <td>-0.005366</td>
      <td>0.005366</td>
      <td>0.492622</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.510272e-194</td>
      <td>0.005037</td>
      <td>-0.005037</td>
      <td>0.005037</td>
      <td>0.487585</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004335</td>
      <td>-0.004335</td>
      <td>0.004335</td>
      <td>0.483250</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003883</td>
      <td>0.003883</td>
      <td>0.003883</td>
      <td>0.487133</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003674</td>
      <td>0.003674</td>
      <td>0.003674</td>
      <td>0.490807</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003610</td>
      <td>-0.003610</td>
      <td>0.003610</td>
      <td>0.487197</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.010000e+02</td>
      <td>-0.003492</td>
      <td>0.003492</td>
      <td>0.003492</td>
      <td>0.490689</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003321</td>
      <td>-0.003321</td>
      <td>0.003321</td>
      <td>0.487368</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.294157e-01</td>
      <td>-0.003264</td>
      <td>0.003264</td>
      <td>0.003264</td>
      <td>0.490632</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003137</td>
      <td>0.003137</td>
      <td>0.003137</td>
      <td>0.493769</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>9.304670e-89</td>
      <td>-0.003109</td>
      <td>0.003109</td>
      <td>0.003109</td>
      <td>0.496878</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.003057</td>
      <td>0.003057</td>
      <td>0.003057</td>
      <td>0.499935</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003008</td>
      <td>-0.003008</td>
      <td>0.003008</td>
      <td>0.496927</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002936</td>
      <td>0.002936</td>
      <td>0.002936</td>
      <td>0.499863</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002892</td>
      <td>0.002892</td>
      <td>0.002892</td>
      <td>0.502755</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002873</td>
      <td>0.002873</td>
      <td>0.002873</td>
      <td>0.505628</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 372
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;You learn a lot about the real inside emotions of people in this movie, and a lot about the movie business itself.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7675 0.2325]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.092562</td>
      <td>-0.092562</td>
      <td>0.092562</td>
      <td>0.406947</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025992</td>
      <td>0.025992</td>
      <td>0.025992</td>
      <td>0.432940</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019495</td>
      <td>0.019495</td>
      <td>0.019495</td>
      <td>0.452435</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.200000e+01</td>
      <td>0.016177</td>
      <td>-0.016177</td>
      <td>0.016177</td>
      <td>0.436257</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.015050</td>
      <td>-0.015050</td>
      <td>0.015050</td>
      <td>0.421207</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.010210</td>
      <td>-0.010210</td>
      <td>0.010210</td>
      <td>0.410997</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.160000e+02</td>
      <td>0.009318</td>
      <td>-0.009318</td>
      <td>0.009318</td>
      <td>0.401679</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.009104</td>
      <td>0.009104</td>
      <td>0.009104</td>
      <td>0.410783</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.000000e-01</td>
      <td>0.008882</td>
      <td>-0.008882</td>
      <td>0.008882</td>
      <td>0.401901</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008645</td>
      <td>-0.008645</td>
      <td>0.008645</td>
      <td>0.393256</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.008446</td>
      <td>-0.008446</td>
      <td>0.008446</td>
      <td>0.384810</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007756</td>
      <td>-0.007756</td>
      <td>0.007756</td>
      <td>0.377055</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006681</td>
      <td>-0.006681</td>
      <td>0.006681</td>
      <td>0.370374</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005399</td>
      <td>0.005399</td>
      <td>0.005399</td>
      <td>0.375773</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.005232</td>
      <td>-0.005232</td>
      <td>0.005232</td>
      <td>0.370541</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.739888e-138</td>
      <td>0.004991</td>
      <td>-0.004991</td>
      <td>0.004991</td>
      <td>0.365550</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004249</td>
      <td>0.004249</td>
      <td>0.004249</td>
      <td>0.369799</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004093</td>
      <td>-0.004093</td>
      <td>0.004093</td>
      <td>0.365706</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003757</td>
      <td>0.003757</td>
      <td>0.003757</td>
      <td>0.369463</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003749</td>
      <td>0.003749</td>
      <td>0.003749</td>
      <td>0.373212</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003529</td>
      <td>0.003529</td>
      <td>0.003529</td>
      <td>0.376741</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003320</td>
      <td>-0.003320</td>
      <td>0.003320</td>
      <td>0.373421</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003247</td>
      <td>-0.003247</td>
      <td>0.003247</td>
      <td>0.370175</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003239</td>
      <td>-0.003239</td>
      <td>0.003239</td>
      <td>0.366936</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.228318e-195</td>
      <td>0.003222</td>
      <td>-0.003222</td>
      <td>0.003222</td>
      <td>0.363714</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003191</td>
      <td>0.003191</td>
      <td>0.003191</td>
      <td>0.366905</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003188</td>
      <td>-0.003188</td>
      <td>0.003188</td>
      <td>0.363718</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.176467e-86</td>
      <td>-0.003186</td>
      <td>0.003186</td>
      <td>0.003186</td>
      <td>0.366904</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>3.649862e-11</td>
      <td>0.003155</td>
      <td>-0.003155</td>
      <td>0.003155</td>
      <td>0.363749</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.003061</td>
      <td>-0.003061</td>
      <td>0.003061</td>
      <td>0.360688</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 379
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;None of them are engaging or exciting.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.26 0.74]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000</td>
      <td>-0.162004</td>
      <td>0.162004</td>
      <td>0.162004</td>
      <td>0.661513</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.680800</td>
      <td>-0.049128</td>
      <td>0.049128</td>
      <td>0.049128</td>
      <td>0.710641</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.528000</td>
      <td>0.045943</td>
      <td>-0.045943</td>
      <td>0.045943</td>
      <td>0.664698</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.022758</td>
      <td>0.022758</td>
      <td>0.022758</td>
      <td>0.687456</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.019632</td>
      <td>0.019632</td>
      <td>0.019632</td>
      <td>0.707088</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000</td>
      <td>0.009918</td>
      <td>-0.009918</td>
      <td>0.009918</td>
      <td>0.697170</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.350000</td>
      <td>-0.009343</td>
      <td>0.009343</td>
      <td>0.009343</td>
      <td>0.706513</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.008836</td>
      <td>-0.008836</td>
      <td>0.008836</td>
      <td>0.697677</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.008552</td>
      <td>-0.008552</td>
      <td>0.008552</td>
      <td>0.689124</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007851</td>
      <td>-0.007851</td>
      <td>0.007851</td>
      <td>0.681274</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006807</td>
      <td>-0.006807</td>
      <td>0.006807</td>
      <td>0.674467</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.005699</td>
      <td>-0.005699</td>
      <td>0.005699</td>
      <td>0.668768</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.005184</td>
      <td>-0.005184</td>
      <td>0.005184</td>
      <td>0.663583</td>
    </tr>
    <tr>
      <th>1021</th>
      <td>none</td>
      <td>0.377964</td>
      <td>0.004000</td>
      <td>-0.004000</td>
      <td>0.004000</td>
      <td>0.659584</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000</td>
      <td>0.003574</td>
      <td>-0.003574</td>
      <td>0.003574</td>
      <td>0.656010</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003346</td>
      <td>0.003346</td>
      <td>0.003346</td>
      <td>0.659356</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000</td>
      <td>0.003333</td>
      <td>-0.003333</td>
      <td>0.003333</td>
      <td>0.656022</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003049</td>
      <td>0.003049</td>
      <td>0.003049</td>
      <td>0.659072</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.002801</td>
      <td>0.002801</td>
      <td>0.002801</td>
      <td>0.661872</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000</td>
      <td>0.002791</td>
      <td>-0.002791</td>
      <td>0.002791</td>
      <td>0.659082</td>
    </tr>
    <tr>
      <th>46</th>
      <td>an</td>
      <td>0.000000</td>
      <td>0.002724</td>
      <td>-0.002724</td>
      <td>0.002724</td>
      <td>0.656358</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.002708</td>
      <td>-0.002708</td>
      <td>0.002708</td>
      <td>0.653650</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.002684</td>
      <td>0.002684</td>
      <td>0.002684</td>
      <td>0.656334</td>
    </tr>
    <tr>
      <th>206</th>
      <td>better</td>
      <td>0.000000</td>
      <td>-0.002683</td>
      <td>0.002683</td>
      <td>0.002683</td>
      <td>0.659017</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000</td>
      <td>-0.002656</td>
      <td>0.002656</td>
      <td>0.002656</td>
      <td>0.661673</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>0.002612</td>
      <td>-0.002612</td>
      <td>0.002612</td>
      <td>0.659061</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000</td>
      <td>0.002595</td>
      <td>-0.002595</td>
      <td>0.002595</td>
      <td>0.656466</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002561</td>
      <td>0.002561</td>
      <td>0.002561</td>
      <td>0.659027</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.002479</td>
      <td>0.002479</td>
      <td>0.002479</td>
      <td>0.661506</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000</td>
      <td>-0.002438</td>
      <td>0.002438</td>
      <td>0.002438</td>
      <td>0.663944</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 383
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;But the duet between the astronaut and his doctor at the beginning of the movie is a perfect exchange if one considers that this movie was made well into the Cold War and the astronaut&#39;s biggest fear is that he has crashed in the USSR.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8425 0.1575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.157120</td>
      <td>-0.157120</td>
      <td>0.157120</td>
      <td>0.342389</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.100000e-01</td>
      <td>0.070785</td>
      <td>-0.070785</td>
      <td>0.070785</td>
      <td>0.271604</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-3.182000e-01</td>
      <td>0.063723</td>
      <td>-0.063723</td>
      <td>0.063723</td>
      <td>0.207881</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>topic 71</td>
      <td>2.458862e-01</td>
      <td>-0.039237</td>
      <td>0.039237</td>
      <td>0.039237</td>
      <td>0.247118</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022836</td>
      <td>0.022836</td>
      <td>0.022836</td>
      <td>0.269954</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.017044</td>
      <td>0.017044</td>
      <td>0.017044</td>
      <td>0.286998</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>2.370000e+02</td>
      <td>0.014215</td>
      <td>-0.014215</td>
      <td>0.014215</td>
      <td>0.272783</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008817</td>
      <td>-0.008817</td>
      <td>0.008817</td>
      <td>0.263966</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006632</td>
      <td>-0.006632</td>
      <td>0.006632</td>
      <td>0.257334</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005782</td>
      <td>-0.005782</td>
      <td>0.005782</td>
      <td>0.251552</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>4.500000e+01</td>
      <td>0.004722</td>
      <td>-0.004722</td>
      <td>0.004722</td>
      <td>0.246830</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.200651e-188</td>
      <td>0.004237</td>
      <td>-0.004237</td>
      <td>0.004237</td>
      <td>0.242593</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>1.110764e-55</td>
      <td>0.004213</td>
      <td>-0.004213</td>
      <td>0.004213</td>
      <td>0.238380</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004185</td>
      <td>0.004185</td>
      <td>0.004185</td>
      <td>0.242564</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>1.490712e-01</td>
      <td>-0.004041</td>
      <td>0.004041</td>
      <td>0.004041</td>
      <td>0.246606</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.725320e-82</td>
      <td>-0.003231</td>
      <td>0.003231</td>
      <td>0.003231</td>
      <td>0.249837</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003109</td>
      <td>0.003109</td>
      <td>0.003109</td>
      <td>0.252946</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>0.003073</td>
      <td>-0.003073</td>
      <td>0.003073</td>
      <td>0.249873</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.981424e-01</td>
      <td>0.002965</td>
      <td>-0.002965</td>
      <td>0.002965</td>
      <td>0.246908</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.002767</td>
      <td>-0.002767</td>
      <td>0.002767</td>
      <td>0.244141</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002698</td>
      <td>-0.002698</td>
      <td>0.002698</td>
      <td>0.241444</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002625</td>
      <td>0.002625</td>
      <td>0.002625</td>
      <td>0.244069</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002598</td>
      <td>-0.002598</td>
      <td>0.002598</td>
      <td>0.241471</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>1.490712e-01</td>
      <td>-0.002350</td>
      <td>0.002350</td>
      <td>0.002350</td>
      <td>0.243821</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002273</td>
      <td>0.002273</td>
      <td>0.002273</td>
      <td>0.246094</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002254</td>
      <td>0.002254</td>
      <td>0.002254</td>
      <td>0.248348</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002202</td>
      <td>0.002202</td>
      <td>0.002202</td>
      <td>0.250550</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002175</td>
      <td>-0.002175</td>
      <td>0.002175</td>
      <td>0.248376</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.000000e-01</td>
      <td>0.002125</td>
      <td>-0.002125</td>
      <td>0.002125</td>
      <td>0.246250</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002095</td>
      <td>-0.002095</td>
      <td>0.002095</td>
      <td>0.244155</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 387
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;If you want a real scare rent this one!  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8875 0.1125]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.159201</td>
      <td>-0.159201</td>
      <td>0.159201</td>
      <td>0.340309</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.926000e-01</td>
      <td>0.092328</td>
      <td>-0.092328</td>
      <td>0.092328</td>
      <td>0.247981</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.200000e-01</td>
      <td>0.066744</td>
      <td>-0.066744</td>
      <td>0.066744</td>
      <td>0.181237</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.029915</td>
      <td>0.029915</td>
      <td>0.029915</td>
      <td>0.211152</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022779</td>
      <td>0.022779</td>
      <td>0.022779</td>
      <td>0.233931</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016460</td>
      <td>0.016460</td>
      <td>0.016460</td>
      <td>0.250391</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>4.100000e+01</td>
      <td>0.012089</td>
      <td>-0.012089</td>
      <td>0.012089</td>
      <td>0.238302</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000e+00</td>
      <td>0.011153</td>
      <td>-0.011153</td>
      <td>0.011153</td>
      <td>0.227149</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009035</td>
      <td>-0.009035</td>
      <td>0.009035</td>
      <td>0.218113</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>0.007707</td>
      <td>-0.007707</td>
      <td>0.007707</td>
      <td>0.210407</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007084</td>
      <td>-0.007084</td>
      <td>0.007084</td>
      <td>0.203323</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.427683e-261</td>
      <td>0.006653</td>
      <td>-0.006653</td>
      <td>0.006653</td>
      <td>0.196670</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005797</td>
      <td>-0.005797</td>
      <td>0.005797</td>
      <td>0.190873</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004710</td>
      <td>0.004710</td>
      <td>0.004710</td>
      <td>0.195583</td>
    </tr>
    <tr>
      <th>122</th>
      <td>are</td>
      <td>0.000000e+00</td>
      <td>0.004241</td>
      <td>-0.004241</td>
      <td>0.004241</td>
      <td>0.191342</td>
    </tr>
    <tr>
      <th>28</th>
      <td>all the</td>
      <td>0.000000e+00</td>
      <td>0.004171</td>
      <td>-0.004171</td>
      <td>0.004171</td>
      <td>0.187171</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.703107e-131</td>
      <td>0.004168</td>
      <td>-0.004168</td>
      <td>0.004168</td>
      <td>0.183003</td>
    </tr>
    <tr>
      <th>1586</th>
      <td>this</td>
      <td>3.333333e-01</td>
      <td>-0.003958</td>
      <td>0.003958</td>
      <td>0.003958</td>
      <td>0.186961</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003727</td>
      <td>0.003727</td>
      <td>0.003727</td>
      <td>0.190688</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003417</td>
      <td>0.003417</td>
      <td>0.003417</td>
      <td>0.194105</td>
    </tr>
    <tr>
      <th>718</th>
      <td>if</td>
      <td>3.333333e-01</td>
      <td>0.002966</td>
      <td>-0.002966</td>
      <td>0.002966</td>
      <td>0.191140</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002758</td>
      <td>0.002758</td>
      <td>0.002758</td>
      <td>0.193898</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002733</td>
      <td>0.002733</td>
      <td>0.002733</td>
      <td>0.196631</td>
    </tr>
    <tr>
      <th>1986</th>
      <td>topic 60</td>
      <td>0.000000e+00</td>
      <td>0.002544</td>
      <td>-0.002544</td>
      <td>0.002544</td>
      <td>0.194087</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002541</td>
      <td>-0.002541</td>
      <td>0.002541</td>
      <td>0.191547</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002391</td>
      <td>-0.002391</td>
      <td>0.002391</td>
      <td>0.189155</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002376</td>
      <td>0.002376</td>
      <td>0.002376</td>
      <td>0.191532</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.002313</td>
      <td>-0.002313</td>
      <td>0.002313</td>
      <td>0.189218</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002295</td>
      <td>0.002295</td>
      <td>0.002295</td>
      <td>0.191513</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002114</td>
      <td>-0.002114</td>
      <td>0.002114</td>
      <td>0.189399</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 391
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;This film highlights the fundamental flaws of the legal process, that it&#39;s not about discovering guilt or innocence, but rather, is about who presents better in court.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.755 0.245]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.158136</td>
      <td>-0.158136</td>
      <td>0.158136</td>
      <td>0.341374</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.436000e-01</td>
      <td>-0.055483</td>
      <td>0.055483</td>
      <td>0.055483</td>
      <td>0.396857</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.650000e-01</td>
      <td>0.049834</td>
      <td>-0.049834</td>
      <td>0.049834</td>
      <td>0.347023</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.041962</td>
      <td>-0.041962</td>
      <td>0.041962</td>
      <td>0.305061</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.500000e-01</td>
      <td>-0.014295</td>
      <td>0.014295</td>
      <td>0.014295</td>
      <td>0.319356</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>2.132007e-01</td>
      <td>-0.008620</td>
      <td>0.008620</td>
      <td>0.008620</td>
      <td>0.327977</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.700000e+01</td>
      <td>0.008301</td>
      <td>-0.008301</td>
      <td>0.008301</td>
      <td>0.319676</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007675</td>
      <td>-0.007675</td>
      <td>0.007675</td>
      <td>0.312001</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007578</td>
      <td>-0.007578</td>
      <td>0.007578</td>
      <td>0.304424</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.248595e-153</td>
      <td>0.006304</td>
      <td>-0.006304</td>
      <td>0.006304</td>
      <td>0.298119</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005802</td>
      <td>-0.005802</td>
      <td>0.005802</td>
      <td>0.292317</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>-0.005355</td>
      <td>0.005355</td>
      <td>0.005355</td>
      <td>0.297673</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.690000e+02</td>
      <td>0.004614</td>
      <td>-0.004614</td>
      <td>0.004614</td>
      <td>0.293059</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>0.000000e+00</td>
      <td>0.004109</td>
      <td>-0.004109</td>
      <td>0.004109</td>
      <td>0.288950</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.132007e-01</td>
      <td>0.003853</td>
      <td>-0.003853</td>
      <td>0.003853</td>
      <td>0.285097</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>4.882282e-195</td>
      <td>0.003650</td>
      <td>-0.003650</td>
      <td>0.003650</td>
      <td>0.281447</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>1.982497e-01</td>
      <td>0.003557</td>
      <td>-0.003557</td>
      <td>0.003557</td>
      <td>0.277891</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003171</td>
      <td>0.003171</td>
      <td>0.003171</td>
      <td>0.281062</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.042426e-220</td>
      <td>-0.003022</td>
      <td>0.003022</td>
      <td>0.003022</td>
      <td>0.284084</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.002887</td>
      <td>-0.002887</td>
      <td>0.002887</td>
      <td>0.281197</td>
    </tr>
    <tr>
      <th>635</th>
      <td>had</td>
      <td>0.000000e+00</td>
      <td>-0.002805</td>
      <td>0.002805</td>
      <td>0.002805</td>
      <td>0.284002</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002779</td>
      <td>0.002779</td>
      <td>0.002779</td>
      <td>0.286781</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002767</td>
      <td>-0.002767</td>
      <td>0.002767</td>
      <td>0.284014</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000e+00</td>
      <td>0.002760</td>
      <td>-0.002760</td>
      <td>0.002760</td>
      <td>0.281254</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002677</td>
      <td>-0.002677</td>
      <td>0.002677</td>
      <td>0.278577</td>
    </tr>
    <tr>
      <th>595</th>
      <td>going back</td>
      <td>0.000000e+00</td>
      <td>-0.002631</td>
      <td>0.002631</td>
      <td>0.002631</td>
      <td>0.281208</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>0.000000e+00</td>
      <td>-0.002620</td>
      <td>0.002620</td>
      <td>0.002620</td>
      <td>0.283828</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002432</td>
      <td>-0.002432</td>
      <td>0.002432</td>
      <td>0.281396</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002429</td>
      <td>-0.002429</td>
      <td>0.002429</td>
      <td>0.278967</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002367</td>
      <td>-0.002367</td>
      <td>0.002367</td>
      <td>0.276600</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 394
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Predictable, but not a bad watch.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.85 0.15]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-3.000000e+00</td>
      <td>0.143585</td>
      <td>-0.143585</td>
      <td>0.143585</td>
      <td>0.355925</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.034472</td>
      <td>-0.034472</td>
      <td>0.034472</td>
      <td>0.321454</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.824000e-01</td>
      <td>-0.032110</td>
      <td>0.032110</td>
      <td>0.032110</td>
      <td>0.353564</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>7.500000e-02</td>
      <td>0.026422</td>
      <td>-0.026422</td>
      <td>0.026422</td>
      <td>0.327142</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>4.860000e-01</td>
      <td>0.020620</td>
      <td>-0.020620</td>
      <td>0.020620</td>
      <td>0.306522</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>6.000000e+00</td>
      <td>0.012545</td>
      <td>-0.012545</td>
      <td>0.012545</td>
      <td>0.293977</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.500000e+01</td>
      <td>0.012057</td>
      <td>-0.012057</td>
      <td>0.012057</td>
      <td>0.281920</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007703</td>
      <td>-0.007703</td>
      <td>0.007703</td>
      <td>0.274217</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.690052e-01</td>
      <td>0.007702</td>
      <td>-0.007702</td>
      <td>0.007702</td>
      <td>0.266515</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007209</td>
      <td>-0.007209</td>
      <td>0.007209</td>
      <td>0.259307</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.007076</td>
      <td>-0.007076</td>
      <td>0.007076</td>
      <td>0.252230</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006527</td>
      <td>-0.006527</td>
      <td>0.006527</td>
      <td>0.245703</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005386</td>
      <td>-0.005386</td>
      <td>0.005386</td>
      <td>0.240317</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>4.082483e-01</td>
      <td>0.005105</td>
      <td>-0.005105</td>
      <td>0.005105</td>
      <td>0.235212</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.004772</td>
      <td>-0.004772</td>
      <td>0.004772</td>
      <td>0.230440</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>8.055381e-62</td>
      <td>-0.004596</td>
      <td>0.004596</td>
      <td>0.004596</td>
      <td>0.235037</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>6.135505e-27</td>
      <td>0.004228</td>
      <td>-0.004228</td>
      <td>0.004228</td>
      <td>0.230809</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004036</td>
      <td>-0.004036</td>
      <td>0.004036</td>
      <td>0.226774</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>4.082483e-01</td>
      <td>0.003768</td>
      <td>-0.003768</td>
      <td>0.003768</td>
      <td>0.223006</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003698</td>
      <td>-0.003698</td>
      <td>0.003698</td>
      <td>0.219307</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003507</td>
      <td>0.003507</td>
      <td>0.003507</td>
      <td>0.222814</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002890</td>
      <td>0.002890</td>
      <td>0.002890</td>
      <td>0.225704</td>
    </tr>
    <tr>
      <th>595</th>
      <td>going back</td>
      <td>0.000000e+00</td>
      <td>-0.002737</td>
      <td>0.002737</td>
      <td>0.002737</td>
      <td>0.228441</td>
    </tr>
    <tr>
      <th>682</th>
      <td>here</td>
      <td>0.000000e+00</td>
      <td>0.002659</td>
      <td>-0.002659</td>
      <td>0.002659</td>
      <td>0.225782</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>0.000000e+00</td>
      <td>0.002647</td>
      <td>-0.002647</td>
      <td>0.002647</td>
      <td>0.223135</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002605</td>
      <td>-0.002605</td>
      <td>0.002605</td>
      <td>0.220530</td>
    </tr>
    <tr>
      <th>1908</th>
      <td>you ll</td>
      <td>0.000000e+00</td>
      <td>0.002545</td>
      <td>-0.002545</td>
      <td>0.002545</td>
      <td>0.217985</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002348</td>
      <td>-0.002348</td>
      <td>0.002348</td>
      <td>0.215637</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002276</td>
      <td>0.002276</td>
      <td>0.002276</td>
      <td>0.217913</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002169</td>
      <td>0.002169</td>
      <td>0.002169</td>
      <td>0.220082</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 403
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The acting from all involved and that includes those like Shatner and Nimoy is bad and washed out and making them seem as old as they look in real life, the special effects are tacky like when Spock has to rescue Kirk on a jet pack when he falls down from a mountain.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3425 0.6575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.174479</td>
      <td>0.174479</td>
      <td>0.174479</td>
      <td>0.673989</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.820000e-01</td>
      <td>0.071924</td>
      <td>-0.071924</td>
      <td>0.071924</td>
      <td>0.602065</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>7.579000e-01</td>
      <td>-0.058680</td>
      <td>0.058680</td>
      <td>0.058680</td>
      <td>0.660745</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-3.306878e-02</td>
      <td>0.041187</td>
      <td>-0.041187</td>
      <td>0.041187</td>
      <td>0.619558</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023330</td>
      <td>0.023330</td>
      <td>0.023330</td>
      <td>0.642888</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018186</td>
      <td>0.018186</td>
      <td>0.018186</td>
      <td>0.661074</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.300000e+01</td>
      <td>0.015476</td>
      <td>-0.015476</td>
      <td>0.015476</td>
      <td>0.645598</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008421</td>
      <td>-0.008421</td>
      <td>0.008421</td>
      <td>0.637177</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.528542e-249</td>
      <td>0.007783</td>
      <td>-0.007783</td>
      <td>0.007783</td>
      <td>0.629394</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>5.000000e+00</td>
      <td>0.006723</td>
      <td>-0.006723</td>
      <td>0.006723</td>
      <td>0.622671</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006050</td>
      <td>-0.006050</td>
      <td>0.006050</td>
      <td>0.616621</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>1.360828e-01</td>
      <td>0.005482</td>
      <td>-0.005482</td>
      <td>0.005482</td>
      <td>0.611139</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.831363e-139</td>
      <td>0.004790</td>
      <td>-0.004790</td>
      <td>0.004790</td>
      <td>0.606349</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>8.694198e-02</td>
      <td>-0.004630</td>
      <td>0.004630</td>
      <td>0.004630</td>
      <td>0.610979</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>1.360828e-01</td>
      <td>-0.003893</td>
      <td>0.003893</td>
      <td>0.003893</td>
      <td>0.614872</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003741</td>
      <td>0.003741</td>
      <td>0.003741</td>
      <td>0.618613</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003706</td>
      <td>-0.003706</td>
      <td>0.003706</td>
      <td>0.614907</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>2.690000e+02</td>
      <td>0.003665</td>
      <td>-0.003665</td>
      <td>0.003665</td>
      <td>0.611242</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003568</td>
      <td>0.003568</td>
      <td>0.003568</td>
      <td>0.614810</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>1.642507e-06</td>
      <td>0.003512</td>
      <td>-0.003512</td>
      <td>0.003512</td>
      <td>0.611298</td>
    </tr>
    <tr>
      <th>2095</th>
      <td>topic 169</td>
      <td>1.580467e-01</td>
      <td>-0.003190</td>
      <td>0.003190</td>
      <td>0.003190</td>
      <td>0.614488</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003122</td>
      <td>0.003122</td>
      <td>0.003122</td>
      <td>0.617610</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>5.443311e-01</td>
      <td>-0.003120</td>
      <td>0.003120</td>
      <td>0.003120</td>
      <td>0.620730</td>
    </tr>
    <tr>
      <th>669</th>
      <td>he</td>
      <td>1.360828e-01</td>
      <td>0.003108</td>
      <td>-0.003108</td>
      <td>0.003108</td>
      <td>0.617622</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002993</td>
      <td>0.002993</td>
      <td>0.002993</td>
      <td>0.620615</td>
    </tr>
    <tr>
      <th>868</th>
      <td>life</td>
      <td>1.360828e-01</td>
      <td>-0.002938</td>
      <td>0.002938</td>
      <td>0.002938</td>
      <td>0.623553</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002688</td>
      <td>0.002688</td>
      <td>0.002688</td>
      <td>0.626241</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002591</td>
      <td>-0.002591</td>
      <td>0.002591</td>
      <td>0.623650</td>
    </tr>
    <tr>
      <th>1403</th>
      <td>steak and</td>
      <td>0.000000e+00</td>
      <td>0.002500</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.621150</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002401</td>
      <td>0.002401</td>
      <td>0.002401</td>
      <td>0.623551</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 405
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The only place good for this film is in the garbage.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.33 0.67]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.159354</td>
      <td>0.159354</td>
      <td>0.159354</td>
      <td>0.658864</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.250000e-01</td>
      <td>0.078654</td>
      <td>-0.078654</td>
      <td>0.078654</td>
      <td>0.580210</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.404000e-01</td>
      <td>-0.026637</td>
      <td>0.026637</td>
      <td>0.026637</td>
      <td>0.606847</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024954</td>
      <td>0.024954</td>
      <td>0.024954</td>
      <td>0.631801</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020529</td>
      <td>0.020529</td>
      <td>0.020529</td>
      <td>0.652330</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.012940</td>
      <td>-0.012940</td>
      <td>0.012940</td>
      <td>0.639390</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.500000e-01</td>
      <td>-0.011546</td>
      <td>0.011546</td>
      <td>0.011546</td>
      <td>0.650937</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009383</td>
      <td>-0.009383</td>
      <td>0.009383</td>
      <td>0.641553</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008864</td>
      <td>-0.008864</td>
      <td>0.008864</td>
      <td>0.632689</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.134148e-89</td>
      <td>0.007872</td>
      <td>-0.007872</td>
      <td>0.007872</td>
      <td>0.624818</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004305</td>
      <td>-0.004305</td>
      <td>0.004305</td>
      <td>0.620513</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.003840</td>
      <td>-0.003840</td>
      <td>0.003840</td>
      <td>0.616673</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003724</td>
      <td>-0.003724</td>
      <td>0.003724</td>
      <td>0.612949</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>2.672612e-01</td>
      <td>-0.003643</td>
      <td>0.003643</td>
      <td>0.003643</td>
      <td>0.616592</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003610</td>
      <td>0.003610</td>
      <td>0.003610</td>
      <td>0.620202</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.356187e-01</td>
      <td>0.003546</td>
      <td>-0.003546</td>
      <td>0.003546</td>
      <td>0.616655</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.672612e-01</td>
      <td>0.003486</td>
      <td>-0.003486</td>
      <td>0.003486</td>
      <td>0.613170</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003416</td>
      <td>0.003416</td>
      <td>0.003416</td>
      <td>0.616586</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>2.672612e-01</td>
      <td>0.003254</td>
      <td>-0.003254</td>
      <td>0.003254</td>
      <td>0.613332</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.400000e+01</td>
      <td>-0.003250</td>
      <td>0.003250</td>
      <td>0.003250</td>
      <td>0.616582</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002838</td>
      <td>-0.002838</td>
      <td>0.002838</td>
      <td>0.613744</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002780</td>
      <td>0.002780</td>
      <td>0.002780</td>
      <td>0.616524</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002768</td>
      <td>-0.002768</td>
      <td>0.002768</td>
      <td>0.613755</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.787447e-218</td>
      <td>-0.002759</td>
      <td>0.002759</td>
      <td>0.002759</td>
      <td>0.616514</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002753</td>
      <td>-0.002753</td>
      <td>0.002753</td>
      <td>0.613761</td>
    </tr>
    <tr>
      <th>1600</th>
      <td>this place</td>
      <td>0.000000e+00</td>
      <td>0.002665</td>
      <td>-0.002665</td>
      <td>0.002665</td>
      <td>0.611096</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002621</td>
      <td>0.002621</td>
      <td>0.002621</td>
      <td>0.613717</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002618</td>
      <td>0.002618</td>
      <td>0.002618</td>
      <td>0.616335</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002608</td>
      <td>0.002608</td>
      <td>0.002608</td>
      <td>0.618943</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002522</td>
      <td>0.002522</td>
      <td>0.002522</td>
      <td>0.621466</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 407
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Editing: The editing of this film was phenomenal in my opinion.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.65 0.35]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.089531</td>
      <td>-0.089531</td>
      <td>0.089531</td>
      <td>0.409979</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>5.000000e-01</td>
      <td>-0.041978</td>
      <td>0.041978</td>
      <td>0.041978</td>
      <td>0.451957</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024872</td>
      <td>0.024872</td>
      <td>0.024872</td>
      <td>0.476829</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020519</td>
      <td>0.020519</td>
      <td>0.020519</td>
      <td>0.497348</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.018197</td>
      <td>-0.018197</td>
      <td>0.018197</td>
      <td>0.479151</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.017094</td>
      <td>0.017094</td>
      <td>0.017094</td>
      <td>0.496244</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.013999</td>
      <td>-0.013999</td>
      <td>0.013999</td>
      <td>0.482246</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009897</td>
      <td>-0.009897</td>
      <td>0.009897</td>
      <td>0.472348</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.009547</td>
      <td>-0.009547</td>
      <td>0.009547</td>
      <td>0.462801</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008822</td>
      <td>-0.008822</td>
      <td>0.008822</td>
      <td>0.453979</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008061</td>
      <td>-0.008061</td>
      <td>0.008061</td>
      <td>0.445918</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.686679e-156</td>
      <td>0.007845</td>
      <td>-0.007845</td>
      <td>0.007845</td>
      <td>0.438073</td>
    </tr>
    <tr>
      <th>2096</th>
      <td>topic 170</td>
      <td>3.322109e-02</td>
      <td>-0.007039</td>
      <td>0.007039</td>
      <td>0.007039</td>
      <td>0.445113</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006707</td>
      <td>-0.006707</td>
      <td>0.006707</td>
      <td>0.438405</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.005837</td>
      <td>-0.005837</td>
      <td>0.005837</td>
      <td>0.432569</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005252</td>
      <td>-0.005252</td>
      <td>0.005252</td>
      <td>0.427317</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005180</td>
      <td>0.005180</td>
      <td>0.005180</td>
      <td>0.432497</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004028</td>
      <td>-0.004028</td>
      <td>0.004028</td>
      <td>0.428469</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003821</td>
      <td>0.003821</td>
      <td>0.003821</td>
      <td>0.432290</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000e+00</td>
      <td>-0.003725</td>
      <td>0.003725</td>
      <td>0.003725</td>
      <td>0.436015</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003602</td>
      <td>0.003602</td>
      <td>0.003602</td>
      <td>0.439616</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003574</td>
      <td>-0.003574</td>
      <td>0.003574</td>
      <td>0.436043</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003509</td>
      <td>-0.003509</td>
      <td>0.003509</td>
      <td>0.432534</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003471</td>
      <td>0.003471</td>
      <td>0.003471</td>
      <td>0.436005</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.773501e-01</td>
      <td>0.003374</td>
      <td>-0.003374</td>
      <td>0.003374</td>
      <td>0.432630</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003309</td>
      <td>0.003309</td>
      <td>0.003309</td>
      <td>0.435939</td>
    </tr>
    <tr>
      <th>1806</th>
      <td>we were</td>
      <td>0.000000e+00</td>
      <td>0.003269</td>
      <td>-0.003269</td>
      <td>0.003269</td>
      <td>0.432671</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003264</td>
      <td>0.003264</td>
      <td>0.003264</td>
      <td>0.435935</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.752007e-224</td>
      <td>-0.003199</td>
      <td>0.003199</td>
      <td>0.003199</td>
      <td>0.439134</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>-0.003147</td>
      <td>0.003147</td>
      <td>0.003147</td>
      <td>0.442282</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 408
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;When a song could explain the emotions of the subjects better, such as when Jay Adams&#39; unfortunate life was a subject of talk, the song Old Man by Neil Young was played, which evokes many emotions.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.4825 0.5175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.160919</td>
      <td>0.160919</td>
      <td>0.160919</td>
      <td>0.660429</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.350000e-01</td>
      <td>0.072249</td>
      <td>-0.072249</td>
      <td>0.072249</td>
      <td>0.588179</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>7.619048e-02</td>
      <td>0.036140</td>
      <td>-0.036140</td>
      <td>0.036140</td>
      <td>0.552040</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.182000e-01</td>
      <td>-0.026588</td>
      <td>0.026588</td>
      <td>0.026588</td>
      <td>0.578627</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.600000e+01</td>
      <td>0.025565</td>
      <td>-0.025565</td>
      <td>0.025565</td>
      <td>0.553062</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023953</td>
      <td>0.023953</td>
      <td>0.023953</td>
      <td>0.577015</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>7.000000e+00</td>
      <td>0.022142</td>
      <td>-0.022142</td>
      <td>0.022142</td>
      <td>0.554873</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020741</td>
      <td>0.020741</td>
      <td>0.020741</td>
      <td>0.575614</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>1.282544e-02</td>
      <td>0.012337</td>
      <td>-0.012337</td>
      <td>0.012337</td>
      <td>0.563277</td>
    </tr>
    <tr>
      <th>2004</th>
      <td>topic 78</td>
      <td>1.535738e-02</td>
      <td>0.011830</td>
      <td>-0.011830</td>
      <td>0.011830</td>
      <td>0.551448</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008732</td>
      <td>-0.008732</td>
      <td>0.008732</td>
      <td>0.542715</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008359</td>
      <td>-0.008359</td>
      <td>0.008359</td>
      <td>0.534357</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.007719</td>
      <td>0.007719</td>
      <td>0.007719</td>
      <td>0.542076</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.206466e-277</td>
      <td>0.007548</td>
      <td>-0.007548</td>
      <td>0.007548</td>
      <td>0.534528</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>topic 86</td>
      <td>1.659548e-02</td>
      <td>-0.006813</td>
      <td>0.006813</td>
      <td>0.006813</td>
      <td>0.541341</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006370</td>
      <td>-0.006370</td>
      <td>0.006370</td>
      <td>0.534971</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.005749</td>
      <td>-0.005749</td>
      <td>0.005749</td>
      <td>0.529222</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005083</td>
      <td>-0.005083</td>
      <td>0.005083</td>
      <td>0.524139</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.197683e-120</td>
      <td>0.004783</td>
      <td>-0.004783</td>
      <td>0.004783</td>
      <td>0.519356</td>
    </tr>
    <tr>
      <th>2059</th>
      <td>topic 133</td>
      <td>1.643850e-06</td>
      <td>-0.004084</td>
      <td>0.004084</td>
      <td>0.004084</td>
      <td>0.523440</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003897</td>
      <td>0.003897</td>
      <td>0.003897</td>
      <td>0.527336</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.003768</td>
      <td>-0.003768</td>
      <td>0.003768</td>
      <td>0.523568</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003578</td>
      <td>0.003578</td>
      <td>0.003578</td>
      <td>0.527146</td>
    </tr>
    <tr>
      <th>344</th>
      <td>could</td>
      <td>1.889822e-01</td>
      <td>-0.003512</td>
      <td>0.003512</td>
      <td>0.003512</td>
      <td>0.530658</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003015</td>
      <td>0.003015</td>
      <td>0.003015</td>
      <td>0.533674</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002987</td>
      <td>0.002987</td>
      <td>0.002987</td>
      <td>0.536661</td>
    </tr>
    <tr>
      <th>868</th>
      <td>life</td>
      <td>1.889822e-01</td>
      <td>-0.002938</td>
      <td>0.002938</td>
      <td>0.002938</td>
      <td>0.539599</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002868</td>
      <td>0.002868</td>
      <td>0.002868</td>
      <td>0.542467</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002770</td>
      <td>0.002770</td>
      <td>0.002770</td>
      <td>0.545237</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.230520e-319</td>
      <td>-0.002730</td>
      <td>0.002730</td>
      <td>0.002730</td>
      <td>0.547967</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 410
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Of course the footage from the 70s was grainy, but that only enhanced the film.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.84 0.16]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084447</td>
      <td>-0.084447</td>
      <td>0.084447</td>
      <td>0.415063</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.500000e+01</td>
      <td>0.036267</td>
      <td>-0.036267</td>
      <td>0.036267</td>
      <td>0.378796</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031633</td>
      <td>-0.031633</td>
      <td>0.031633</td>
      <td>0.347163</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024818</td>
      <td>0.024818</td>
      <td>0.024818</td>
      <td>0.371981</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019659</td>
      <td>0.019659</td>
      <td>0.019659</td>
      <td>0.391641</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.016252</td>
      <td>-0.016252</td>
      <td>0.016252</td>
      <td>0.375388</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009700</td>
      <td>-0.009700</td>
      <td>0.009700</td>
      <td>0.365688</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007830</td>
      <td>-0.007830</td>
      <td>0.007830</td>
      <td>0.357858</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007756</td>
      <td>-0.007756</td>
      <td>0.007756</td>
      <td>0.350102</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.841247e-152</td>
      <td>0.007271</td>
      <td>-0.007271</td>
      <td>0.007271</td>
      <td>0.342831</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006424</td>
      <td>-0.006424</td>
      <td>0.006424</td>
      <td>0.336407</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.006239</td>
      <td>-0.006239</td>
      <td>0.006239</td>
      <td>0.330168</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005562</td>
      <td>0.005562</td>
      <td>0.005562</td>
      <td>0.335731</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.005530</td>
      <td>0.005530</td>
      <td>0.005530</td>
      <td>0.341261</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005086</td>
      <td>-0.005086</td>
      <td>0.005086</td>
      <td>0.336175</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004706</td>
      <td>-0.004706</td>
      <td>0.004706</td>
      <td>0.331469</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.100000e+01</td>
      <td>0.004499</td>
      <td>-0.004499</td>
      <td>0.004499</td>
      <td>0.326970</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004245</td>
      <td>0.004245</td>
      <td>0.004245</td>
      <td>0.331215</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>3.015113e-01</td>
      <td>-0.004077</td>
      <td>0.004077</td>
      <td>0.004077</td>
      <td>0.335292</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003970</td>
      <td>-0.003970</td>
      <td>0.003970</td>
      <td>0.331322</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003828</td>
      <td>0.003828</td>
      <td>0.003828</td>
      <td>0.335150</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>6.061751e-243</td>
      <td>0.003691</td>
      <td>-0.003691</td>
      <td>0.003691</td>
      <td>0.331460</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003653</td>
      <td>-0.003653</td>
      <td>0.003653</td>
      <td>0.327806</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003638</td>
      <td>0.003638</td>
      <td>0.003638</td>
      <td>0.331444</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003344</td>
      <td>-0.003344</td>
      <td>0.003344</td>
      <td>0.328100</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>3.015113e-01</td>
      <td>-0.003322</td>
      <td>0.003322</td>
      <td>0.003322</td>
      <td>0.331422</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.181736e-219</td>
      <td>-0.003286</td>
      <td>0.003286</td>
      <td>0.003286</td>
      <td>0.334708</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003178</td>
      <td>0.003178</td>
      <td>0.003178</td>
      <td>0.337886</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.003127</td>
      <td>-0.003127</td>
      <td>0.003127</td>
      <td>0.334759</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003121</td>
      <td>-0.003121</td>
      <td>0.003121</td>
      <td>0.331638</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 415
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;But this understated film leaves a lasting impression.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7475 0.2525]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.410000e-01</td>
      <td>0.061298</td>
      <td>-0.061298</td>
      <td>0.061298</td>
      <td>0.438212</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.036333</td>
      <td>-0.036333</td>
      <td>0.036333</td>
      <td>0.401879</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>8.000000e+00</td>
      <td>0.030732</td>
      <td>-0.030732</td>
      <td>0.030732</td>
      <td>0.371147</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025165</td>
      <td>0.025165</td>
      <td>0.025165</td>
      <td>0.396312</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>2.263000e-01</td>
      <td>-0.024559</td>
      <td>0.024559</td>
      <td>0.024559</td>
      <td>0.420871</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019613</td>
      <td>0.019613</td>
      <td>0.019613</td>
      <td>0.440484</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.600000e+01</td>
      <td>0.016019</td>
      <td>-0.016019</td>
      <td>0.016019</td>
      <td>0.424466</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009758</td>
      <td>-0.009758</td>
      <td>0.009758</td>
      <td>0.414707</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008293</td>
      <td>-0.008293</td>
      <td>0.008293</td>
      <td>0.406414</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008076</td>
      <td>-0.008076</td>
      <td>0.008076</td>
      <td>0.398338</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.124490e-152</td>
      <td>0.007696</td>
      <td>-0.007696</td>
      <td>0.007696</td>
      <td>0.390643</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006586</td>
      <td>-0.006586</td>
      <td>0.006586</td>
      <td>0.384056</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.006133</td>
      <td>-0.006133</td>
      <td>0.006133</td>
      <td>0.377923</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005472</td>
      <td>0.005472</td>
      <td>0.005472</td>
      <td>0.383395</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.005171</td>
      <td>-0.005171</td>
      <td>0.005171</td>
      <td>0.378224</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.004587</td>
      <td>-0.004587</td>
      <td>0.004587</td>
      <td>0.373637</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.004542</td>
      <td>-0.004542</td>
      <td>0.004542</td>
      <td>0.369094</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.004248</td>
      <td>0.004248</td>
      <td>0.004248</td>
      <td>0.373342</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004128</td>
      <td>0.004128</td>
      <td>0.004128</td>
      <td>0.377470</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003991</td>
      <td>0.003991</td>
      <td>0.003991</td>
      <td>0.381461</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003984</td>
      <td>-0.003984</td>
      <td>0.003984</td>
      <td>0.377477</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003809</td>
      <td>0.003809</td>
      <td>0.003809</td>
      <td>0.381286</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.003777</td>
      <td>-0.003777</td>
      <td>0.003777</td>
      <td>0.377509</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003625</td>
      <td>0.003625</td>
      <td>0.003625</td>
      <td>0.381135</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>6.076283e-243</td>
      <td>0.003467</td>
      <td>-0.003467</td>
      <td>0.003467</td>
      <td>0.377668</td>
    </tr>
    <tr>
      <th>873</th>
      <td>like</td>
      <td>0.000000e+00</td>
      <td>-0.003433</td>
      <td>0.003433</td>
      <td>0.003433</td>
      <td>0.381101</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.346596e-219</td>
      <td>-0.003414</td>
      <td>0.003414</td>
      <td>0.003414</td>
      <td>0.384516</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003250</td>
      <td>-0.003250</td>
      <td>0.003250</td>
      <td>0.381266</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003154</td>
      <td>-0.003154</td>
      <td>0.003154</td>
      <td>0.378112</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>3.846364e-143</td>
      <td>0.003132</td>
      <td>-0.003132</td>
      <td>0.003132</td>
      <td>0.374980</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 417
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;You will leave the theater wanting to go out and dance under the stars.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.92 0.08]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000</td>
      <td>0.184815</td>
      <td>-0.184815</td>
      <td>0.184815</td>
      <td>0.314695</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.078989</td>
      <td>-0.078989</td>
      <td>0.078989</td>
      <td>0.235706</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000</td>
      <td>0.025953</td>
      <td>-0.025953</td>
      <td>0.025953</td>
      <td>0.209752</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.023334</td>
      <td>0.023334</td>
      <td>0.023334</td>
      <td>0.233086</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>14.000000</td>
      <td>0.018800</td>
      <td>-0.018800</td>
      <td>0.018800</td>
      <td>0.214286</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.017475</td>
      <td>0.017475</td>
      <td>0.017475</td>
      <td>0.231761</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-0.051600</td>
      <td>0.012665</td>
      <td>-0.012665</td>
      <td>0.012665</td>
      <td>0.219096</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>73.000000</td>
      <td>0.009130</td>
      <td>-0.009130</td>
      <td>0.009130</td>
      <td>0.209966</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009106</td>
      <td>-0.009106</td>
      <td>0.009106</td>
      <td>0.200860</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.006685</td>
      <td>-0.006685</td>
      <td>0.006685</td>
      <td>0.194176</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.005841</td>
      <td>-0.005841</td>
      <td>0.005841</td>
      <td>0.188335</td>
    </tr>
    <tr>
      <th>28</th>
      <td>all the</td>
      <td>0.000000</td>
      <td>0.004655</td>
      <td>-0.004655</td>
      <td>0.004655</td>
      <td>0.183680</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000</td>
      <td>0.004526</td>
      <td>-0.004526</td>
      <td>0.004526</td>
      <td>0.179155</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004153</td>
      <td>-0.004153</td>
      <td>0.004153</td>
      <td>0.175002</td>
    </tr>
    <tr>
      <th>1635</th>
      <td>to go</td>
      <td>0.301511</td>
      <td>-0.003901</td>
      <td>0.003901</td>
      <td>0.003901</td>
      <td>0.178903</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000</td>
      <td>-0.003691</td>
      <td>0.003691</td>
      <td>0.003691</td>
      <td>0.182594</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.301511</td>
      <td>0.003550</td>
      <td>-0.003550</td>
      <td>0.003550</td>
      <td>0.179044</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003536</td>
      <td>0.003536</td>
      <td>0.003536</td>
      <td>0.182580</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>0.301511</td>
      <td>-0.003371</td>
      <td>0.003371</td>
      <td>0.003371</td>
      <td>0.185951</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.003359</td>
      <td>0.003359</td>
      <td>0.003359</td>
      <td>0.189310</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.003079</td>
      <td>-0.003079</td>
      <td>0.003079</td>
      <td>0.186230</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003055</td>
      <td>0.003055</td>
      <td>0.003055</td>
      <td>0.189285</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.301511</td>
      <td>-0.002794</td>
      <td>0.002794</td>
      <td>0.002794</td>
      <td>0.192079</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000</td>
      <td>-0.002706</td>
      <td>0.002706</td>
      <td>0.002706</td>
      <td>0.194785</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.002565</td>
      <td>0.002565</td>
      <td>0.002565</td>
      <td>0.197350</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000</td>
      <td>-0.002510</td>
      <td>0.002510</td>
      <td>0.002510</td>
      <td>0.199860</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.002501</td>
      <td>0.002501</td>
      <td>0.002501</td>
      <td>0.202361</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000</td>
      <td>0.002463</td>
      <td>-0.002463</td>
      <td>0.002463</td>
      <td>0.199898</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.002451</td>
      <td>-0.002451</td>
      <td>0.002451</td>
      <td>0.197448</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.002382</td>
      <td>0.002382</td>
      <td>0.002382</td>
      <td>0.199829</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 418
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;The acting, as you&#39;d expect from this cast, is top notch.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.51 0.49]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.145632</td>
      <td>0.145632</td>
      <td>0.145632</td>
      <td>0.645142</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.530000e-01</td>
      <td>0.063444</td>
      <td>-0.063444</td>
      <td>0.063444</td>
      <td>0.581698</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.042371</td>
      <td>-0.042371</td>
      <td>0.042371</td>
      <td>0.539327</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019984</td>
      <td>0.019984</td>
      <td>0.019984</td>
      <td>0.559311</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.016255</td>
      <td>-0.016255</td>
      <td>0.016255</td>
      <td>0.543056</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.500000e-01</td>
      <td>0.012861</td>
      <td>-0.012861</td>
      <td>0.012861</td>
      <td>0.530195</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008102</td>
      <td>-0.008102</td>
      <td>0.008102</td>
      <td>0.522093</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007897</td>
      <td>-0.007897</td>
      <td>0.007897</td>
      <td>0.514196</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007661</td>
      <td>-0.007661</td>
      <td>0.007661</td>
      <td>0.506535</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005871</td>
      <td>-0.005871</td>
      <td>0.005871</td>
      <td>0.500664</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005410</td>
      <td>0.005410</td>
      <td>0.005410</td>
      <td>0.506074</td>
    </tr>
    <tr>
      <th>2031</th>
      <td>topic 105</td>
      <td>1.405735e-02</td>
      <td>-0.005066</td>
      <td>0.005066</td>
      <td>0.005066</td>
      <td>0.511139</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>3.333333e-01</td>
      <td>0.004556</td>
      <td>-0.004556</td>
      <td>0.004556</td>
      <td>0.506584</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004433</td>
      <td>-0.004433</td>
      <td>0.004433</td>
      <td>0.502151</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>8.487796e-21</td>
      <td>0.003976</td>
      <td>-0.003976</td>
      <td>0.003976</td>
      <td>0.498175</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003945</td>
      <td>0.003945</td>
      <td>0.003945</td>
      <td>0.502120</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003383</td>
      <td>0.003383</td>
      <td>0.003383</td>
      <td>0.505502</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003373</td>
      <td>0.003373</td>
      <td>0.003373</td>
      <td>0.508875</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.003200</td>
      <td>-0.003200</td>
      <td>0.003200</td>
      <td>0.505675</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003149</td>
      <td>0.003149</td>
      <td>0.003149</td>
      <td>0.508825</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003082</td>
      <td>-0.003082</td>
      <td>0.003082</td>
      <td>0.505743</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003055</td>
      <td>-0.003055</td>
      <td>0.003055</td>
      <td>0.502688</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002764</td>
      <td>-0.002764</td>
      <td>0.002764</td>
      <td>0.499924</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.900000e+01</td>
      <td>0.002757</td>
      <td>-0.002757</td>
      <td>0.002757</td>
      <td>0.497167</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.002699</td>
      <td>-0.002699</td>
      <td>0.002699</td>
      <td>0.494468</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>-0.002688</td>
      <td>0.002688</td>
      <td>0.002688</td>
      <td>0.497156</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002559</td>
      <td>0.002559</td>
      <td>0.002559</td>
      <td>0.499715</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002526</td>
      <td>-0.002526</td>
      <td>0.002526</td>
      <td>0.497189</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>9.925660e-03</td>
      <td>-0.002523</td>
      <td>0.002523</td>
      <td>0.002523</td>
      <td>0.499713</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.502213</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 423
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I struggle to find anything bad to say about it.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [1. 0.]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-5.000000e+00</td>
      <td>0.143037</td>
      <td>-0.143037</td>
      <td>0.143037</td>
      <td>0.356473</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-7.003000e-01</td>
      <td>0.094082</td>
      <td>-0.094082</td>
      <td>0.094082</td>
      <td>0.262391</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-7.000000e-01</td>
      <td>0.092147</td>
      <td>-0.092147</td>
      <td>0.092147</td>
      <td>0.170244</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.055575</td>
      <td>-0.055575</td>
      <td>0.055575</td>
      <td>0.114669</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.019196</td>
      <td>0.019196</td>
      <td>0.019196</td>
      <td>0.133865</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.013912</td>
      <td>0.013912</td>
      <td>0.013912</td>
      <td>0.147776</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.523648e-01</td>
      <td>0.010296</td>
      <td>-0.010296</td>
      <td>0.010296</td>
      <td>0.137480</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.000000e+01</td>
      <td>0.008183</td>
      <td>-0.008183</td>
      <td>0.008183</td>
      <td>0.129297</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007954</td>
      <td>-0.007954</td>
      <td>0.007954</td>
      <td>0.121343</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.005820</td>
      <td>-0.005820</td>
      <td>0.005820</td>
      <td>0.115523</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.000000e+01</td>
      <td>0.005600</td>
      <td>-0.005600</td>
      <td>0.005600</td>
      <td>0.109923</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.005295</td>
      <td>-0.005295</td>
      <td>0.005295</td>
      <td>0.104628</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005236</td>
      <td>-0.005236</td>
      <td>0.005236</td>
      <td>0.099392</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003706</td>
      <td>-0.003706</td>
      <td>0.003706</td>
      <td>0.095687</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003556</td>
      <td>-0.003556</td>
      <td>0.003556</td>
      <td>0.092131</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003227</td>
      <td>-0.003227</td>
      <td>0.003227</td>
      <td>0.088904</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.002891</td>
      <td>0.002891</td>
      <td>0.002891</td>
      <td>0.091795</td>
    </tr>
    <tr>
      <th>118</th>
      <td>anyone</td>
      <td>0.000000e+00</td>
      <td>0.002679</td>
      <td>-0.002679</td>
      <td>0.002679</td>
      <td>0.089117</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002256</td>
      <td>0.002256</td>
      <td>0.002256</td>
      <td>0.091373</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002094</td>
      <td>-0.002094</td>
      <td>0.002094</td>
      <td>0.089279</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002071</td>
      <td>0.002071</td>
      <td>0.002071</td>
      <td>0.091350</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.001758</td>
      <td>-0.001758</td>
      <td>0.001758</td>
      <td>0.089592</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.001726</td>
      <td>-0.001726</td>
      <td>0.001726</td>
      <td>0.087866</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>0.000000e+00</td>
      <td>0.001652</td>
      <td>-0.001652</td>
      <td>0.001652</td>
      <td>0.086214</td>
    </tr>
    <tr>
      <th>2042</th>
      <td>topic 116</td>
      <td>2.707807e-149</td>
      <td>0.001625</td>
      <td>-0.001625</td>
      <td>0.001625</td>
      <td>0.084589</td>
    </tr>
    <tr>
      <th>1952</th>
      <td>topic 26</td>
      <td>0.000000e+00</td>
      <td>0.001610</td>
      <td>-0.001610</td>
      <td>0.001610</td>
      <td>0.082978</td>
    </tr>
    <tr>
      <th>1943</th>
      <td>topic 17</td>
      <td>0.000000e+00</td>
      <td>0.001561</td>
      <td>-0.001561</td>
      <td>0.001561</td>
      <td>0.081417</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.001541</td>
      <td>0.001541</td>
      <td>0.001541</td>
      <td>0.082958</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.001501</td>
      <td>0.001501</td>
      <td>0.001501</td>
      <td>0.084459</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.001462</td>
      <td>0.001462</td>
      <td>0.001462</td>
      <td>0.085921</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 424
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Mark my words, this is one of those cult films like Evil Dead 2 or Phantasm that people will still be discovering and falling in love with 20, 30, 40 years down the line.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9175 0.0825]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.159446</td>
      <td>-0.159446</td>
      <td>0.159446</td>
      <td>0.340064</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-5.574000e-01</td>
      <td>0.099176</td>
      <td>-0.099176</td>
      <td>0.099176</td>
      <td>0.240888</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.490000e-01</td>
      <td>0.060237</td>
      <td>-0.060237</td>
      <td>0.060237</td>
      <td>0.180650</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-2.138889e-01</td>
      <td>0.037249</td>
      <td>-0.037249</td>
      <td>0.037249</td>
      <td>0.143401</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.020393</td>
      <td>0.020393</td>
      <td>0.020393</td>
      <td>0.163794</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.015122</td>
      <td>0.015122</td>
      <td>0.015122</td>
      <td>0.178916</td>
    </tr>
    <tr>
      <th>1936</th>
      <td>topic 10</td>
      <td>1.040418e-01</td>
      <td>-0.011751</td>
      <td>0.011751</td>
      <td>0.011751</td>
      <td>0.190667</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.720000e+02</td>
      <td>0.011206</td>
      <td>-0.011206</td>
      <td>0.011206</td>
      <td>0.179462</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.400000e+01</td>
      <td>0.011070</td>
      <td>-0.011070</td>
      <td>0.011070</td>
      <td>0.168392</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008743</td>
      <td>-0.008743</td>
      <td>0.008743</td>
      <td>0.159649</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>topic 86</td>
      <td>1.632787e-01</td>
      <td>-0.007842</td>
      <td>0.007842</td>
      <td>0.007842</td>
      <td>0.167491</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>7.682009e-154</td>
      <td>0.006324</td>
      <td>-0.006324</td>
      <td>0.006324</td>
      <td>0.161167</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005475</td>
      <td>-0.005475</td>
      <td>0.005475</td>
      <td>0.155692</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>-0.004303</td>
      <td>0.004303</td>
      <td>0.004303</td>
      <td>0.159995</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.650116e-18</td>
      <td>0.003735</td>
      <td>-0.003735</td>
      <td>0.003735</td>
      <td>0.156260</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.097343e-123</td>
      <td>-0.003496</td>
      <td>0.003496</td>
      <td>0.003496</td>
      <td>0.159756</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003074</td>
      <td>0.003074</td>
      <td>0.003074</td>
      <td>0.162831</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002628</td>
      <td>0.002628</td>
      <td>0.002628</td>
      <td>0.165458</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002555</td>
      <td>0.002555</td>
      <td>0.002555</td>
      <td>0.168013</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>this phone</td>
      <td>0.000000e+00</td>
      <td>0.002436</td>
      <td>-0.002436</td>
      <td>0.002436</td>
      <td>0.165577</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002332</td>
      <td>-0.002332</td>
      <td>0.002332</td>
      <td>0.163245</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002299</td>
      <td>-0.002299</td>
      <td>0.002299</td>
      <td>0.160946</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002277</td>
      <td>0.002277</td>
      <td>0.002277</td>
      <td>0.163223</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002272</td>
      <td>0.002272</td>
      <td>0.002272</td>
      <td>0.165494</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>1.889822e-01</td>
      <td>0.002117</td>
      <td>-0.002117</td>
      <td>0.002117</td>
      <td>0.163377</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002050</td>
      <td>0.002050</td>
      <td>0.002050</td>
      <td>0.165427</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.001903</td>
      <td>0.001903</td>
      <td>0.001903</td>
      <td>0.167330</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>-0.001902</td>
      <td>0.001902</td>
      <td>0.001902</td>
      <td>0.169232</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.001860</td>
      <td>0.001860</td>
      <td>0.001860</td>
      <td>0.171092</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.001809</td>
      <td>-0.001809</td>
      <td>0.001809</td>
      <td>0.169283</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 431
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;See both films if you can.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8425 0.1575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084745</td>
      <td>-0.084745</td>
      <td>0.084745</td>
      <td>0.414765</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>6.000000e+00</td>
      <td>0.034677</td>
      <td>-0.034677</td>
      <td>0.034677</td>
      <td>0.380088</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031632</td>
      <td>-0.031632</td>
      <td>0.031632</td>
      <td>0.348456</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025645</td>
      <td>0.025645</td>
      <td>0.025645</td>
      <td>0.374101</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>2.800000e+01</td>
      <td>0.019655</td>
      <td>-0.019655</td>
      <td>0.019655</td>
      <td>0.354445</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019646</td>
      <td>0.019646</td>
      <td>0.019646</td>
      <td>0.374091</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009756</td>
      <td>-0.009756</td>
      <td>0.009756</td>
      <td>0.364336</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008828</td>
      <td>-0.008828</td>
      <td>0.008828</td>
      <td>0.355508</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.118127e-147</td>
      <td>0.007530</td>
      <td>-0.007530</td>
      <td>0.007530</td>
      <td>0.347978</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007014</td>
      <td>-0.007014</td>
      <td>0.007014</td>
      <td>0.340964</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.006808</td>
      <td>0.006808</td>
      <td>0.006808</td>
      <td>0.347772</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006385</td>
      <td>-0.006385</td>
      <td>0.006385</td>
      <td>0.341387</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005630</td>
      <td>0.005630</td>
      <td>0.005630</td>
      <td>0.347017</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.005484</td>
      <td>-0.005484</td>
      <td>0.005484</td>
      <td>0.341533</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.005456</td>
      <td>0.005456</td>
      <td>0.005456</td>
      <td>0.346989</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.005226</td>
      <td>-0.005226</td>
      <td>0.005226</td>
      <td>0.341763</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.336775</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004497</td>
      <td>-0.004497</td>
      <td>0.004497</td>
      <td>0.332279</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.004461</td>
      <td>-0.004461</td>
      <td>0.004461</td>
      <td>0.327818</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004401</td>
      <td>0.004401</td>
      <td>0.004401</td>
      <td>0.332219</td>
    </tr>
    <tr>
      <th>718</th>
      <td>if</td>
      <td>3.535534e-01</td>
      <td>0.004367</td>
      <td>-0.004367</td>
      <td>0.004367</td>
      <td>0.327852</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000e+00</td>
      <td>-0.004253</td>
      <td>0.004253</td>
      <td>0.004253</td>
      <td>0.332105</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004072</td>
      <td>-0.004072</td>
      <td>0.004072</td>
      <td>0.328033</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>6.797261e-238</td>
      <td>0.004040</td>
      <td>-0.004040</td>
      <td>0.004040</td>
      <td>0.323994</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003988</td>
      <td>0.003988</td>
      <td>0.003988</td>
      <td>0.327982</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003943</td>
      <td>0.003943</td>
      <td>0.003943</td>
      <td>0.331925</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003708</td>
      <td>-0.003708</td>
      <td>0.003708</td>
      <td>0.328217</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>1.349917e-138</td>
      <td>0.003327</td>
      <td>-0.003327</td>
      <td>0.003327</td>
      <td>0.324890</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003325</td>
      <td>-0.003325</td>
      <td>0.003325</td>
      <td>0.321565</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.214784e-214</td>
      <td>-0.003285</td>
      <td>0.003285</td>
      <td>0.003285</td>
      <td>0.324850</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 432
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;It was that year, however, that reminded us that Huston was still at the top of his game as evinced by his faithful adaptation of James Joyce\&#39;s acclaimed novella &#34;The Dead.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.4875 0.5125]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>4.000000e+00</td>
      <td>-0.181477</td>
      <td>0.181477</td>
      <td>0.181477</td>
      <td>0.680987</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.270000e-01</td>
      <td>0.064305</td>
      <td>-0.064305</td>
      <td>0.064305</td>
      <td>0.616682</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-1.531000e-01</td>
      <td>0.055501</td>
      <td>-0.055501</td>
      <td>0.055501</td>
      <td>0.561181</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-3.333333e-02</td>
      <td>0.037107</td>
      <td>-0.037107</td>
      <td>0.037107</td>
      <td>0.524074</td>
    </tr>
    <tr>
      <th>2042</th>
      <td>topic 116</td>
      <td>3.148937e-01</td>
      <td>-0.029551</td>
      <td>0.029551</td>
      <td>0.029551</td>
      <td>0.553624</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022494</td>
      <td>0.022494</td>
      <td>0.022494</td>
      <td>0.576119</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.100000e+01</td>
      <td>0.021996</td>
      <td>-0.021996</td>
      <td>0.021996</td>
      <td>0.554122</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018195</td>
      <td>0.018195</td>
      <td>0.018195</td>
      <td>0.572317</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>6.000000e+00</td>
      <td>0.009225</td>
      <td>-0.009225</td>
      <td>0.009225</td>
      <td>0.563092</td>
    </tr>
    <tr>
      <th>2012</th>
      <td>topic 86</td>
      <td>2.507169e-01</td>
      <td>-0.008194</td>
      <td>0.008194</td>
      <td>0.008194</td>
      <td>0.571286</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008123</td>
      <td>-0.008123</td>
      <td>0.008123</td>
      <td>0.563164</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007287</td>
      <td>-0.007287</td>
      <td>0.007287</td>
      <td>0.555877</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.838531e-253</td>
      <td>0.006871</td>
      <td>-0.006871</td>
      <td>0.006871</td>
      <td>0.549005</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>5.144958e-01</td>
      <td>0.005735</td>
      <td>-0.005735</td>
      <td>0.005735</td>
      <td>0.543271</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005069</td>
      <td>-0.005069</td>
      <td>0.005069</td>
      <td>0.538202</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.716216e-207</td>
      <td>0.004384</td>
      <td>-0.004384</td>
      <td>0.004384</td>
      <td>0.533818</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>1.714986e-01</td>
      <td>-0.004081</td>
      <td>0.004081</td>
      <td>0.004081</td>
      <td>0.537900</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>3.429972e-01</td>
      <td>0.003985</td>
      <td>-0.003985</td>
      <td>0.003985</td>
      <td>0.533915</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.003774</td>
      <td>-0.003774</td>
      <td>0.003774</td>
      <td>0.530141</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003714</td>
      <td>0.003714</td>
      <td>0.003714</td>
      <td>0.533855</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003628</td>
      <td>0.003628</td>
      <td>0.003628</td>
      <td>0.537483</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003559</td>
      <td>-0.003559</td>
      <td>0.003559</td>
      <td>0.533924</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>0.000000e+00</td>
      <td>-0.003526</td>
      <td>0.003526</td>
      <td>0.003526</td>
      <td>0.537450</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003335</td>
      <td>0.003335</td>
      <td>0.003335</td>
      <td>0.540785</td>
    </tr>
    <tr>
      <th>693</th>
      <td>his</td>
      <td>3.429972e-01</td>
      <td>-0.003048</td>
      <td>0.003048</td>
      <td>0.003048</td>
      <td>0.543833</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003030</td>
      <td>-0.003030</td>
      <td>0.003030</td>
      <td>0.540803</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002891</td>
      <td>0.002891</td>
      <td>0.002891</td>
      <td>0.543694</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002847</td>
      <td>0.002847</td>
      <td>0.002847</td>
      <td>0.546541</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.002836</td>
      <td>-0.002836</td>
      <td>0.002836</td>
      <td>0.543705</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002711</td>
      <td>0.002711</td>
      <td>0.002711</td>
      <td>0.546415</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 433
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Feelings, thoughts...Gabriel&#39;s discomfort during the dance...all these intangibles leap to life and come within the viewer&#39;s grasp in Huston&#39;s portrayal.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9375 0.0625]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.182933</td>
      <td>-0.182933</td>
      <td>0.182933</td>
      <td>0.316577</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.215000e-01</td>
      <td>0.079058</td>
      <td>-0.079058</td>
      <td>0.079058</td>
      <td>0.237519</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.075653</td>
      <td>-0.075653</td>
      <td>0.075653</td>
      <td>0.161866</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.023715</td>
      <td>-0.023715</td>
      <td>0.023715</td>
      <td>0.138151</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.021720</td>
      <td>0.021720</td>
      <td>0.021720</td>
      <td>0.159871</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.015673</td>
      <td>0.015673</td>
      <td>0.015673</td>
      <td>0.175545</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.550000e+02</td>
      <td>0.012864</td>
      <td>-0.012864</td>
      <td>0.012864</td>
      <td>0.162681</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.000000e+01</td>
      <td>0.011218</td>
      <td>-0.011218</td>
      <td>0.011218</td>
      <td>0.151463</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.100000e+01</td>
      <td>-0.010653</td>
      <td>0.010653</td>
      <td>0.010653</td>
      <td>0.162117</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008988</td>
      <td>-0.008988</td>
      <td>0.008988</td>
      <td>0.153128</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.157934e-275</td>
      <td>0.006319</td>
      <td>-0.006319</td>
      <td>0.006319</td>
      <td>0.146810</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005471</td>
      <td>-0.005471</td>
      <td>0.005471</td>
      <td>0.141339</td>
    </tr>
    <tr>
      <th>1946</th>
      <td>topic 20</td>
      <td>2.259736e-02</td>
      <td>-0.004926</td>
      <td>0.004926</td>
      <td>0.004926</td>
      <td>0.146265</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>-0.004915</td>
      <td>0.004915</td>
      <td>0.004915</td>
      <td>0.151180</td>
    </tr>
    <tr>
      <th>2102</th>
      <td>topic 176</td>
      <td>1.259480e-02</td>
      <td>-0.003930</td>
      <td>0.003930</td>
      <td>0.003930</td>
      <td>0.155109</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.032310e-37</td>
      <td>0.003792</td>
      <td>-0.003792</td>
      <td>0.003792</td>
      <td>0.151317</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.306685e-236</td>
      <td>-0.003220</td>
      <td>0.003220</td>
      <td>0.003220</td>
      <td>0.154537</td>
    </tr>
    <tr>
      <th>22</th>
      <td>all</td>
      <td>2.773501e-01</td>
      <td>-0.003214</td>
      <td>0.003214</td>
      <td>0.003214</td>
      <td>0.157752</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003162</td>
      <td>0.003162</td>
      <td>0.003162</td>
      <td>0.160914</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002772</td>
      <td>-0.002772</td>
      <td>0.002772</td>
      <td>0.158142</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002703</td>
      <td>0.002703</td>
      <td>0.002703</td>
      <td>0.160845</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002665</td>
      <td>0.002665</td>
      <td>0.002665</td>
      <td>0.163510</td>
    </tr>
    <tr>
      <th>347</th>
      <td>could not</td>
      <td>0.000000e+00</td>
      <td>0.002493</td>
      <td>-0.002493</td>
      <td>0.002493</td>
      <td>0.161018</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002385</td>
      <td>0.002385</td>
      <td>0.002385</td>
      <td>0.163403</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002318</td>
      <td>-0.002318</td>
      <td>0.002318</td>
      <td>0.161085</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>4.900968e-15</td>
      <td>0.002288</td>
      <td>-0.002288</td>
      <td>0.002288</td>
      <td>0.158797</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002251</td>
      <td>0.002251</td>
      <td>0.002251</td>
      <td>0.161049</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002070</td>
      <td>0.002070</td>
      <td>0.002070</td>
      <td>0.163118</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002062</td>
      <td>0.002062</td>
      <td>0.002062</td>
      <td>0.165180</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002029</td>
      <td>-0.002029</td>
      <td>0.002029</td>
      <td>0.163151</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 443
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It has everything you could want... suspense, drama, comedy, confusing subplots, native americans, brain eating... If you&#39;re looking for the be-all, end-all of brainsucking movies, look no further.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9425 0.0575]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.167565</td>
      <td>-0.167565</td>
      <td>0.167565</td>
      <td>0.331945</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>7.900000e-02</td>
      <td>0.062976</td>
      <td>-0.062976</td>
      <td>0.062976</td>
      <td>0.268969</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-1.531000e-01</td>
      <td>0.046207</td>
      <td>-0.046207</td>
      <td>0.046207</td>
      <td>0.222762</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-1.500000e-01</td>
      <td>0.035434</td>
      <td>-0.035434</td>
      <td>0.035434</td>
      <td>0.187329</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022236</td>
      <td>0.022236</td>
      <td>0.022236</td>
      <td>0.209565</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.800000e+01</td>
      <td>0.020241</td>
      <td>-0.020241</td>
      <td>0.020241</td>
      <td>0.189324</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.016978</td>
      <td>0.016978</td>
      <td>0.016978</td>
      <td>0.206302</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.990000e+02</td>
      <td>0.015137</td>
      <td>-0.015137</td>
      <td>0.015137</td>
      <td>0.191165</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009176</td>
      <td>-0.009176</td>
      <td>0.009176</td>
      <td>0.181989</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007657</td>
      <td>-0.007657</td>
      <td>0.007657</td>
      <td>0.174331</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.834633e-238</td>
      <td>0.006506</td>
      <td>-0.006506</td>
      <td>0.006506</td>
      <td>0.167826</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005808</td>
      <td>-0.005808</td>
      <td>0.005808</td>
      <td>0.162017</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.157682e-15</td>
      <td>0.004179</td>
      <td>-0.004179</td>
      <td>0.004179</td>
      <td>0.157839</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.003854</td>
      <td>0.003854</td>
      <td>0.003854</td>
      <td>0.161692</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003516</td>
      <td>-0.003516</td>
      <td>0.003516</td>
      <td>0.158176</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.003515</td>
      <td>-0.003515</td>
      <td>0.003515</td>
      <td>0.154661</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>3.481553e-01</td>
      <td>-0.003506</td>
      <td>0.003506</td>
      <td>0.003506</td>
      <td>0.158167</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003494</td>
      <td>0.003494</td>
      <td>0.003494</td>
      <td>0.161662</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.615409e-91</td>
      <td>-0.003399</td>
      <td>0.003399</td>
      <td>0.003399</td>
      <td>0.165061</td>
    </tr>
    <tr>
      <th>22</th>
      <td>all</td>
      <td>3.481553e-01</td>
      <td>-0.003164</td>
      <td>0.003164</td>
      <td>0.003164</td>
      <td>0.168225</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>0.003003</td>
      <td>-0.003003</td>
      <td>0.003003</td>
      <td>0.165222</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.002831</td>
      <td>0.002831</td>
      <td>0.002831</td>
      <td>0.168053</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002708</td>
      <td>0.002708</td>
      <td>0.002708</td>
      <td>0.170761</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002599</td>
      <td>0.002599</td>
      <td>0.002599</td>
      <td>0.173360</td>
    </tr>
    <tr>
      <th>347</th>
      <td>could not</td>
      <td>0.000000e+00</td>
      <td>0.002507</td>
      <td>-0.002507</td>
      <td>0.002507</td>
      <td>0.170853</td>
    </tr>
    <tr>
      <th>937</th>
      <td>may</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.173353</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002495</td>
      <td>-0.002495</td>
      <td>0.002495</td>
      <td>0.170858</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002420</td>
      <td>0.002420</td>
      <td>0.002420</td>
      <td>0.173278</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>3.908065e-17</td>
      <td>0.002338</td>
      <td>-0.002338</td>
      <td>0.002338</td>
      <td>0.170940</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002328</td>
      <td>0.002328</td>
      <td>0.002328</td>
      <td>0.173268</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 462
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;A film not easily forgotten.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9525 0.0475]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-1.000000e+00</td>
      <td>0.134082</td>
      <td>-0.134082</td>
      <td>0.134082</td>
      <td>0.365428</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.920000e-01</td>
      <td>0.045749</td>
      <td>-0.045749</td>
      <td>0.045749</td>
      <td>0.319679</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-2.166667e-01</td>
      <td>0.038208</td>
      <td>-0.038208</td>
      <td>0.038208</td>
      <td>0.281471</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.036841</td>
      <td>-0.036841</td>
      <td>0.036841</td>
      <td>0.244630</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-9.510000e-02</td>
      <td>0.024910</td>
      <td>-0.024910</td>
      <td>0.024910</td>
      <td>0.219720</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.000000e+01</td>
      <td>0.016939</td>
      <td>-0.016939</td>
      <td>0.016939</td>
      <td>0.202781</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.014674</td>
      <td>-0.014674</td>
      <td>0.014674</td>
      <td>0.188107</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007726</td>
      <td>-0.007726</td>
      <td>0.007726</td>
      <td>0.180381</td>
    </tr>
    <tr>
      <th>2111</th>
      <td>topic 185</td>
      <td>6.582224e-02</td>
      <td>-0.007623</td>
      <td>0.007623</td>
      <td>0.007623</td>
      <td>0.188004</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.588972e-151</td>
      <td>0.006527</td>
      <td>-0.006527</td>
      <td>0.006527</td>
      <td>0.181477</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006307</td>
      <td>-0.006307</td>
      <td>0.006307</td>
      <td>0.175170</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.004664</td>
      <td>-0.004664</td>
      <td>0.004664</td>
      <td>0.170506</td>
    </tr>
    <tr>
      <th>501</th>
      <td>film</td>
      <td>5.773503e-01</td>
      <td>-0.004108</td>
      <td>0.004108</td>
      <td>0.004108</td>
      <td>0.174614</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003466</td>
      <td>-0.003466</td>
      <td>0.003466</td>
      <td>0.171148</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.003368</td>
      <td>-0.003368</td>
      <td>0.003368</td>
      <td>0.167780</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003347</td>
      <td>0.003347</td>
      <td>0.003347</td>
      <td>0.171128</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.887144e-219</td>
      <td>-0.002981</td>
      <td>0.002981</td>
      <td>0.002981</td>
      <td>0.174109</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002845</td>
      <td>-0.002845</td>
      <td>0.002845</td>
      <td>0.171264</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002321</td>
      <td>0.002321</td>
      <td>0.002321</td>
      <td>0.173585</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002309</td>
      <td>0.002309</td>
      <td>0.002309</td>
      <td>0.175894</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002218</td>
      <td>-0.002218</td>
      <td>0.002218</td>
      <td>0.173676</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002153</td>
      <td>-0.002153</td>
      <td>0.002153</td>
      <td>0.171524</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002084</td>
      <td>0.002084</td>
      <td>0.002084</td>
      <td>0.173607</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002059</td>
      <td>0.002059</td>
      <td>0.002059</td>
      <td>0.175666</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>0.002040</td>
      <td>-0.002040</td>
      <td>0.002040</td>
      <td>0.173626</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.001968</td>
      <td>-0.001968</td>
      <td>0.001968</td>
      <td>0.171659</td>
    </tr>
    <tr>
      <th>425</th>
      <td>easily</td>
      <td>5.773503e-01</td>
      <td>0.001894</td>
      <td>-0.001894</td>
      <td>0.001894</td>
      <td>0.169765</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>9.447098e-143</td>
      <td>0.001874</td>
      <td>-0.001874</td>
      <td>0.001874</td>
      <td>0.167891</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.001831</td>
      <td>-0.001831</td>
      <td>0.001831</td>
      <td>0.166060</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.001796</td>
      <td>0.001796</td>
      <td>0.001796</td>
      <td>0.167856</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 465
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The characters are interesting, even if a bit predictable.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.4225 0.5775]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000</td>
      <td>-0.162013</td>
      <td>0.162013</td>
      <td>0.162013</td>
      <td>0.661523</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.278000</td>
      <td>0.073995</td>
      <td>-0.073995</td>
      <td>0.073995</td>
      <td>0.587528</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.401900</td>
      <td>-0.032189</td>
      <td>0.032189</td>
      <td>0.032189</td>
      <td>0.619717</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025081</td>
      <td>0.025081</td>
      <td>0.025081</td>
      <td>0.644799</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.150000</td>
      <td>0.023725</td>
      <td>-0.023725</td>
      <td>0.023725</td>
      <td>0.621074</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.021327</td>
      <td>0.021327</td>
      <td>0.021327</td>
      <td>0.642401</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000</td>
      <td>0.019913</td>
      <td>-0.019913</td>
      <td>0.019913</td>
      <td>0.622488</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>0.209874</td>
      <td>0.014396</td>
      <td>-0.014396</td>
      <td>0.014396</td>
      <td>0.608092</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.012275</td>
      <td>-0.012275</td>
      <td>0.012275</td>
      <td>0.595817</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009026</td>
      <td>-0.009026</td>
      <td>0.009026</td>
      <td>0.586792</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007754</td>
      <td>-0.007754</td>
      <td>0.007754</td>
      <td>0.579038</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006693</td>
      <td>-0.006693</td>
      <td>0.006693</td>
      <td>0.572345</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000</td>
      <td>0.005933</td>
      <td>-0.005933</td>
      <td>0.005933</td>
      <td>0.566412</td>
    </tr>
    <tr>
      <th>718</th>
      <td>if</td>
      <td>0.353553</td>
      <td>0.005268</td>
      <td>-0.005268</td>
      <td>0.005268</td>
      <td>0.561144</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.005118</td>
      <td>-0.005118</td>
      <td>0.005118</td>
      <td>0.556026</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.004889</td>
      <td>-0.004889</td>
      <td>0.004889</td>
      <td>0.551138</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000</td>
      <td>-0.004368</td>
      <td>0.004368</td>
      <td>0.004368</td>
      <td>0.555506</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>0.000000</td>
      <td>-0.004344</td>
      <td>0.004344</td>
      <td>0.004344</td>
      <td>0.559849</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000</td>
      <td>0.004132</td>
      <td>-0.004132</td>
      <td>0.004132</td>
      <td>0.555718</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000</td>
      <td>-0.003639</td>
      <td>0.003639</td>
      <td>0.003639</td>
      <td>0.559357</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003556</td>
      <td>0.003556</td>
      <td>0.003556</td>
      <td>0.562913</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000</td>
      <td>-0.003205</td>
      <td>0.003205</td>
      <td>0.003205</td>
      <td>0.566118</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>0.003155</td>
      <td>-0.003155</td>
      <td>0.003155</td>
      <td>0.562963</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000</td>
      <td>0.003126</td>
      <td>-0.003126</td>
      <td>0.003126</td>
      <td>0.559837</td>
    </tr>
    <tr>
      <th>2022</th>
      <td>topic 96</td>
      <td>0.266338</td>
      <td>0.003096</td>
      <td>-0.003096</td>
      <td>0.003096</td>
      <td>0.556741</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000</td>
      <td>-0.002860</td>
      <td>0.002860</td>
      <td>0.002860</td>
      <td>0.559601</td>
    </tr>
    <tr>
      <th>1209</th>
      <td>predictable</td>
      <td>0.353553</td>
      <td>0.002858</td>
      <td>-0.002858</td>
      <td>0.002858</td>
      <td>0.556743</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.002856</td>
      <td>0.002856</td>
      <td>0.002856</td>
      <td>0.559599</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000</td>
      <td>-0.002852</td>
      <td>0.002852</td>
      <td>0.002852</td>
      <td>0.562451</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002849</td>
      <td>0.002849</td>
      <td>0.002849</td>
      <td>0.565300</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 466
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Highly recommended for all ages, although the younger set will probably not appreciate some of the more subtle references, they will certainly appreciate one galley scene in particular!  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.56 0.44]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>6.000000e+00</td>
      <td>-0.155107</td>
      <td>0.155107</td>
      <td>0.155107</td>
      <td>0.654617</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.350000e-01</td>
      <td>0.061390</td>
      <td>-0.061390</td>
      <td>0.061390</td>
      <td>0.593227</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.039148</td>
      <td>-0.039148</td>
      <td>0.039148</td>
      <td>0.554079</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-8.110000e-02</td>
      <td>0.032417</td>
      <td>-0.032417</td>
      <td>0.032417</td>
      <td>0.521662</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.248810e-01</td>
      <td>0.019758</td>
      <td>-0.019758</td>
      <td>0.019758</td>
      <td>0.501904</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.800000e+01</td>
      <td>0.012254</td>
      <td>-0.012254</td>
      <td>0.012254</td>
      <td>0.489650</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.010381</td>
      <td>0.010381</td>
      <td>0.010381</td>
      <td>0.500032</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007162</td>
      <td>-0.007162</td>
      <td>0.007162</td>
      <td>0.492870</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006911</td>
      <td>-0.006911</td>
      <td>0.006911</td>
      <td>0.485959</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006619</td>
      <td>-0.006619</td>
      <td>0.006619</td>
      <td>0.479340</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.005746</td>
      <td>-0.005746</td>
      <td>0.005746</td>
      <td>0.473593</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.004642</td>
      <td>-0.004642</td>
      <td>0.004642</td>
      <td>0.468951</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.870000e+02</td>
      <td>0.004641</td>
      <td>-0.004641</td>
      <td>0.004641</td>
      <td>0.464309</td>
    </tr>
    <tr>
      <th>1846</th>
      <td>will</td>
      <td>4.264014e-01</td>
      <td>0.004354</td>
      <td>-0.004354</td>
      <td>0.004354</td>
      <td>0.459956</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>2.132007e-01</td>
      <td>-0.004307</td>
      <td>0.004307</td>
      <td>0.004307</td>
      <td>0.464263</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004212</td>
      <td>-0.004212</td>
      <td>0.004212</td>
      <td>0.460051</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.320703e-41</td>
      <td>0.004070</td>
      <td>-0.004070</td>
      <td>0.004070</td>
      <td>0.455981</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003562</td>
      <td>0.003562</td>
      <td>0.003562</td>
      <td>0.459543</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>2.929620e-03</td>
      <td>0.003456</td>
      <td>-0.003456</td>
      <td>0.003456</td>
      <td>0.456087</td>
    </tr>
    <tr>
      <th>2000</th>
      <td>topic 74</td>
      <td>2.000873e-01</td>
      <td>-0.003332</td>
      <td>0.003332</td>
      <td>0.003332</td>
      <td>0.459419</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003326</td>
      <td>0.003326</td>
      <td>0.003326</td>
      <td>0.462745</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003207</td>
      <td>0.003207</td>
      <td>0.003207</td>
      <td>0.465952</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002753</td>
      <td>0.002753</td>
      <td>0.002753</td>
      <td>0.468705</td>
    </tr>
    <tr>
      <th>1335</th>
      <td>set</td>
      <td>2.132007e-01</td>
      <td>-0.002607</td>
      <td>0.002607</td>
      <td>0.002607</td>
      <td>0.471311</td>
    </tr>
    <tr>
      <th>526</th>
      <td>for</td>
      <td>2.132007e-01</td>
      <td>-0.002595</td>
      <td>0.002595</td>
      <td>0.002595</td>
      <td>0.473906</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002526</td>
      <td>0.002526</td>
      <td>0.002526</td>
      <td>0.476433</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.002517</td>
      <td>0.478950</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002514</td>
      <td>0.002514</td>
      <td>0.002514</td>
      <td>0.481463</td>
    </tr>
    <tr>
      <th>130</th>
      <td>aren</td>
      <td>0.000000e+00</td>
      <td>-0.002479</td>
      <td>0.002479</td>
      <td>0.002479</td>
      <td>0.483942</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.531207e-302</td>
      <td>-0.002449</td>
      <td>0.002449</td>
      <td>0.002449</td>
      <td>0.486391</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 490
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;The only consistent thread holding the series together were the amazing performances of Leni Parker and Anita LaSelva as the two Taelons in quiet idealogical conflict.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3825 0.6175]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.163971</td>
      <td>0.163971</td>
      <td>0.163971</td>
      <td>0.663481</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.260000e-01</td>
      <td>0.079248</td>
      <td>-0.079248</td>
      <td>0.079248</td>
      <td>0.584232</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025493</td>
      <td>0.025493</td>
      <td>0.025493</td>
      <td>0.609725</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.612000e-01</td>
      <td>-0.022904</td>
      <td>0.022904</td>
      <td>0.022904</td>
      <td>0.632629</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020900</td>
      <td>0.020900</td>
      <td>0.020900</td>
      <td>0.653529</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>2.216347e-01</td>
      <td>-0.020690</td>
      <td>0.020690</td>
      <td>0.020690</td>
      <td>0.674219</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>7.000000e+00</td>
      <td>0.020236</td>
      <td>-0.020236</td>
      <td>0.020236</td>
      <td>0.653982</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.125000e-01</td>
      <td>0.018289</td>
      <td>-0.018289</td>
      <td>0.018289</td>
      <td>0.635693</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.600000e+01</td>
      <td>0.014309</td>
      <td>-0.014309</td>
      <td>0.014309</td>
      <td>0.621384</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008828</td>
      <td>-0.008828</td>
      <td>0.008828</td>
      <td>0.612557</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>4.196788e-248</td>
      <td>0.007871</td>
      <td>-0.007871</td>
      <td>0.007871</td>
      <td>0.604685</td>
    </tr>
    <tr>
      <th>2088</th>
      <td>topic 162</td>
      <td>6.230437e-02</td>
      <td>-0.006494</td>
      <td>0.006494</td>
      <td>0.006494</td>
      <td>0.611179</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006350</td>
      <td>-0.006350</td>
      <td>0.006350</td>
      <td>0.604829</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005107</td>
      <td>-0.005107</td>
      <td>0.005107</td>
      <td>0.599721</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004940</td>
      <td>-0.004940</td>
      <td>0.004940</td>
      <td>0.594781</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.690000e+02</td>
      <td>-0.004173</td>
      <td>0.004173</td>
      <td>0.004173</td>
      <td>0.598955</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003968</td>
      <td>-0.003968</td>
      <td>0.003968</td>
      <td>0.594986</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003402</td>
      <td>0.003402</td>
      <td>0.003402</td>
      <td>0.598388</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003289</td>
      <td>-0.003289</td>
      <td>0.003289</td>
      <td>0.595099</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003208</td>
      <td>0.003208</td>
      <td>0.003208</td>
      <td>0.598307</td>
    </tr>
    <tr>
      <th>2042</th>
      <td>topic 116</td>
      <td>1.087026e-03</td>
      <td>-0.003184</td>
      <td>0.003184</td>
      <td>0.003184</td>
      <td>0.601491</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002919</td>
      <td>0.002919</td>
      <td>0.002919</td>
      <td>0.604410</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.002714</td>
      <td>0.002714</td>
      <td>0.002714</td>
      <td>0.607124</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.002689</td>
      <td>-0.002689</td>
      <td>0.002689</td>
      <td>0.604436</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002648</td>
      <td>0.002648</td>
      <td>0.002648</td>
      <td>0.607083</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002643</td>
      <td>0.002643</td>
      <td>0.002643</td>
      <td>0.609726</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002636</td>
      <td>-0.002636</td>
      <td>0.002636</td>
      <td>0.607090</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002560</td>
      <td>-0.002560</td>
      <td>0.002560</td>
      <td>0.604530</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.607030</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002404</td>
      <td>0.002404</td>
      <td>0.002404</td>
      <td>0.609435</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 496
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I felt asleep the first time I watched it, so I can recommend it for insomniacs.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3925 0.6075]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.170774</td>
      <td>0.170774</td>
      <td>0.170774</td>
      <td>0.670283</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.880000e-01</td>
      <td>0.075106</td>
      <td>-0.075106</td>
      <td>0.075106</td>
      <td>0.595177</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>4.173000e-01</td>
      <td>-0.026154</td>
      <td>0.026154</td>
      <td>0.026154</td>
      <td>0.621331</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025029</td>
      <td>0.025029</td>
      <td>0.025029</td>
      <td>0.646359</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021211</td>
      <td>0.021211</td>
      <td>0.021211</td>
      <td>0.667571</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.600000e+01</td>
      <td>0.014600</td>
      <td>-0.014600</td>
      <td>0.014600</td>
      <td>0.652971</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.500000e-01</td>
      <td>0.012252</td>
      <td>-0.012252</td>
      <td>0.012252</td>
      <td>0.640718</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.010491</td>
      <td>-0.010491</td>
      <td>0.010491</td>
      <td>0.630227</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009040</td>
      <td>-0.009040</td>
      <td>0.009040</td>
      <td>0.621188</td>
    </tr>
    <tr>
      <th>1941</th>
      <td>topic 15</td>
      <td>1.732467e-01</td>
      <td>0.008321</td>
      <td>-0.008321</td>
      <td>0.008321</td>
      <td>0.612867</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>3.159675e-01</td>
      <td>0.008110</td>
      <td>-0.008110</td>
      <td>0.008110</td>
      <td>0.604757</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.200000e+01</td>
      <td>0.007828</td>
      <td>-0.007828</td>
      <td>0.007828</td>
      <td>0.596929</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.577820e-77</td>
      <td>0.007706</td>
      <td>-0.007706</td>
      <td>0.007706</td>
      <td>0.589223</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006746</td>
      <td>-0.006746</td>
      <td>0.006746</td>
      <td>0.582477</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.005970</td>
      <td>-0.005970</td>
      <td>0.005970</td>
      <td>0.576507</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005779</td>
      <td>-0.005779</td>
      <td>0.005779</td>
      <td>0.570728</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>5.152904e-215</td>
      <td>0.005140</td>
      <td>-0.005140</td>
      <td>0.005140</td>
      <td>0.565588</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004483</td>
      <td>0.004483</td>
      <td>0.004483</td>
      <td>0.570071</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.004329</td>
      <td>-0.004329</td>
      <td>0.004329</td>
      <td>0.565742</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003886</td>
      <td>0.003886</td>
      <td>0.003886</td>
      <td>0.569628</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003769</td>
      <td>-0.003769</td>
      <td>0.003769</td>
      <td>0.565859</td>
    </tr>
    <tr>
      <th>1934</th>
      <td>topic 8</td>
      <td>1.231594e-01</td>
      <td>-0.003760</td>
      <td>0.003760</td>
      <td>0.003760</td>
      <td>0.569619</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003608</td>
      <td>0.003608</td>
      <td>0.003608</td>
      <td>0.573227</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.003144</td>
      <td>0.003144</td>
      <td>0.003144</td>
      <td>0.576372</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>0.000000e+00</td>
      <td>-0.003107</td>
      <td>0.003107</td>
      <td>0.003107</td>
      <td>0.579478</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>0.002925</td>
      <td>-0.002925</td>
      <td>0.002925</td>
      <td>0.576553</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002876</td>
      <td>0.002876</td>
      <td>0.002876</td>
      <td>0.579429</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>7.372646e-172</td>
      <td>-0.002856</td>
      <td>0.002856</td>
      <td>0.002856</td>
      <td>0.582286</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002834</td>
      <td>0.002834</td>
      <td>0.002834</td>
      <td>0.585120</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002811</td>
      <td>0.002811</td>
      <td>0.002811</td>
      <td>0.587931</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 499
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Director Neil LaBute uses brutal violence to seperate dreams from reality, and along with the touching drama, and hilarious comedy, you can never tell what is going to happen next.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9075 0.0925]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.183423</td>
      <td>-0.183423</td>
      <td>0.183423</td>
      <td>0.316087</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-3.182000e-01</td>
      <td>0.064822</td>
      <td>-0.064822</td>
      <td>0.064822</td>
      <td>0.251265</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.920000e-01</td>
      <td>0.059948</td>
      <td>-0.059948</td>
      <td>0.059948</td>
      <td>0.191317</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.125000e-02</td>
      <td>0.023311</td>
      <td>-0.023311</td>
      <td>0.023311</td>
      <td>0.168005</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.021873</td>
      <td>0.021873</td>
      <td>0.021873</td>
      <td>0.189879</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.015572</td>
      <td>0.015572</td>
      <td>0.015572</td>
      <td>0.205451</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.820000e+02</td>
      <td>0.013851</td>
      <td>-0.013851</td>
      <td>0.013851</td>
      <td>0.191600</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.000000e+01</td>
      <td>0.011726</td>
      <td>-0.011726</td>
      <td>0.011726</td>
      <td>0.179874</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009032</td>
      <td>-0.009032</td>
      <td>0.009032</td>
      <td>0.170842</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>2.009113e-06</td>
      <td>0.006400</td>
      <td>-0.006400</td>
      <td>0.006400</td>
      <td>0.164441</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005525</td>
      <td>-0.005525</td>
      <td>0.005525</td>
      <td>0.158916</td>
    </tr>
    <tr>
      <th>1981</th>
      <td>topic 55</td>
      <td>1.695708e-01</td>
      <td>-0.004260</td>
      <td>0.004260</td>
      <td>0.004260</td>
      <td>0.163176</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.348038e-286</td>
      <td>0.004006</td>
      <td>-0.004006</td>
      <td>0.004006</td>
      <td>0.159170</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>-0.003800</td>
      <td>0.003800</td>
      <td>0.003800</td>
      <td>0.162970</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>2.000000e-01</td>
      <td>-0.003655</td>
      <td>0.003655</td>
      <td>0.003655</td>
      <td>0.166625</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003352</td>
      <td>-0.003352</td>
      <td>0.003352</td>
      <td>0.163273</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.083122e-269</td>
      <td>-0.003248</td>
      <td>0.003248</td>
      <td>0.003248</td>
      <td>0.166522</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003146</td>
      <td>0.003146</td>
      <td>0.003146</td>
      <td>0.169668</td>
    </tr>
    <tr>
      <th>2073</th>
      <td>topic 147</td>
      <td>1.377145e-02</td>
      <td>-0.002692</td>
      <td>0.002692</td>
      <td>0.002692</td>
      <td>0.172360</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002536</td>
      <td>0.002536</td>
      <td>0.002536</td>
      <td>0.174896</td>
    </tr>
    <tr>
      <th>347</th>
      <td>could not</td>
      <td>0.000000e+00</td>
      <td>0.002493</td>
      <td>-0.002493</td>
      <td>0.002493</td>
      <td>0.172403</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.000000e-01</td>
      <td>0.002482</td>
      <td>-0.002482</td>
      <td>0.002482</td>
      <td>0.169921</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002318</td>
      <td>-0.002318</td>
      <td>0.002318</td>
      <td>0.167603</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002292</td>
      <td>0.002292</td>
      <td>0.002292</td>
      <td>0.169895</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002123</td>
      <td>0.002123</td>
      <td>0.002123</td>
      <td>0.172017</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002048</td>
      <td>0.002048</td>
      <td>0.002048</td>
      <td>0.174065</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000e+00</td>
      <td>0.002001</td>
      <td>-0.002001</td>
      <td>0.002001</td>
      <td>0.172065</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.001989</td>
      <td>-0.001989</td>
      <td>0.001989</td>
      <td>0.170076</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.001932</td>
      <td>0.001932</td>
      <td>0.001932</td>
      <td>0.172008</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.001900</td>
      <td>0.001900</td>
      <td>0.001900</td>
      <td>0.173908</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 515
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;I didn&#39;t realize how wonderful the short really is until the last two scenes.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.5375 0.4625]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>4.000000e+00</td>
      <td>-0.183628</td>
      <td>0.183628</td>
      <td>0.183628</td>
      <td>0.683138</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-4.585000e-01</td>
      <td>0.111320</td>
      <td>-0.111320</td>
      <td>0.111320</td>
      <td>0.571818</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.081379</td>
      <td>-0.081379</td>
      <td>0.081379</td>
      <td>0.490439</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.023552</td>
      <td>0.023552</td>
      <td>0.023552</td>
      <td>0.513991</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.400000e+01</td>
      <td>0.012543</td>
      <td>-0.012543</td>
      <td>0.012543</td>
      <td>0.501448</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007872</td>
      <td>-0.007872</td>
      <td>0.007872</td>
      <td>0.493576</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.357615e-287</td>
      <td>0.006729</td>
      <td>-0.006729</td>
      <td>0.006729</td>
      <td>0.486847</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006458</td>
      <td>-0.006458</td>
      <td>0.006458</td>
      <td>0.480389</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.000000e-01</td>
      <td>-0.005845</td>
      <td>0.005845</td>
      <td>0.005845</td>
      <td>0.486234</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005026</td>
      <td>-0.005026</td>
      <td>0.005026</td>
      <td>0.481208</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.654357e-165</td>
      <td>0.004704</td>
      <td>-0.004704</td>
      <td>0.004704</td>
      <td>0.476504</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004048</td>
      <td>0.004048</td>
      <td>0.004048</td>
      <td>0.480552</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004002</td>
      <td>-0.004002</td>
      <td>0.004002</td>
      <td>0.476550</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>2.672612e-01</td>
      <td>0.003916</td>
      <td>-0.003916</td>
      <td>0.003916</td>
      <td>0.472633</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>8.067948e-14</td>
      <td>0.003704</td>
      <td>-0.003704</td>
      <td>0.003704</td>
      <td>0.468929</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003499</td>
      <td>0.003499</td>
      <td>0.003499</td>
      <td>0.472428</td>
    </tr>
    <tr>
      <th>915</th>
      <td>low</td>
      <td>0.000000e+00</td>
      <td>-0.003127</td>
      <td>0.003127</td>
      <td>0.003127</td>
      <td>0.475555</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.003107</td>
      <td>0.003107</td>
      <td>0.003107</td>
      <td>0.478662</td>
    </tr>
    <tr>
      <th>2100</th>
      <td>topic 174</td>
      <td>1.400834e-01</td>
      <td>-0.002836</td>
      <td>0.002836</td>
      <td>0.002836</td>
      <td>0.481498</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002704</td>
      <td>0.002704</td>
      <td>0.002704</td>
      <td>0.484202</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>0.002701</td>
      <td>-0.002701</td>
      <td>0.002701</td>
      <td>0.481501</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>2.672612e-01</td>
      <td>0.002636</td>
      <td>-0.002636</td>
      <td>0.002636</td>
      <td>0.478865</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002612</td>
      <td>-0.002612</td>
      <td>0.002612</td>
      <td>0.476253</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.118038e-132</td>
      <td>-0.002559</td>
      <td>0.002559</td>
      <td>0.002559</td>
      <td>0.478812</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002537</td>
      <td>0.002537</td>
      <td>0.002537</td>
      <td>0.481349</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.002517</td>
      <td>0.483866</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002514</td>
      <td>0.002514</td>
      <td>0.002514</td>
      <td>0.486380</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002501</td>
      <td>0.002501</td>
      <td>0.002501</td>
      <td>0.488881</td>
    </tr>
    <tr>
      <th>543</th>
      <td>forced</td>
      <td>0.000000e+00</td>
      <td>-0.002500</td>
      <td>0.002500</td>
      <td>0.002500</td>
      <td>0.491381</td>
    </tr>
    <tr>
      <th>130</th>
      <td>aren</td>
      <td>0.000000e+00</td>
      <td>-0.002496</td>
      <td>0.002496</td>
      <td>0.002496</td>
      <td>0.493877</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 521
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.565 0.435]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.134901</td>
      <td>0.134901</td>
      <td>0.134901</td>
      <td>0.634411</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.350000e-01</td>
      <td>0.067174</td>
      <td>-0.067174</td>
      <td>0.067174</td>
      <td>0.567236</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.040959</td>
      <td>-0.040959</td>
      <td>0.040959</td>
      <td>0.526277</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.250000e-01</td>
      <td>0.023907</td>
      <td>-0.023907</td>
      <td>0.023907</td>
      <td>0.502370</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>3.612000e-01</td>
      <td>-0.016357</td>
      <td>0.016357</td>
      <td>0.016357</td>
      <td>0.518727</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.800000e+01</td>
      <td>0.012861</td>
      <td>-0.012861</td>
      <td>0.012861</td>
      <td>0.505866</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>4.364358e-01</td>
      <td>0.007880</td>
      <td>-0.007880</td>
      <td>0.007880</td>
      <td>0.497986</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.378452e-155</td>
      <td>0.007633</td>
      <td>-0.007633</td>
      <td>0.007633</td>
      <td>0.490352</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007555</td>
      <td>-0.007555</td>
      <td>0.007555</td>
      <td>0.482797</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000e+00</td>
      <td>0.006324</td>
      <td>-0.006324</td>
      <td>0.006324</td>
      <td>0.476473</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005424</td>
      <td>-0.005424</td>
      <td>0.005424</td>
      <td>0.471049</td>
    </tr>
    <tr>
      <th>1967</th>
      <td>topic 41</td>
      <td>7.485162e-03</td>
      <td>-0.005136</td>
      <td>0.005136</td>
      <td>0.005136</td>
      <td>0.476186</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004239</td>
      <td>-0.004239</td>
      <td>0.004239</td>
      <td>0.471947</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003916</td>
      <td>-0.003916</td>
      <td>0.003916</td>
      <td>0.468030</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>2.182179e-01</td>
      <td>0.003817</td>
      <td>-0.003817</td>
      <td>0.003817</td>
      <td>0.464213</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003344</td>
      <td>0.003344</td>
      <td>0.003344</td>
      <td>0.467556</td>
    </tr>
    <tr>
      <th>2058</th>
      <td>topic 132</td>
      <td>3.071386e-01</td>
      <td>-0.003288</td>
      <td>0.003288</td>
      <td>0.003288</td>
      <td>0.470844</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003263</td>
      <td>0.003263</td>
      <td>0.003263</td>
      <td>0.474107</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002983</td>
      <td>-0.002983</td>
      <td>0.002983</td>
      <td>0.471123</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.110000e+02</td>
      <td>0.002971</td>
      <td>-0.002971</td>
      <td>0.002971</td>
      <td>0.468152</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002943</td>
      <td>0.002943</td>
      <td>0.002943</td>
      <td>0.471096</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002870</td>
      <td>-0.002870</td>
      <td>0.002870</td>
      <td>0.468225</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>6.574117e-150</td>
      <td>0.002827</td>
      <td>-0.002827</td>
      <td>0.002827</td>
      <td>0.465399</td>
    </tr>
    <tr>
      <th>501</th>
      <td>film</td>
      <td>2.182179e-01</td>
      <td>-0.002754</td>
      <td>0.002754</td>
      <td>0.002754</td>
      <td>0.468153</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002724</td>
      <td>-0.002724</td>
      <td>0.002724</td>
      <td>0.465429</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002610</td>
      <td>-0.002610</td>
      <td>0.002610</td>
      <td>0.462819</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002580</td>
      <td>-0.002580</td>
      <td>0.002580</td>
      <td>0.460239</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002534</td>
      <td>0.002534</td>
      <td>0.002534</td>
      <td>0.462773</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002514</td>
      <td>0.002514</td>
      <td>0.002514</td>
      <td>0.465287</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002458</td>
      <td>-0.002458</td>
      <td>0.002458</td>
      <td>0.462829</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 522
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;I&#39;ve seen soap operas more intelligent than this movie.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.285 0.715]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.145272</td>
      <td>0.145272</td>
      <td>0.145272</td>
      <td>0.644781</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.920000e-01</td>
      <td>0.076107</td>
      <td>-0.076107</td>
      <td>0.076107</td>
      <td>0.568674</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>6.500000e-01</td>
      <td>-0.043394</td>
      <td>0.043394</td>
      <td>0.043394</td>
      <td>0.612069</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.095000e-01</td>
      <td>-0.037847</td>
      <td>0.037847</td>
      <td>0.037847</td>
      <td>0.649916</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>9.000000e+00</td>
      <td>0.026235</td>
      <td>-0.026235</td>
      <td>0.026235</td>
      <td>0.623681</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024335</td>
      <td>0.024335</td>
      <td>0.024335</td>
      <td>0.648016</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.021136</td>
      <td>0.021136</td>
      <td>0.021136</td>
      <td>0.669152</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009481</td>
      <td>-0.009481</td>
      <td>0.009481</td>
      <td>0.659671</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009250</td>
      <td>-0.009250</td>
      <td>0.009250</td>
      <td>0.650421</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.008042</td>
      <td>-0.008042</td>
      <td>0.008042</td>
      <td>0.642380</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.007518</td>
      <td>-0.007518</td>
      <td>0.007518</td>
      <td>0.634862</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.007050</td>
      <td>-0.007050</td>
      <td>0.007050</td>
      <td>0.627811</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.869085e-193</td>
      <td>0.005596</td>
      <td>-0.005596</td>
      <td>0.005596</td>
      <td>0.622216</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.004953</td>
      <td>-0.004953</td>
      <td>0.004953</td>
      <td>0.617263</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>4.740403e-02</td>
      <td>0.004505</td>
      <td>-0.004505</td>
      <td>0.004505</td>
      <td>0.612758</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.700000e+01</td>
      <td>-0.004306</td>
      <td>0.004306</td>
      <td>0.004306</td>
      <td>0.617064</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004305</td>
      <td>0.004305</td>
      <td>0.004305</td>
      <td>0.621369</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003594</td>
      <td>0.003594</td>
      <td>0.003594</td>
      <td>0.624963</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003278</td>
      <td>-0.003278</td>
      <td>0.003278</td>
      <td>0.621686</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003067</td>
      <td>0.003067</td>
      <td>0.003067</td>
      <td>0.624753</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002990</td>
      <td>-0.002990</td>
      <td>0.002990</td>
      <td>0.621763</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002935</td>
      <td>0.002935</td>
      <td>0.002935</td>
      <td>0.624698</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002932</td>
      <td>-0.002932</td>
      <td>0.002932</td>
      <td>0.621765</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002898</td>
      <td>0.002898</td>
      <td>0.002898</td>
      <td>0.624664</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.227743e-83</td>
      <td>-0.002882</td>
      <td>0.002882</td>
      <td>0.002882</td>
      <td>0.627546</td>
    </tr>
    <tr>
      <th>1985</th>
      <td>topic 59</td>
      <td>6.476665e-05</td>
      <td>0.002766</td>
      <td>-0.002766</td>
      <td>0.002766</td>
      <td>0.624779</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002573</td>
      <td>0.002573</td>
      <td>0.002573</td>
      <td>0.627352</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002482</td>
      <td>0.002482</td>
      <td>0.002482</td>
      <td>0.629835</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002473</td>
      <td>0.002473</td>
      <td>0.002473</td>
      <td>0.632308</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002430</td>
      <td>0.002430</td>
      <td>0.002430</td>
      <td>0.634738</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 527
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It was a long time that i didn&#39;t see a so charismatic actor on screen.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.79 0.21]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085060</td>
      <td>-0.085060</td>
      <td>0.085060</td>
      <td>0.414450</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025775</td>
      <td>0.025775</td>
      <td>0.025775</td>
      <td>0.440225</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.500000e+01</td>
      <td>0.021070</td>
      <td>-0.021070</td>
      <td>0.021070</td>
      <td>0.419154</td>
    </tr>
    <tr>
      <th>1934</th>
      <td>topic 8</td>
      <td>1.008889e-01</td>
      <td>-0.014420</td>
      <td>0.014420</td>
      <td>0.014420</td>
      <td>0.433574</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.013677</td>
      <td>-0.013677</td>
      <td>0.013677</td>
      <td>0.419897</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>2.250000e-01</td>
      <td>0.012343</td>
      <td>-0.012343</td>
      <td>0.012343</td>
      <td>0.407554</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>7.200000e+01</td>
      <td>0.012025</td>
      <td>-0.012025</td>
      <td>0.012025</td>
      <td>0.395529</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009366</td>
      <td>-0.009366</td>
      <td>0.009366</td>
      <td>0.386163</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.009255</td>
      <td>-0.009255</td>
      <td>0.009255</td>
      <td>0.376907</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008141</td>
      <td>-0.008141</td>
      <td>0.008141</td>
      <td>0.368766</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.862752e-79</td>
      <td>0.007503</td>
      <td>-0.007503</td>
      <td>0.007503</td>
      <td>0.361263</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007289</td>
      <td>-0.007289</td>
      <td>0.007289</td>
      <td>0.353974</td>
    </tr>
    <tr>
      <th>1363</th>
      <td>so</td>
      <td>2.581989e-01</td>
      <td>-0.006410</td>
      <td>0.006410</td>
      <td>0.006410</td>
      <td>0.360383</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006309</td>
      <td>-0.006309</td>
      <td>0.006309</td>
      <td>0.354074</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005656</td>
      <td>0.005656</td>
      <td>0.005656</td>
      <td>0.359730</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>8.410204e-02</td>
      <td>-0.005633</td>
      <td>0.005633</td>
      <td>0.005633</td>
      <td>0.365363</td>
    </tr>
    <tr>
      <th>1089</th>
      <td>on</td>
      <td>2.581989e-01</td>
      <td>-0.005422</td>
      <td>0.005422</td>
      <td>0.005422</td>
      <td>0.370785</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.256028e-16</td>
      <td>0.004897</td>
      <td>-0.004897</td>
      <td>0.004897</td>
      <td>0.365888</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004250</td>
      <td>0.004250</td>
      <td>0.004250</td>
      <td>0.370138</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004177</td>
      <td>-0.004177</td>
      <td>0.004177</td>
      <td>0.365961</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>2.581989e-01</td>
      <td>0.003847</td>
      <td>-0.003847</td>
      <td>0.003847</td>
      <td>0.362114</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.003709</td>
      <td>-0.003709</td>
      <td>0.003709</td>
      <td>0.358405</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003459</td>
      <td>-0.003459</td>
      <td>0.003459</td>
      <td>0.354946</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003411</td>
      <td>0.003411</td>
      <td>0.003411</td>
      <td>0.358357</td>
    </tr>
    <tr>
      <th>1984</th>
      <td>topic 58</td>
      <td>5.937991e-03</td>
      <td>-0.003350</td>
      <td>0.003350</td>
      <td>0.003350</td>
      <td>0.361708</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>2.857764e-32</td>
      <td>0.003254</td>
      <td>-0.003254</td>
      <td>0.003254</td>
      <td>0.358454</td>
    </tr>
    <tr>
      <th>1452</th>
      <td>that</td>
      <td>2.581989e-01</td>
      <td>-0.003253</td>
      <td>0.003253</td>
      <td>0.003253</td>
      <td>0.361707</td>
    </tr>
    <tr>
      <th>383</th>
      <td>did</td>
      <td>2.581989e-01</td>
      <td>0.003237</td>
      <td>-0.003237</td>
      <td>0.003237</td>
      <td>0.358470</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003231</td>
      <td>-0.003231</td>
      <td>0.003231</td>
      <td>0.355240</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.092959e-20</td>
      <td>-0.003169</td>
      <td>0.003169</td>
      <td>0.003169</td>
      <td>0.358409</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 529
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;The movie is not completely perfect but &#39;Titta Di Girolamo&#39; will stay with you for a long time after the vision of the movie.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.545 0.455]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>4.000000e+00</td>
      <td>-0.156015</td>
      <td>0.156015</td>
      <td>0.156015</td>
      <td>0.655525</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>9.800000e-02</td>
      <td>0.056217</td>
      <td>-0.056217</td>
      <td>0.056217</td>
      <td>0.599308</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-2.750000e-01</td>
      <td>0.048946</td>
      <td>-0.048946</td>
      <td>0.048946</td>
      <td>0.550362</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.045610</td>
      <td>-0.045610</td>
      <td>0.045610</td>
      <td>0.504752</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>topic 71</td>
      <td>1.744832e-01</td>
      <td>-0.024001</td>
      <td>0.024001</td>
      <td>0.024001</td>
      <td>0.528753</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.400000e+01</td>
      <td>0.016943</td>
      <td>-0.016943</td>
      <td>0.016943</td>
      <td>0.511810</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>1.008000e-01</td>
      <td>0.011645</td>
      <td>-0.011645</td>
      <td>0.011645</td>
      <td>0.500164</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.924501e-01</td>
      <td>-0.008368</td>
      <td>0.008368</td>
      <td>0.008368</td>
      <td>0.508533</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.006927</td>
      <td>-0.006927</td>
      <td>0.006927</td>
      <td>0.501605</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.006915</td>
      <td>-0.006915</td>
      <td>0.006915</td>
      <td>0.494690</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.565492e-81</td>
      <td>0.006804</td>
      <td>-0.006804</td>
      <td>0.006804</td>
      <td>0.487886</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.005346</td>
      <td>0.005346</td>
      <td>0.005346</td>
      <td>0.493233</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005095</td>
      <td>-0.005095</td>
      <td>0.005095</td>
      <td>0.488138</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>0.005076</td>
      <td>-0.005076</td>
      <td>0.005076</td>
      <td>0.483062</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>6.560370e-02</td>
      <td>-0.004536</td>
      <td>0.004536</td>
      <td>0.004536</td>
      <td>0.487598</td>
    </tr>
    <tr>
      <th>1934</th>
      <td>topic 8</td>
      <td>8.090895e-02</td>
      <td>-0.004097</td>
      <td>0.004097</td>
      <td>0.004097</td>
      <td>0.491695</td>
    </tr>
    <tr>
      <th>2114</th>
      <td>topic 188</td>
      <td>1.839877e-01</td>
      <td>-0.004032</td>
      <td>0.004032</td>
      <td>0.004032</td>
      <td>0.495727</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>8.758272e-191</td>
      <td>0.003713</td>
      <td>-0.003713</td>
      <td>0.003713</td>
      <td>0.492014</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003689</td>
      <td>-0.003689</td>
      <td>0.003689</td>
      <td>0.488324</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003554</td>
      <td>0.003554</td>
      <td>0.003554</td>
      <td>0.491878</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003140</td>
      <td>0.003140</td>
      <td>0.003140</td>
      <td>0.495018</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003060</td>
      <td>0.003060</td>
      <td>0.003060</td>
      <td>0.498079</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.002834</td>
      <td>-0.002834</td>
      <td>0.002834</td>
      <td>0.495244</td>
    </tr>
    <tr>
      <th>1599</th>
      <td>this phone</td>
      <td>0.000000e+00</td>
      <td>0.002763</td>
      <td>-0.002763</td>
      <td>0.002763</td>
      <td>0.492482</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.681104e-85</td>
      <td>-0.002636</td>
      <td>0.002636</td>
      <td>0.002636</td>
      <td>0.495118</td>
    </tr>
    <tr>
      <th>972</th>
      <td>movie</td>
      <td>3.849002e-01</td>
      <td>-0.002608</td>
      <td>0.002608</td>
      <td>0.002608</td>
      <td>0.497726</td>
    </tr>
    <tr>
      <th>360</th>
      <td>day</td>
      <td>0.000000e+00</td>
      <td>0.002555</td>
      <td>-0.002555</td>
      <td>0.002555</td>
      <td>0.495171</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002524</td>
      <td>0.002524</td>
      <td>0.002524</td>
      <td>0.497695</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002517</td>
      <td>0.002517</td>
      <td>0.002517</td>
      <td>0.500213</td>
    </tr>
    <tr>
      <th>440</th>
      <td>empty</td>
      <td>0.000000e+00</td>
      <td>-0.002514</td>
      <td>0.002514</td>
      <td>0.002514</td>
      <td>0.502726</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 530
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I rate this movie 9/10.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.835 0.165]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.085642</td>
      <td>-0.085642</td>
      <td>0.085642</td>
      <td>0.413868</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>5.000000e+00</td>
      <td>0.037167</td>
      <td>-0.037167</td>
      <td>0.037167</td>
      <td>0.376701</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.032133</td>
      <td>-0.032133</td>
      <td>0.032133</td>
      <td>0.344568</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025356</td>
      <td>0.025356</td>
      <td>0.025356</td>
      <td>0.369924</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019636</td>
      <td>0.019636</td>
      <td>0.019636</td>
      <td>0.389559</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.016785</td>
      <td>-0.016785</td>
      <td>0.016785</td>
      <td>0.372774</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009970</td>
      <td>-0.009970</td>
      <td>0.009970</td>
      <td>0.362804</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>2.500000e+01</td>
      <td>0.009644</td>
      <td>-0.009644</td>
      <td>0.009644</td>
      <td>0.353160</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008960</td>
      <td>-0.008960</td>
      <td>0.008960</td>
      <td>0.344200</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.008372</td>
      <td>0.008372</td>
      <td>0.008372</td>
      <td>0.352571</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007679</td>
      <td>-0.007679</td>
      <td>0.007679</td>
      <td>0.344893</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007458</td>
      <td>-0.007458</td>
      <td>0.007458</td>
      <td>0.337435</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006539</td>
      <td>-0.006539</td>
      <td>0.006539</td>
      <td>0.330896</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005704</td>
      <td>0.005704</td>
      <td>0.005704</td>
      <td>0.336599</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.725238e-185</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.331612</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004564</td>
      <td>-0.004564</td>
      <td>0.004564</td>
      <td>0.327048</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004401</td>
      <td>0.004401</td>
      <td>0.004401</td>
      <td>0.331449</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004320</td>
      <td>-0.004320</td>
      <td>0.004320</td>
      <td>0.327129</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004090</td>
      <td>0.004090</td>
      <td>0.004090</td>
      <td>0.331219</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003970</td>
      <td>0.003970</td>
      <td>0.003970</td>
      <td>0.335189</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003894</td>
      <td>-0.003894</td>
      <td>0.003894</td>
      <td>0.331295</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003867</td>
      <td>0.003867</td>
      <td>0.003867</td>
      <td>0.335161</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003634</td>
      <td>-0.003634</td>
      <td>0.003634</td>
      <td>0.331528</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003380</td>
      <td>-0.003380</td>
      <td>0.003380</td>
      <td>0.328148</td>
    </tr>
    <tr>
      <th>1930</th>
      <td>topic 4</td>
      <td>0.000000e+00</td>
      <td>0.003358</td>
      <td>-0.003358</td>
      <td>0.003358</td>
      <td>0.324790</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>1.833923e-79</td>
      <td>-0.003329</td>
      <td>0.003329</td>
      <td>0.003329</td>
      <td>0.328120</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.003279</td>
      <td>-0.003279</td>
      <td>0.003279</td>
      <td>0.324841</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.003243</td>
      <td>-0.003243</td>
      <td>0.003243</td>
      <td>0.321598</td>
    </tr>
    <tr>
      <th>1961</th>
      <td>topic 35</td>
      <td>0.000000e+00</td>
      <td>0.003209</td>
      <td>-0.003209</td>
      <td>0.003209</td>
      <td>0.318389</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>2.028003e-05</td>
      <td>0.003164</td>
      <td>-0.003164</td>
      <td>0.003164</td>
      <td>0.315225</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 531
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;I do not know if this was Emilio Estevez&#39;s directorial debut, but the pacing, the interplay and development of the characters as well as some clever camera work surrounding the character Estevez plays all suggest a natural eye.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.465 0.535]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.125626</td>
      <td>0.125626</td>
      <td>0.125626</td>
      <td>0.625135</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>9.081000e-01</td>
      <td>-0.069363</td>
      <td>0.069363</td>
      <td>0.069363</td>
      <td>0.694499</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.790000e-01</td>
      <td>0.063601</td>
      <td>-0.063601</td>
      <td>0.063601</td>
      <td>0.630898</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.038701</td>
      <td>-0.038701</td>
      <td>0.038701</td>
      <td>0.592197</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.333333e-01</td>
      <td>0.026087</td>
      <td>-0.026087</td>
      <td>0.026087</td>
      <td>0.566109</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.800000e+01</td>
      <td>0.012614</td>
      <td>-0.012614</td>
      <td>0.012614</td>
      <td>0.553495</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.825742e-01</td>
      <td>-0.008561</td>
      <td>0.008561</td>
      <td>0.008561</td>
      <td>0.562056</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>2.891292e-01</td>
      <td>0.007972</td>
      <td>-0.007972</td>
      <td>0.007972</td>
      <td>0.554085</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.047948e-41</td>
      <td>0.007750</td>
      <td>-0.007750</td>
      <td>0.007750</td>
      <td>0.546335</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007368</td>
      <td>-0.007368</td>
      <td>0.007368</td>
      <td>0.538967</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005692</td>
      <td>-0.005692</td>
      <td>0.005692</td>
      <td>0.533275</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>1.825742e-01</td>
      <td>0.005353</td>
      <td>-0.005353</td>
      <td>0.005353</td>
      <td>0.527922</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>6.162166e-232</td>
      <td>0.004265</td>
      <td>-0.004265</td>
      <td>0.004265</td>
      <td>0.523657</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>1.825742e-01</td>
      <td>-0.003765</td>
      <td>0.003765</td>
      <td>0.003765</td>
      <td>0.527422</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>0.003540</td>
      <td>-0.003540</td>
      <td>0.003540</td>
      <td>0.523882</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>-0.003214</td>
      <td>0.003214</td>
      <td>0.003214</td>
      <td>0.527097</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>1.825742e-01</td>
      <td>0.003051</td>
      <td>-0.003051</td>
      <td>0.003051</td>
      <td>0.524046</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.002860</td>
      <td>0.002860</td>
      <td>0.002860</td>
      <td>0.526905</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002790</td>
      <td>-0.002790</td>
      <td>0.002790</td>
      <td>0.524115</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>7.470576e-154</td>
      <td>-0.002595</td>
      <td>0.002595</td>
      <td>0.002595</td>
      <td>0.526710</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>-0.002513</td>
      <td>0.002513</td>
      <td>0.002513</td>
      <td>0.529223</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.002487</td>
      <td>-0.002487</td>
      <td>0.002487</td>
      <td>0.526736</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002461</td>
      <td>-0.002461</td>
      <td>0.002461</td>
      <td>0.524275</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002425</td>
      <td>0.002425</td>
      <td>0.002425</td>
      <td>0.526700</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002327</td>
      <td>0.002327</td>
      <td>0.002327</td>
      <td>0.529026</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002271</td>
      <td>-0.002271</td>
      <td>0.002271</td>
      <td>0.526756</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002138</td>
      <td>0.002138</td>
      <td>0.002138</td>
      <td>0.528894</td>
    </tr>
    <tr>
      <th>1925</th>
      <td>zero star</td>
      <td>0.000000e+00</td>
      <td>-0.002068</td>
      <td>0.002068</td>
      <td>0.002068</td>
      <td>0.530961</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002064</td>
      <td>0.002064</td>
      <td>0.002064</td>
      <td>0.533025</td>
    </tr>
    <tr>
      <th>1953</th>
      <td>topic 27</td>
      <td>1.447664e-250</td>
      <td>-0.002041</td>
      <td>0.002041</td>
      <td>0.002041</td>
      <td>0.535066</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 543
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Go rent it.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8625 0.1375]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.085028</td>
      <td>-0.085028</td>
      <td>0.085028</td>
      <td>0.414482</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.000000</td>
      <td>0.044340</td>
      <td>-0.044340</td>
      <td>0.044340</td>
      <td>0.370142</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000</td>
      <td>0.029093</td>
      <td>-0.029093</td>
      <td>0.029093</td>
      <td>0.341049</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>13.000000</td>
      <td>0.025628</td>
      <td>-0.025628</td>
      <td>0.025628</td>
      <td>0.315421</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.025506</td>
      <td>0.025506</td>
      <td>0.025506</td>
      <td>0.340927</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.019646</td>
      <td>0.019646</td>
      <td>0.019646</td>
      <td>0.360573</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.009807</td>
      <td>-0.009807</td>
      <td>0.009807</td>
      <td>0.350766</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.008541</td>
      <td>-0.008541</td>
      <td>0.008541</td>
      <td>0.342225</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007530</td>
      <td>-0.007530</td>
      <td>0.007530</td>
      <td>0.334695</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000</td>
      <td>0.006900</td>
      <td>-0.006900</td>
      <td>0.006900</td>
      <td>0.327796</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006495</td>
      <td>-0.006495</td>
      <td>0.006495</td>
      <td>0.321301</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>-0.006211</td>
      <td>0.006211</td>
      <td>0.006211</td>
      <td>0.327511</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.005420</td>
      <td>0.005420</td>
      <td>0.005420</td>
      <td>0.332931</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000</td>
      <td>0.005362</td>
      <td>-0.005362</td>
      <td>0.005362</td>
      <td>0.327569</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004987</td>
      <td>-0.004987</td>
      <td>0.004987</td>
      <td>0.322582</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000</td>
      <td>0.004675</td>
      <td>-0.004675</td>
      <td>0.004675</td>
      <td>0.317908</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000</td>
      <td>0.004557</td>
      <td>-0.004557</td>
      <td>0.004557</td>
      <td>0.313351</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000</td>
      <td>0.004449</td>
      <td>-0.004449</td>
      <td>0.004449</td>
      <td>0.308901</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>0.000000</td>
      <td>-0.004365</td>
      <td>0.004365</td>
      <td>0.004365</td>
      <td>0.313266</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.004350</td>
      <td>0.004350</td>
      <td>0.004350</td>
      <td>0.317615</td>
    </tr>
    <tr>
      <th>1174</th>
      <td>place</td>
      <td>0.000000</td>
      <td>0.004334</td>
      <td>-0.004334</td>
      <td>0.004334</td>
      <td>0.313281</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000</td>
      <td>0.004165</td>
      <td>-0.004165</td>
      <td>0.004165</td>
      <td>0.309116</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000</td>
      <td>0.004087</td>
      <td>-0.004087</td>
      <td>0.004087</td>
      <td>0.305029</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.004063</td>
      <td>0.004063</td>
      <td>0.004063</td>
      <td>0.309092</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003969</td>
      <td>0.003969</td>
      <td>0.003969</td>
      <td>0.313061</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000</td>
      <td>0.003960</td>
      <td>-0.003960</td>
      <td>0.003960</td>
      <td>0.309101</td>
    </tr>
    <tr>
      <th>589</th>
      <td>go</td>
      <td>0.707107</td>
      <td>0.003802</td>
      <td>-0.003802</td>
      <td>0.003802</td>
      <td>0.305299</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000</td>
      <td>0.003649</td>
      <td>-0.003649</td>
      <td>0.003649</td>
      <td>0.301650</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000</td>
      <td>0.003471</td>
      <td>-0.003471</td>
      <td>0.003471</td>
      <td>0.298180</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000</td>
      <td>0.003365</td>
      <td>-0.003365</td>
      <td>0.003365</td>
      <td>0.294814</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 544
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;However, after finally watching this film, I realized that not only had I had a closed mind to the brilliance it depicts, I also found myself watching it over and over again.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.515 0.485]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.144822</td>
      <td>0.144822</td>
      <td>0.144822</td>
      <td>0.644332</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.260000e-01</td>
      <td>0.064792</td>
      <td>-0.064792</td>
      <td>0.064792</td>
      <td>0.579540</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.045318</td>
      <td>-0.045318</td>
      <td>0.045318</td>
      <td>0.534221</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.994000e-01</td>
      <td>-0.038231</td>
      <td>0.038231</td>
      <td>0.038231</td>
      <td>0.572452</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-3.333333e-02</td>
      <td>0.036543</td>
      <td>-0.036543</td>
      <td>0.036543</td>
      <td>0.535909</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>3.200000e+01</td>
      <td>0.017976</td>
      <td>-0.017976</td>
      <td>0.017976</td>
      <td>0.517933</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>5.752912e-158</td>
      <td>0.007501</td>
      <td>-0.007501</td>
      <td>0.007501</td>
      <td>0.510432</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007437</td>
      <td>-0.007437</td>
      <td>0.007437</td>
      <td>0.502995</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>-0.006117</td>
      <td>0.006117</td>
      <td>0.006117</td>
      <td>0.509112</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005735</td>
      <td>-0.005735</td>
      <td>0.005735</td>
      <td>0.503377</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>1.690309e-01</td>
      <td>0.005334</td>
      <td>-0.005334</td>
      <td>0.005334</td>
      <td>0.498043</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>1.690309e-01</td>
      <td>-0.004457</td>
      <td>0.004457</td>
      <td>0.004457</td>
      <td>0.502500</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003873</td>
      <td>-0.003873</td>
      <td>0.003873</td>
      <td>0.498627</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003790</td>
      <td>-0.003790</td>
      <td>0.003790</td>
      <td>0.494837</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003404</td>
      <td>0.003404</td>
      <td>0.003404</td>
      <td>0.498241</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>4.000000e+00</td>
      <td>0.003268</td>
      <td>-0.003268</td>
      <td>0.003268</td>
      <td>0.494973</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003138</td>
      <td>0.003138</td>
      <td>0.003138</td>
      <td>0.498111</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003052</td>
      <td>0.003052</td>
      <td>0.003052</td>
      <td>0.501163</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.002827</td>
      <td>-0.002827</td>
      <td>0.002827</td>
      <td>0.498336</td>
    </tr>
    <tr>
      <th>501</th>
      <td>film</td>
      <td>1.690309e-01</td>
      <td>-0.002758</td>
      <td>0.002758</td>
      <td>0.002758</td>
      <td>0.501094</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.002732</td>
      <td>0.002732</td>
      <td>0.002732</td>
      <td>0.503826</td>
    </tr>
    <tr>
      <th>2096</th>
      <td>topic 170</td>
      <td>5.304446e-03</td>
      <td>-0.002697</td>
      <td>0.002697</td>
      <td>0.002697</td>
      <td>0.506524</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002601</td>
      <td>-0.002601</td>
      <td>0.002601</td>
      <td>0.503922</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002545</td>
      <td>0.002545</td>
      <td>0.002545</td>
      <td>0.506468</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002506</td>
      <td>-0.002506</td>
      <td>0.002506</td>
      <td>0.503961</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.952208e-226</td>
      <td>-0.002492</td>
      <td>0.002492</td>
      <td>0.002492</td>
      <td>0.506454</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002419</td>
      <td>-0.002419</td>
      <td>0.002419</td>
      <td>0.504035</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.760000e+02</td>
      <td>0.002330</td>
      <td>-0.002330</td>
      <td>0.002330</td>
      <td>0.501705</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002223</td>
      <td>0.002223</td>
      <td>0.002223</td>
      <td>0.503928</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002213</td>
      <td>-0.002213</td>
      <td>0.002213</td>
      <td>0.501715</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 545
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It&#39;s the one movie that never ceases to interest me, simply because it keeps me alert, as I try to attempt to decipher it&#39;s meanings.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8225 0.1775]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>8.200000e-02</td>
      <td>0.074911</td>
      <td>-0.074911</td>
      <td>0.074911</td>
      <td>0.424599</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-7.210000e-02</td>
      <td>0.033649</td>
      <td>-0.033649</td>
      <td>0.033649</td>
      <td>0.390950</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031404</td>
      <td>-0.031404</td>
      <td>0.031404</td>
      <td>0.359545</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.029475</td>
      <td>-0.029475</td>
      <td>0.029475</td>
      <td>0.330071</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024768</td>
      <td>0.024768</td>
      <td>0.024768</td>
      <td>0.354838</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018627</td>
      <td>0.018627</td>
      <td>0.018627</td>
      <td>0.373465</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.350000e+02</td>
      <td>0.015172</td>
      <td>-0.015172</td>
      <td>0.015172</td>
      <td>0.358294</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.010147</td>
      <td>-0.010147</td>
      <td>0.010147</td>
      <td>0.348147</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009897</td>
      <td>-0.009897</td>
      <td>0.009897</td>
      <td>0.338250</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008527</td>
      <td>-0.008527</td>
      <td>0.008527</td>
      <td>0.329723</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007722</td>
      <td>-0.007722</td>
      <td>0.007722</td>
      <td>0.322000</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007526</td>
      <td>-0.007526</td>
      <td>0.007526</td>
      <td>0.314475</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>2.000000e+00</td>
      <td>-0.007132</td>
      <td>0.007132</td>
      <td>0.007132</td>
      <td>0.321606</td>
    </tr>
    <tr>
      <th>939</th>
      <td>me</td>
      <td>3.380617e-01</td>
      <td>0.006596</td>
      <td>-0.006596</td>
      <td>0.006596</td>
      <td>0.315010</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006446</td>
      <td>-0.006446</td>
      <td>0.006446</td>
      <td>0.308564</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005656</td>
      <td>0.005656</td>
      <td>0.005656</td>
      <td>0.314220</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>4.838879e-194</td>
      <td>0.004783</td>
      <td>-0.004783</td>
      <td>0.004783</td>
      <td>0.309437</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004131</td>
      <td>0.004131</td>
      <td>0.004131</td>
      <td>0.313568</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003610</td>
      <td>0.003610</td>
      <td>0.003610</td>
      <td>0.317178</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003580</td>
      <td>0.003580</td>
      <td>0.003580</td>
      <td>0.320758</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003521</td>
      <td>0.003521</td>
      <td>0.003521</td>
      <td>0.324279</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003491</td>
      <td>-0.003491</td>
      <td>0.003491</td>
      <td>0.320788</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.003447</td>
      <td>-0.003447</td>
      <td>0.003447</td>
      <td>0.317342</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003376</td>
      <td>-0.003376</td>
      <td>0.003376</td>
      <td>0.313966</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>3.758849e-88</td>
      <td>-0.003279</td>
      <td>0.003279</td>
      <td>0.003279</td>
      <td>0.317245</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003255</td>
      <td>0.003255</td>
      <td>0.003255</td>
      <td>0.320500</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003211</td>
      <td>-0.003211</td>
      <td>0.003211</td>
      <td>0.317288</td>
    </tr>
    <tr>
      <th>1932</th>
      <td>topic 6</td>
      <td>6.862143e-200</td>
      <td>0.003088</td>
      <td>-0.003088</td>
      <td>0.003088</td>
      <td>0.314201</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002855</td>
      <td>0.002855</td>
      <td>0.002855</td>
      <td>0.317055</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>topic 72</td>
      <td>0.000000e+00</td>
      <td>-0.002799</td>
      <td>0.002799</td>
      <td>0.002799</td>
      <td>0.319854</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 550
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;Both Rickman and Stowe play their roles to the hilt in this tale of a childrens&#39; book writer who-- maybe?-- has written a subversive tract.  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.9025 0.0975]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>-2.000000e+00</td>
      <td>0.197632</td>
      <td>-0.197632</td>
      <td>0.197632</td>
      <td>0.301878</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>9.500000e-02</td>
      <td>0.066151</td>
      <td>-0.066151</td>
      <td>0.066151</td>
      <td>0.235727</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.029503</td>
      <td>-0.029503</td>
      <td>0.029503</td>
      <td>0.206224</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.022924</td>
      <td>0.022924</td>
      <td>0.022924</td>
      <td>0.229148</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.500000e+01</td>
      <td>0.017691</td>
      <td>-0.017691</td>
      <td>0.017691</td>
      <td>0.211457</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.015973</td>
      <td>0.015973</td>
      <td>0.015973</td>
      <td>0.227430</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.410000e+02</td>
      <td>0.009873</td>
      <td>-0.009873</td>
      <td>0.009873</td>
      <td>0.217557</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009030</td>
      <td>-0.009030</td>
      <td>0.009030</td>
      <td>0.208527</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>1.280000e-01</td>
      <td>0.006619</td>
      <td>-0.006619</td>
      <td>0.006619</td>
      <td>0.201908</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.006444</td>
      <td>-0.006444</td>
      <td>0.006444</td>
      <td>0.195464</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005704</td>
      <td>-0.005704</td>
      <td>0.005704</td>
      <td>0.189761</td>
    </tr>
    <tr>
      <th>1948</th>
      <td>topic 22</td>
      <td>3.166803e-25</td>
      <td>0.004743</td>
      <td>-0.004743</td>
      <td>0.004743</td>
      <td>0.185018</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>3.000000e+00</td>
      <td>-0.004122</td>
      <td>0.004122</td>
      <td>0.004122</td>
      <td>0.189140</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.003941</td>
      <td>-0.003941</td>
      <td>0.003941</td>
      <td>0.185200</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>7.000000e+00</td>
      <td>-0.003517</td>
      <td>0.003517</td>
      <td>0.003517</td>
      <td>0.188716</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003348</td>
      <td>0.003348</td>
      <td>0.003348</td>
      <td>0.192065</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003203</td>
      <td>-0.003203</td>
      <td>0.003203</td>
      <td>0.188861</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003201</td>
      <td>0.003201</td>
      <td>0.003201</td>
      <td>0.192063</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.002612</td>
      <td>-0.002612</td>
      <td>0.002612</td>
      <td>0.189451</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002604</td>
      <td>0.002604</td>
      <td>0.002604</td>
      <td>0.192055</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.002501</td>
      <td>0.002501</td>
      <td>0.002501</td>
      <td>0.194556</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>0.000000e+00</td>
      <td>-0.002475</td>
      <td>0.002475</td>
      <td>0.002475</td>
      <td>0.197031</td>
    </tr>
    <tr>
      <th>1025</th>
      <td>not be</td>
      <td>0.000000e+00</td>
      <td>0.002390</td>
      <td>-0.002390</td>
      <td>0.002390</td>
      <td>0.194641</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.002386</td>
      <td>0.002386</td>
      <td>0.002386</td>
      <td>0.197026</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002379</td>
      <td>-0.002379</td>
      <td>0.002379</td>
      <td>0.194647</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002337</td>
      <td>0.002337</td>
      <td>0.002337</td>
      <td>0.196984</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002255</td>
      <td>0.002255</td>
      <td>0.002255</td>
      <td>0.199239</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002244</td>
      <td>0.002244</td>
      <td>0.002244</td>
      <td>0.201484</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.002224</td>
      <td>0.002224</td>
      <td>0.002224</td>
      <td>0.203708</td>
    </tr>
    <tr>
      <th>1558</th>
      <td>then</td>
      <td>0.000000e+00</td>
      <td>-0.002203</td>
      <td>0.002203</td>
      <td>0.002203</td>
      <td>0.205911</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 552
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;It presents a idyllic yet serious portrayal of the ups and downs of the characters lives.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8875 0.1125]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.083130</td>
      <td>-0.083130</td>
      <td>0.083130</td>
      <td>0.416380</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>-3.333333e-01</td>
      <td>0.077673</td>
      <td>-0.077673</td>
      <td>0.077673</td>
      <td>0.338706</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.600000e+01</td>
      <td>0.025918</td>
      <td>-0.025918</td>
      <td>0.025918</td>
      <td>0.312788</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024774</td>
      <td>0.024774</td>
      <td>0.024774</td>
      <td>0.337561</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-7.720000e-02</td>
      <td>0.023997</td>
      <td>-0.023997</td>
      <td>0.023997</td>
      <td>0.313564</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018720</td>
      <td>0.018720</td>
      <td>0.018720</td>
      <td>0.332284</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>9.100000e+01</td>
      <td>0.015323</td>
      <td>-0.015323</td>
      <td>0.015323</td>
      <td>0.316961</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009815</td>
      <td>-0.009815</td>
      <td>0.009815</td>
      <td>0.307146</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.227496e-272</td>
      <td>0.007247</td>
      <td>-0.007247</td>
      <td>0.007247</td>
      <td>0.299899</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006146</td>
      <td>-0.006146</td>
      <td>0.006146</td>
      <td>0.293753</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005568</td>
      <td>-0.005568</td>
      <td>0.005568</td>
      <td>0.288186</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.005558</td>
      <td>-0.005558</td>
      <td>0.005558</td>
      <td>0.282627</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005289</td>
      <td>0.005289</td>
      <td>0.005289</td>
      <td>0.287916</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004728</td>
      <td>-0.004728</td>
      <td>0.004728</td>
      <td>0.283188</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004129</td>
      <td>-0.004129</td>
      <td>0.004129</td>
      <td>0.279059</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003905</td>
      <td>0.003905</td>
      <td>0.003905</td>
      <td>0.282963</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.003803</td>
      <td>0.003803</td>
      <td>0.003803</td>
      <td>0.286766</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003786</td>
      <td>0.003786</td>
      <td>0.003786</td>
      <td>0.290552</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>0.000000e+00</td>
      <td>0.003549</td>
      <td>-0.003549</td>
      <td>0.003549</td>
      <td>0.287003</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003412</td>
      <td>0.003412</td>
      <td>0.003412</td>
      <td>0.290415</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>5.578102e-314</td>
      <td>-0.003321</td>
      <td>0.003321</td>
      <td>0.003321</td>
      <td>0.293736</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003167</td>
      <td>-0.003167</td>
      <td>0.003167</td>
      <td>0.290569</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003138</td>
      <td>-0.003138</td>
      <td>0.003138</td>
      <td>0.287431</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003119</td>
      <td>-0.003119</td>
      <td>0.003119</td>
      <td>0.284312</td>
    </tr>
    <tr>
      <th>1077</th>
      <td>of the</td>
      <td>5.000000e-01</td>
      <td>0.003117</td>
      <td>-0.003117</td>
      <td>0.003117</td>
      <td>0.281195</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.002889</td>
      <td>0.002889</td>
      <td>0.002889</td>
      <td>0.284084</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.002830</td>
      <td>-0.002830</td>
      <td>0.002830</td>
      <td>0.281255</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>3.773717e-04</td>
      <td>0.002815</td>
      <td>-0.002815</td>
      <td>0.002815</td>
      <td>0.278439</td>
    </tr>
    <tr>
      <th>2042</th>
      <td>topic 116</td>
      <td>2.869740e-109</td>
      <td>0.002778</td>
      <td>-0.002778</td>
      <td>0.002778</td>
      <td>0.275661</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.002745</td>
      <td>0.002745</td>
      <td>0.002745</td>
      <td>0.278406</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 553
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Just whatever you do, avoid &#34;Groove&#34; as its the antithesis of all that is good about Human Traffic.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.405 0.595]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.162541</td>
      <td>0.162541</td>
      <td>0.162541</td>
      <td>0.662051</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.370000e-01</td>
      <td>0.075163</td>
      <td>-0.075163</td>
      <td>0.075163</td>
      <td>0.586888</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025160</td>
      <td>0.025160</td>
      <td>0.025160</td>
      <td>0.612048</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020998</td>
      <td>0.020998</td>
      <td>0.020998</td>
      <td>0.633045</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.500000e-01</td>
      <td>-0.014631</td>
      <td>0.014631</td>
      <td>0.014631</td>
      <td>0.647676</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.800000e+01</td>
      <td>0.013851</td>
      <td>-0.013851</td>
      <td>0.013851</td>
      <td>0.633825</td>
    </tr>
    <tr>
      <th>2099</th>
      <td>topic 173</td>
      <td>1.731265e-03</td>
      <td>0.010676</td>
      <td>-0.010676</td>
      <td>0.010676</td>
      <td>0.623149</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.010304</td>
      <td>-0.010304</td>
      <td>0.010304</td>
      <td>0.612845</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009042</td>
      <td>-0.009042</td>
      <td>0.009042</td>
      <td>0.603803</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>1.779000e-01</td>
      <td>0.008169</td>
      <td>-0.008169</td>
      <td>0.008169</td>
      <td>0.595634</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>3.954551e-155</td>
      <td>0.007961</td>
      <td>-0.007961</td>
      <td>0.007961</td>
      <td>0.587673</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>0.005868</td>
      <td>-0.005868</td>
      <td>0.005868</td>
      <td>0.581805</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.005737</td>
      <td>-0.005737</td>
      <td>0.005737</td>
      <td>0.576069</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>8.606469e-02</td>
      <td>0.005252</td>
      <td>-0.005252</td>
      <td>0.005252</td>
      <td>0.570817</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>0.000000e+00</td>
      <td>-0.004990</td>
      <td>0.004990</td>
      <td>0.004990</td>
      <td>0.575807</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.004829</td>
      <td>0.004829</td>
      <td>0.004829</td>
      <td>0.580636</td>
    </tr>
    <tr>
      <th>1900</th>
      <td>you</td>
      <td>2.357023e-01</td>
      <td>0.004682</td>
      <td>-0.004682</td>
      <td>0.004682</td>
      <td>0.575954</td>
    </tr>
    <tr>
      <th>714</th>
      <td>human</td>
      <td>2.357023e-01</td>
      <td>0.004382</td>
      <td>-0.004382</td>
      <td>0.004382</td>
      <td>0.571572</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004142</td>
      <td>-0.004142</td>
      <td>0.004142</td>
      <td>0.567431</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>2.357023e-01</td>
      <td>-0.003985</td>
      <td>0.003985</td>
      <td>0.003985</td>
      <td>0.571416</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003788</td>
      <td>-0.003788</td>
      <td>0.003788</td>
      <td>0.567628</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003645</td>
      <td>0.003645</td>
      <td>0.003645</td>
      <td>0.571273</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003600</td>
      <td>0.003600</td>
      <td>0.003600</td>
      <td>0.574874</td>
    </tr>
    <tr>
      <th>1153</th>
      <td>performance</td>
      <td>0.000000e+00</td>
      <td>-0.003598</td>
      <td>0.003598</td>
      <td>0.003598</td>
      <td>0.578471</td>
    </tr>
    <tr>
      <th>1595</th>
      <td>this is</td>
      <td>0.000000e+00</td>
      <td>0.002936</td>
      <td>-0.002936</td>
      <td>0.002936</td>
      <td>0.575535</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002851</td>
      <td>0.002851</td>
      <td>0.002851</td>
      <td>0.578386</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.010000e+02</td>
      <td>0.002810</td>
      <td>-0.002810</td>
      <td>0.002810</td>
      <td>0.575576</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>4.940656e-324</td>
      <td>-0.002802</td>
      <td>0.002802</td>
      <td>0.002802</td>
      <td>0.578379</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002767</td>
      <td>-0.002767</td>
      <td>0.002767</td>
      <td>0.575612</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002716</td>
      <td>-0.002716</td>
      <td>0.002716</td>
      <td>0.572896</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 556
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;But it picked up speed and got right to the point.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.7475 0.2525]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.091206</td>
      <td>-0.091206</td>
      <td>0.091206</td>
      <td>0.408304</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025948</td>
      <td>0.025948</td>
      <td>0.025948</td>
      <td>0.434252</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019661</td>
      <td>0.019661</td>
      <td>0.019661</td>
      <td>0.453913</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.017266</td>
      <td>-0.017266</td>
      <td>0.017266</td>
      <td>0.436647</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>5.200000e+01</td>
      <td>0.015187</td>
      <td>-0.015187</td>
      <td>0.015187</td>
      <td>0.421460</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009795</td>
      <td>-0.009795</td>
      <td>0.009795</td>
      <td>0.411665</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.008807</td>
      <td>0.008807</td>
      <td>0.008807</td>
      <td>0.420472</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008707</td>
      <td>-0.008707</td>
      <td>0.008707</td>
      <td>0.411765</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.008199</td>
      <td>-0.008199</td>
      <td>0.008199</td>
      <td>0.403566</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007845</td>
      <td>-0.007845</td>
      <td>0.007845</td>
      <td>0.395721</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006601</td>
      <td>-0.006601</td>
      <td>0.006601</td>
      <td>0.389119</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>1.000000e+00</td>
      <td>0.005676</td>
      <td>-0.005676</td>
      <td>0.005676</td>
      <td>0.383443</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005256</td>
      <td>0.005256</td>
      <td>0.005256</td>
      <td>0.388699</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.458460e-323</td>
      <td>0.005213</td>
      <td>-0.005213</td>
      <td>0.005213</td>
      <td>0.383486</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.004632</td>
      <td>0.004632</td>
      <td>0.004632</td>
      <td>0.388119</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.004389</td>
      <td>-0.004389</td>
      <td>0.004389</td>
      <td>0.383729</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004164</td>
      <td>0.004164</td>
      <td>0.004164</td>
      <td>0.387893</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003885</td>
      <td>0.003885</td>
      <td>0.003885</td>
      <td>0.391778</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003763</td>
      <td>0.003763</td>
      <td>0.003763</td>
      <td>0.395541</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003732</td>
      <td>-0.003732</td>
      <td>0.003732</td>
      <td>0.391809</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003278</td>
      <td>0.003278</td>
      <td>0.003278</td>
      <td>0.395087</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003220</td>
      <td>-0.003220</td>
      <td>0.003220</td>
      <td>0.391867</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003206</td>
      <td>0.003206</td>
      <td>0.003206</td>
      <td>0.395073</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003197</td>
      <td>-0.003197</td>
      <td>0.003197</td>
      <td>0.391876</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.003179</td>
      <td>-0.003179</td>
      <td>0.003179</td>
      <td>0.388697</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.358716e-87</td>
      <td>0.003155</td>
      <td>-0.003155</td>
      <td>0.003155</td>
      <td>0.385542</td>
    </tr>
    <tr>
      <th>678</th>
      <td>heart</td>
      <td>0.000000e+00</td>
      <td>0.003155</td>
      <td>-0.003155</td>
      <td>0.003155</td>
      <td>0.382387</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003133</td>
      <td>-0.003133</td>
      <td>0.003133</td>
      <td>0.379254</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>2.017583e-242</td>
      <td>0.003041</td>
      <td>-0.003041</td>
      <td>0.003041</td>
      <td>0.376213</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.003009</td>
      <td>-0.003009</td>
      <td>0.003009</td>
      <td>0.373204</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 557
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;It showed exactly how the government and the scientist argued for humanity and the reasons of the &#34;gadget&#34;.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8325 0.1675]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-0.361200</td>
      <td>0.118043</td>
      <td>-0.118043</td>
      <td>0.118043</td>
      <td>0.381467</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000</td>
      <td>0.090736</td>
      <td>-0.090736</td>
      <td>0.090736</td>
      <td>0.290730</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000</td>
      <td>-0.024256</td>
      <td>0.024256</td>
      <td>0.024256</td>
      <td>0.314986</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000</td>
      <td>-0.018449</td>
      <td>0.018449</td>
      <td>0.018449</td>
      <td>0.333435</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>109.000000</td>
      <td>0.015052</td>
      <td>-0.015052</td>
      <td>0.015052</td>
      <td>0.318383</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>3.000000</td>
      <td>0.011841</td>
      <td>-0.011841</td>
      <td>0.011841</td>
      <td>0.306542</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000</td>
      <td>0.010256</td>
      <td>-0.010256</td>
      <td>0.010256</td>
      <td>0.296286</td>
    </tr>
    <tr>
      <th>466</th>
      <td>exactly</td>
      <td>0.258199</td>
      <td>-0.010174</td>
      <td>0.010174</td>
      <td>0.010174</td>
      <td>0.306460</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000</td>
      <td>0.007565</td>
      <td>-0.007565</td>
      <td>0.007565</td>
      <td>0.298895</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>18.000000</td>
      <td>0.006730</td>
      <td>-0.006730</td>
      <td>0.006730</td>
      <td>0.292165</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000</td>
      <td>0.006228</td>
      <td>-0.006228</td>
      <td>0.006228</td>
      <td>0.285937</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000</td>
      <td>0.006098</td>
      <td>-0.006098</td>
      <td>0.006098</td>
      <td>0.279838</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.250000</td>
      <td>0.005352</td>
      <td>-0.005352</td>
      <td>0.005352</td>
      <td>0.274486</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000</td>
      <td>-0.005308</td>
      <td>0.005308</td>
      <td>0.005308</td>
      <td>0.279794</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000</td>
      <td>0.004552</td>
      <td>-0.004552</td>
      <td>0.004552</td>
      <td>0.275242</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000</td>
      <td>0.004521</td>
      <td>-0.004521</td>
      <td>0.004521</td>
      <td>0.270721</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000</td>
      <td>0.004502</td>
      <td>-0.004502</td>
      <td>0.004502</td>
      <td>0.266219</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000</td>
      <td>-0.003911</td>
      <td>0.003911</td>
      <td>0.003911</td>
      <td>0.270130</td>
    </tr>
    <tr>
      <th>1077</th>
      <td>of the</td>
      <td>0.258199</td>
      <td>0.003530</td>
      <td>-0.003530</td>
      <td>0.003530</td>
      <td>0.266600</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000</td>
      <td>-0.003408</td>
      <td>0.003408</td>
      <td>0.003408</td>
      <td>0.270008</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000</td>
      <td>0.003384</td>
      <td>-0.003384</td>
      <td>0.003384</td>
      <td>0.266625</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000</td>
      <td>-0.003354</td>
      <td>0.003354</td>
      <td>0.003354</td>
      <td>0.269979</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000</td>
      <td>-0.003276</td>
      <td>0.003276</td>
      <td>0.003276</td>
      <td>0.273255</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000</td>
      <td>-0.003212</td>
      <td>0.003212</td>
      <td>0.003212</td>
      <td>0.276467</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000</td>
      <td>0.003008</td>
      <td>-0.003008</td>
      <td>0.003008</td>
      <td>0.273459</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000</td>
      <td>0.002975</td>
      <td>-0.002975</td>
      <td>0.002975</td>
      <td>0.270484</td>
    </tr>
    <tr>
      <th>1812</th>
      <td>well</td>
      <td>0.000000</td>
      <td>0.002827</td>
      <td>-0.002827</td>
      <td>0.002827</td>
      <td>0.267657</td>
    </tr>
    <tr>
      <th>1944</th>
      <td>topic 18</td>
      <td>0.000869</td>
      <td>-0.002817</td>
      <td>0.002817</td>
      <td>0.002817</td>
      <td>0.270475</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000</td>
      <td>-0.002775</td>
      <td>0.002775</td>
      <td>0.002775</td>
      <td>0.273250</td>
    </tr>
    <tr>
      <th>1363</th>
      <td>so</td>
      <td>0.000000</td>
      <td>-0.002774</td>
      <td>0.002774</td>
      <td>0.002774</td>
      <td>0.276024</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 562
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Their on-screen chemistry, critical to the entire film, is genuine.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8275 0.1725]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-3.182000e-01</td>
      <td>0.098502</td>
      <td>-0.098502</td>
      <td>0.098502</td>
      <td>0.401008</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.084462</td>
      <td>-0.084462</td>
      <td>0.084462</td>
      <td>0.316546</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024634</td>
      <td>0.024634</td>
      <td>0.024634</td>
      <td>0.341180</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.000000e+01</td>
      <td>0.023301</td>
      <td>-0.023301</td>
      <td>0.023301</td>
      <td>0.317879</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018985</td>
      <td>0.018985</td>
      <td>0.018985</td>
      <td>0.336864</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.900000e+01</td>
      <td>0.014000</td>
      <td>-0.014000</td>
      <td>0.014000</td>
      <td>0.322864</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009926</td>
      <td>-0.009926</td>
      <td>0.009926</td>
      <td>0.312938</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.333333e-01</td>
      <td>0.009000</td>
      <td>-0.009000</td>
      <td>0.009000</td>
      <td>0.303938</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>3.535534e-01</td>
      <td>0.007840</td>
      <td>-0.007840</td>
      <td>0.007840</td>
      <td>0.296099</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>9.045683e-151</td>
      <td>0.007289</td>
      <td>-0.007289</td>
      <td>0.007289</td>
      <td>0.288809</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.007060</td>
      <td>-0.007060</td>
      <td>0.007060</td>
      <td>0.281749</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006400</td>
      <td>-0.006400</td>
      <td>0.006400</td>
      <td>0.275349</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>4.000000e+00</td>
      <td>0.005372</td>
      <td>-0.005372</td>
      <td>0.005372</td>
      <td>0.269978</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004724</td>
      <td>-0.004724</td>
      <td>0.004724</td>
      <td>0.265254</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.004345</td>
      <td>-0.004345</td>
      <td>0.004345</td>
      <td>0.260909</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.004134</td>
      <td>0.004134</td>
      <td>0.004134</td>
      <td>0.265043</td>
    </tr>
    <tr>
      <th>1915</th>
      <td>your</td>
      <td>0.000000e+00</td>
      <td>-0.004102</td>
      <td>0.004102</td>
      <td>0.004102</td>
      <td>0.269146</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.003874</td>
      <td>0.003874</td>
      <td>0.003874</td>
      <td>0.273020</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003763</td>
      <td>0.003763</td>
      <td>0.003763</td>
      <td>0.276783</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003620</td>
      <td>-0.003620</td>
      <td>0.003620</td>
      <td>0.273163</td>
    </tr>
    <tr>
      <th>2079</th>
      <td>topic 153</td>
      <td>6.197442e-07</td>
      <td>-0.003512</td>
      <td>0.003512</td>
      <td>0.003512</td>
      <td>0.276675</td>
    </tr>
    <tr>
      <th>1648</th>
      <td>to the</td>
      <td>3.535534e-01</td>
      <td>-0.003460</td>
      <td>0.003460</td>
      <td>0.003460</td>
      <td>0.280134</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003362</td>
      <td>0.003362</td>
      <td>0.003362</td>
      <td>0.283496</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003347</td>
      <td>0.003347</td>
      <td>0.003347</td>
      <td>0.286844</td>
    </tr>
    <tr>
      <th>2062</th>
      <td>topic 136</td>
      <td>0.000000e+00</td>
      <td>0.003342</td>
      <td>-0.003342</td>
      <td>0.003342</td>
      <td>0.283502</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.164122e-218</td>
      <td>-0.003306</td>
      <td>0.003306</td>
      <td>0.003306</td>
      <td>0.286808</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003182</td>
      <td>-0.003182</td>
      <td>0.003182</td>
      <td>0.283626</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003176</td>
      <td>0.003176</td>
      <td>0.003176</td>
      <td>0.286801</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003152</td>
      <td>0.003152</td>
      <td>0.003152</td>
      <td>0.289953</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003050</td>
      <td>-0.003050</td>
      <td>0.003050</td>
      <td>0.286903</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 566
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Each track commands sentiment, actually contributing to the scenes and characters.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.8225 0.1775]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.090664</td>
      <td>-0.090664</td>
      <td>0.090664</td>
      <td>0.408846</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031798</td>
      <td>-0.031798</td>
      <td>0.031798</td>
      <td>0.377048</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.029638</td>
      <td>-0.029638</td>
      <td>0.029638</td>
      <td>0.347410</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.025916</td>
      <td>0.025916</td>
      <td>0.025916</td>
      <td>0.373326</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019354</td>
      <td>0.019354</td>
      <td>0.019354</td>
      <td>0.392679</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.014282</td>
      <td>-0.014282</td>
      <td>0.014282</td>
      <td>0.378397</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.010146</td>
      <td>-0.010146</td>
      <td>0.010146</td>
      <td>0.368251</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.009858</td>
      <td>0.009858</td>
      <td>0.009858</td>
      <td>0.378109</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.007873</td>
      <td>-0.007873</td>
      <td>0.007873</td>
      <td>0.370236</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007619</td>
      <td>-0.007619</td>
      <td>0.007619</td>
      <td>0.362616</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>8.400000e+01</td>
      <td>0.006513</td>
      <td>-0.006513</td>
      <td>0.006513</td>
      <td>0.356103</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006397</td>
      <td>-0.006397</td>
      <td>0.006397</td>
      <td>0.349706</td>
    </tr>
    <tr>
      <th>2002</th>
      <td>topic 76</td>
      <td>2.835116e-01</td>
      <td>0.005860</td>
      <td>-0.005860</td>
      <td>0.005860</td>
      <td>0.343846</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005704</td>
      <td>0.005704</td>
      <td>0.005704</td>
      <td>0.349550</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.005239</td>
      <td>-0.005239</td>
      <td>0.005239</td>
      <td>0.344311</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>3.818049e-217</td>
      <td>0.004905</td>
      <td>-0.004905</td>
      <td>0.004905</td>
      <td>0.339406</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>topic 71</td>
      <td>5.355101e-04</td>
      <td>0.004731</td>
      <td>-0.004731</td>
      <td>0.004731</td>
      <td>0.334675</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004179</td>
      <td>-0.004179</td>
      <td>0.004179</td>
      <td>0.330496</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.004118</td>
      <td>0.004118</td>
      <td>0.004118</td>
      <td>0.334614</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004069</td>
      <td>0.004069</td>
      <td>0.004069</td>
      <td>0.338683</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>2.123685e-28</td>
      <td>0.003937</td>
      <td>-0.003937</td>
      <td>0.003937</td>
      <td>0.334746</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003866</td>
      <td>0.003866</td>
      <td>0.003866</td>
      <td>0.338612</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003710</td>
      <td>0.003710</td>
      <td>0.003710</td>
      <td>0.342322</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003291</td>
      <td>-0.003291</td>
      <td>0.003291</td>
      <td>0.339031</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003209</td>
      <td>0.003209</td>
      <td>0.003209</td>
      <td>0.342241</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003191</td>
      <td>-0.003191</td>
      <td>0.003191</td>
      <td>0.339049</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003182</td>
      <td>0.003182</td>
      <td>0.003182</td>
      <td>0.342231</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>9.225775e-13</td>
      <td>0.003148</td>
      <td>-0.003148</td>
      <td>0.003148</td>
      <td>0.339083</td>
    </tr>
    <tr>
      <th>1396</th>
      <td>star</td>
      <td>0.000000e+00</td>
      <td>0.003144</td>
      <td>-0.003144</td>
      <td>0.003144</td>
      <td>0.335939</td>
    </tr>
    <tr>
      <th>282</th>
      <td>case</td>
      <td>0.000000e+00</td>
      <td>0.003119</td>
      <td>-0.003119</td>
      <td>0.003119</td>
      <td>0.332820</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 570
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;Enough can not be said of the remarkable animation in this film.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.465 0.535]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.131020</td>
      <td>0.131020</td>
      <td>0.131020</td>
      <td>0.630530</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>2.470000e-01</td>
      <td>0.066056</td>
      <td>-0.066056</td>
      <td>0.066056</td>
      <td>0.564474</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.041306</td>
      <td>-0.041306</td>
      <td>0.041306</td>
      <td>0.523168</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.574000e-01</td>
      <td>-0.029350</td>
      <td>0.029350</td>
      <td>0.029350</td>
      <td>0.552518</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.200000e+01</td>
      <td>0.011466</td>
      <td>-0.011466</td>
      <td>0.011466</td>
      <td>0.541052</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009369</td>
      <td>-0.009369</td>
      <td>0.009369</td>
      <td>0.531683</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007760</td>
      <td>-0.007760</td>
      <td>0.007760</td>
      <td>0.523924</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.600000e+01</td>
      <td>-0.007726</td>
      <td>0.007726</td>
      <td>0.007726</td>
      <td>0.531649</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.750000e-01</td>
      <td>-0.007611</td>
      <td>0.007611</td>
      <td>0.007611</td>
      <td>0.539260</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>6.570977e-151</td>
      <td>0.007599</td>
      <td>-0.007599</td>
      <td>0.007599</td>
      <td>0.531661</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005792</td>
      <td>-0.005792</td>
      <td>0.005792</td>
      <td>0.525869</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004306</td>
      <td>-0.004306</td>
      <td>0.004306</td>
      <td>0.521563</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004096</td>
      <td>-0.004096</td>
      <td>0.004096</td>
      <td>0.517467</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003345</td>
      <td>0.003345</td>
      <td>0.003345</td>
      <td>0.520813</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.003157</td>
      <td>-0.003157</td>
      <td>0.003157</td>
      <td>0.517656</td>
    </tr>
    <tr>
      <th>501</th>
      <td>film</td>
      <td>2.672612e-01</td>
      <td>-0.003118</td>
      <td>0.003118</td>
      <td>0.003118</td>
      <td>0.520774</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002917</td>
      <td>-0.002917</td>
      <td>0.002917</td>
      <td>0.517857</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002915</td>
      <td>-0.002915</td>
      <td>0.002915</td>
      <td>0.514942</td>
    </tr>
    <tr>
      <th>2018</th>
      <td>topic 92</td>
      <td>0.000000e+00</td>
      <td>0.002887</td>
      <td>-0.002887</td>
      <td>0.002887</td>
      <td>0.512055</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002821</td>
      <td>-0.002821</td>
      <td>0.002821</td>
      <td>0.509234</td>
    </tr>
    <tr>
      <th>244</th>
      <td>but</td>
      <td>0.000000e+00</td>
      <td>-0.002790</td>
      <td>0.002790</td>
      <td>0.002790</td>
      <td>0.512024</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002749</td>
      <td>0.002749</td>
      <td>0.002749</td>
      <td>0.514774</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.002678</td>
      <td>-0.002678</td>
      <td>0.002678</td>
      <td>0.512096</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002562</td>
      <td>0.002562</td>
      <td>0.002562</td>
      <td>0.514658</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.002523</td>
      <td>-0.002523</td>
      <td>0.002523</td>
      <td>0.512135</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>7.163752e-219</td>
      <td>-0.002490</td>
      <td>0.002490</td>
      <td>0.002490</td>
      <td>0.514625</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002474</td>
      <td>0.002474</td>
      <td>0.002474</td>
      <td>0.517099</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>2.672612e-01</td>
      <td>0.002274</td>
      <td>-0.002274</td>
      <td>0.002274</td>
      <td>0.514825</td>
    </tr>
    <tr>
      <th>907</th>
      <td>love</td>
      <td>0.000000e+00</td>
      <td>0.002253</td>
      <td>-0.002253</td>
      <td>0.002253</td>
      <td>0.512572</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002204</td>
      <td>0.002204</td>
      <td>0.002204</td>
      <td>0.514776</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 572
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;If you act in such a film, you should be glad that you&#39;re gonna drift away from earth as far as possible!  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 0
Prediction [0.3325 0.6675]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>3.000000e+00</td>
      <td>-0.175346</td>
      <td>0.175346</td>
      <td>0.175346</td>
      <td>0.674856</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>1.410000e-01</td>
      <td>0.075543</td>
      <td>-0.075543</td>
      <td>0.075543</td>
      <td>0.599313</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>5.093000e-01</td>
      <td>-0.044424</td>
      <td>0.044424</td>
      <td>0.044424</td>
      <td>0.643737</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024863</td>
      <td>0.024863</td>
      <td>0.024863</td>
      <td>0.668600</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>1.500000e-01</td>
      <td>0.024539</td>
      <td>-0.024539</td>
      <td>0.024539</td>
      <td>0.644061</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.200000e+01</td>
      <td>0.024016</td>
      <td>-0.024016</td>
      <td>0.024016</td>
      <td>0.620045</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.021485</td>
      <td>0.021485</td>
      <td>0.021485</td>
      <td>0.641529</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.020150</td>
      <td>0.020150</td>
      <td>0.020150</td>
      <td>0.661680</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.008232</td>
      <td>-0.008232</td>
      <td>0.008232</td>
      <td>0.653448</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008132</td>
      <td>-0.008132</td>
      <td>0.008132</td>
      <td>0.645316</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>1.230891e-155</td>
      <td>0.007557</td>
      <td>-0.007557</td>
      <td>0.007557</td>
      <td>0.637759</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006291</td>
      <td>-0.006291</td>
      <td>0.006291</td>
      <td>0.631468</td>
    </tr>
    <tr>
      <th>2025</th>
      <td>topic 99</td>
      <td>2.126942e-01</td>
      <td>-0.006168</td>
      <td>0.006168</td>
      <td>0.006168</td>
      <td>0.637636</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.005508</td>
      <td>-0.005508</td>
      <td>0.005508</td>
      <td>0.632128</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>2.638821e-223</td>
      <td>0.005286</td>
      <td>-0.005286</td>
      <td>0.005286</td>
      <td>0.626842</td>
    </tr>
    <tr>
      <th>731</th>
      <td>in</td>
      <td>2.000000e-01</td>
      <td>-0.004706</td>
      <td>0.004706</td>
      <td>0.004706</td>
      <td>0.631548</td>
    </tr>
    <tr>
      <th>2089</th>
      <td>topic 163</td>
      <td>2.654992e-01</td>
      <td>-0.004580</td>
      <td>0.004580</td>
      <td>0.004580</td>
      <td>0.636128</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>0.000000e+00</td>
      <td>-0.004344</td>
      <td>0.004344</td>
      <td>0.004344</td>
      <td>0.640473</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.003946</td>
      <td>-0.003946</td>
      <td>0.003946</td>
      <td>0.636527</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003897</td>
      <td>0.003897</td>
      <td>0.003897</td>
      <td>0.640424</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003509</td>
      <td>0.003509</td>
      <td>0.003509</td>
      <td>0.643933</td>
    </tr>
    <tr>
      <th>1742</th>
      <td>wa</td>
      <td>0.000000e+00</td>
      <td>-0.003456</td>
      <td>0.003456</td>
      <td>0.003456</td>
      <td>0.647389</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.070000e+02</td>
      <td>-0.003405</td>
      <td>0.003405</td>
      <td>0.003405</td>
      <td>0.650794</td>
    </tr>
    <tr>
      <th>718</th>
      <td>if</td>
      <td>2.000000e-01</td>
      <td>0.003180</td>
      <td>-0.003180</td>
      <td>0.003180</td>
      <td>0.647615</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.003127</td>
      <td>-0.003127</td>
      <td>0.003127</td>
      <td>0.644488</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002995</td>
      <td>-0.002995</td>
      <td>0.002995</td>
      <td>0.641493</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002947</td>
      <td>0.002947</td>
      <td>0.002947</td>
      <td>0.644440</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>4.146655e-247</td>
      <td>0.002942</td>
      <td>-0.002942</td>
      <td>0.002942</td>
      <td>0.641498</td>
    </tr>
    <tr>
      <th>177</th>
      <td>be</td>
      <td>2.000000e-01</td>
      <td>-0.002881</td>
      <td>0.002881</td>
      <td>0.002881</td>
      <td>0.644380</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>8.076743e-224</td>
      <td>-0.002708</td>
      <td>0.002708</td>
      <td>0.002708</td>
      <td>0.647087</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 581
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;I keep watching it over and over.  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.82 0.18]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>0.000000e+00</td>
      <td>0.090274</td>
      <td>-0.090274</td>
      <td>0.090274</td>
      <td>0.409236</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.031277</td>
      <td>-0.031277</td>
      <td>0.031277</td>
      <td>0.377958</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>7.000000e+00</td>
      <td>0.030160</td>
      <td>-0.030160</td>
      <td>0.030160</td>
      <td>0.347798</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.026066</td>
      <td>0.026066</td>
      <td>0.026066</td>
      <td>0.373864</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.019317</td>
      <td>0.019317</td>
      <td>0.019317</td>
      <td>0.393181</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>3.500000e+01</td>
      <td>0.019028</td>
      <td>-0.019028</td>
      <td>0.019028</td>
      <td>0.374153</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009982</td>
      <td>-0.009982</td>
      <td>0.009982</td>
      <td>0.364171</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.008363</td>
      <td>-0.008363</td>
      <td>0.008363</td>
      <td>0.355808</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007678</td>
      <td>-0.007678</td>
      <td>0.007678</td>
      <td>0.348131</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006353</td>
      <td>-0.006353</td>
      <td>0.006353</td>
      <td>0.341778</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>1.000000e+00</td>
      <td>-0.006057</td>
      <td>0.006057</td>
      <td>0.006057</td>
      <td>0.347835</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.005630</td>
      <td>0.005630</td>
      <td>0.005630</td>
      <td>0.353465</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.005410</td>
      <td>0.005410</td>
      <td>0.005410</td>
      <td>0.358875</td>
    </tr>
    <tr>
      <th>1567</th>
      <td>they</td>
      <td>0.000000e+00</td>
      <td>0.005377</td>
      <td>-0.005377</td>
      <td>0.005377</td>
      <td>0.353498</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>0.000000e+00</td>
      <td>0.004905</td>
      <td>-0.004905</td>
      <td>0.004905</td>
      <td>0.348593</td>
    </tr>
    <tr>
      <th>998</th>
      <td>name</td>
      <td>0.000000e+00</td>
      <td>0.004592</td>
      <td>-0.004592</td>
      <td>0.004592</td>
      <td>0.344001</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.004562</td>
      <td>-0.004562</td>
      <td>0.004562</td>
      <td>0.339440</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.004324</td>
      <td>-0.004324</td>
      <td>0.004324</td>
      <td>0.335116</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>0.000000e+00</td>
      <td>0.004288</td>
      <td>-0.004288</td>
      <td>0.004288</td>
      <td>0.330828</td>
    </tr>
    <tr>
      <th>1931</th>
      <td>topic 5</td>
      <td>1.786056e-144</td>
      <td>0.004092</td>
      <td>-0.004092</td>
      <td>0.004092</td>
      <td>0.326735</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.004018</td>
      <td>0.004018</td>
      <td>0.004018</td>
      <td>0.330753</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003848</td>
      <td>0.003848</td>
      <td>0.003848</td>
      <td>0.334601</td>
    </tr>
    <tr>
      <th>137</th>
      <td>at</td>
      <td>0.000000e+00</td>
      <td>-0.003842</td>
      <td>0.003842</td>
      <td>0.003842</td>
      <td>0.338444</td>
    </tr>
    <tr>
      <th>2096</th>
      <td>topic 170</td>
      <td>2.208402e-02</td>
      <td>-0.003438</td>
      <td>0.003438</td>
      <td>0.003438</td>
      <td>0.341882</td>
    </tr>
    <tr>
      <th>1723</th>
      <td>very</td>
      <td>0.000000e+00</td>
      <td>0.003373</td>
      <td>-0.003373</td>
      <td>0.003373</td>
      <td>0.338509</td>
    </tr>
    <tr>
      <th>1127</th>
      <td>over</td>
      <td>7.071068e-01</td>
      <td>-0.003363</td>
      <td>0.003363</td>
      <td>0.003363</td>
      <td>0.341872</td>
    </tr>
    <tr>
      <th>1298</th>
      <td>sat</td>
      <td>0.000000e+00</td>
      <td>0.003312</td>
      <td>-0.003312</td>
      <td>0.003312</td>
      <td>0.338560</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>0.000000e+00</td>
      <td>-0.003268</td>
      <td>0.003268</td>
      <td>0.003268</td>
      <td>0.341828</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>topic 69</td>
      <td>0.000000e+00</td>
      <td>0.003262</td>
      <td>-0.003262</td>
      <td>0.003262</td>
      <td>0.338566</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003251</td>
      <td>0.003251</td>
      <td>0.003251</td>
      <td>0.341817</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 583
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;If you have not seen this movie, I definitely recommend it!  &#39;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.495 0.505]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>2.000000e+00</td>
      <td>-0.129747</td>
      <td>0.129747</td>
      <td>0.129747</td>
      <td>0.629257</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>4.070000e-01</td>
      <td>0.053117</td>
      <td>-0.053117</td>
      <td>0.053117</td>
      <td>0.576140</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>1.000000e+00</td>
      <td>0.041253</td>
      <td>-0.041253</td>
      <td>0.041253</td>
      <td>0.534887</td>
    </tr>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>6.696000e-01</td>
      <td>-0.037878</td>
      <td>0.037878</td>
      <td>0.037878</td>
      <td>0.572765</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>0.000000e+00</td>
      <td>0.037598</td>
      <td>-0.037598</td>
      <td>0.037598</td>
      <td>0.535167</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>1.000000e+00</td>
      <td>-0.016810</td>
      <td>0.016810</td>
      <td>0.016810</td>
      <td>0.551977</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>1.100000e+01</td>
      <td>0.012565</td>
      <td>-0.012565</td>
      <td>0.012565</td>
      <td>0.539412</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.009294</td>
      <td>-0.009294</td>
      <td>0.009294</td>
      <td>0.530119</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.007744</td>
      <td>-0.007744</td>
      <td>0.007744</td>
      <td>0.522375</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007456</td>
      <td>-0.007456</td>
      <td>0.007456</td>
      <td>0.514919</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.005406</td>
      <td>-0.005406</td>
      <td>0.005406</td>
      <td>0.509514</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>2.581989e-01</td>
      <td>-0.004660</td>
      <td>0.004660</td>
      <td>0.004660</td>
      <td>0.514173</td>
    </tr>
    <tr>
      <th>1870</th>
      <td>work</td>
      <td>0.000000e+00</td>
      <td>0.004154</td>
      <td>-0.004154</td>
      <td>0.004154</td>
      <td>0.510019</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.652275e-194</td>
      <td>0.003964</td>
      <td>-0.003964</td>
      <td>0.003964</td>
      <td>0.506055</td>
    </tr>
    <tr>
      <th>1928</th>
      <td>topic 2</td>
      <td>1.680620e-24</td>
      <td>-0.003920</td>
      <td>0.003920</td>
      <td>0.003920</td>
      <td>0.509975</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003435</td>
      <td>0.003435</td>
      <td>0.003435</td>
      <td>0.513410</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>6.100000e+01</td>
      <td>0.003323</td>
      <td>-0.003323</td>
      <td>0.003323</td>
      <td>0.510087</td>
    </tr>
    <tr>
      <th>1560</th>
      <td>there</td>
      <td>0.000000e+00</td>
      <td>-0.003153</td>
      <td>0.003153</td>
      <td>0.003153</td>
      <td>0.513240</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.003071</td>
      <td>0.003071</td>
      <td>0.003071</td>
      <td>0.516312</td>
    </tr>
    <tr>
      <th>32</th>
      <td>also</td>
      <td>0.000000e+00</td>
      <td>0.002959</td>
      <td>-0.002959</td>
      <td>0.002959</td>
      <td>0.513353</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002658</td>
      <td>0.002658</td>
      <td>0.002658</td>
      <td>0.516011</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002639</td>
      <td>-0.002639</td>
      <td>0.002639</td>
      <td>0.513372</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>2.330992e-86</td>
      <td>-0.002629</td>
      <td>0.002629</td>
      <td>0.002629</td>
      <td>0.516001</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>2.000000e+00</td>
      <td>0.002564</td>
      <td>-0.002564</td>
      <td>0.002564</td>
      <td>0.513438</td>
    </tr>
    <tr>
      <th>1035</th>
      <td>not go</td>
      <td>0.000000e+00</td>
      <td>-0.002562</td>
      <td>0.002562</td>
      <td>0.002562</td>
      <td>0.516000</td>
    </tr>
    <tr>
      <th>1929</th>
      <td>topic 3</td>
      <td>7.041484e-216</td>
      <td>-0.002490</td>
      <td>0.002490</td>
      <td>0.002490</td>
      <td>0.518490</td>
    </tr>
    <tr>
      <th>1100</th>
      <td>one</td>
      <td>0.000000e+00</td>
      <td>0.002485</td>
      <td>-0.002485</td>
      <td>0.002485</td>
      <td>0.516005</td>
    </tr>
    <tr>
      <th>1624</th>
      <td>to</td>
      <td>0.000000e+00</td>
      <td>-0.002478</td>
      <td>0.002478</td>
      <td>0.002478</td>
      <td>0.518483</td>
    </tr>
    <tr>
      <th>1856</th>
      <td>with</td>
      <td>0.000000e+00</td>
      <td>0.002430</td>
      <td>-0.002430</td>
      <td>0.002430</td>
      <td>0.516053</td>
    </tr>
    <tr>
      <th>142</th>
      <td>at the</td>
      <td>0.000000e+00</td>
      <td>0.002427</td>
      <td>-0.002427</td>
      <td>0.002427</td>
      <td>0.513626</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
Instance 588
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#34;It was a riot to see Hugo Weaving play a sex-obsessed gay real estate salesman who uses his clients&#39; houses for his trysts with the flaming Darren (Tom Hollander).  &#34;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Bias (testset mean) [0.5004902 0.4995098]
Truth 1
Prediction [0.785 0.215]
Feature contributions:
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[253]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>value</th>
      <th>neg contr</th>
      <th>pos contr</th>
      <th>abs contr</th>
      <th>pos cumulative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2136</th>
      <td>sid_compound</td>
      <td>-2.960000e-01</td>
      <td>0.092575</td>
      <td>-0.092575</td>
      <td>0.092575</td>
      <td>0.406935</td>
    </tr>
    <tr>
      <th>2135</th>
      <td>sid_pos</td>
      <td>7.700000e-02</td>
      <td>0.078710</td>
      <td>-0.078710</td>
      <td>0.078710</td>
      <td>0.328225</td>
    </tr>
    <tr>
      <th>2132</th>
      <td>has_not</td>
      <td>0.000000e+00</td>
      <td>-0.024417</td>
      <td>0.024417</td>
      <td>0.024417</td>
      <td>0.352642</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>not</td>
      <td>0.000000e+00</td>
      <td>-0.018537</td>
      <td>0.018537</td>
      <td>0.018537</td>
      <td>0.371179</td>
    </tr>
    <tr>
      <th>2126</th>
      <td>length</td>
      <td>1.650000e+02</td>
      <td>0.016019</td>
      <td>-0.016019</td>
      <td>0.016019</td>
      <td>0.355160</td>
    </tr>
    <tr>
      <th>2134</th>
      <td>sentiment_polar</td>
      <td>3.083333e-01</td>
      <td>-0.014354</td>
      <td>0.014354</td>
      <td>0.014354</td>
      <td>0.369514</td>
    </tr>
    <tr>
      <th>613</th>
      <td>great</td>
      <td>0.000000e+00</td>
      <td>0.009529</td>
      <td>-0.009529</td>
      <td>0.009529</td>
      <td>0.359985</td>
    </tr>
    <tr>
      <th>51</th>
      <td>and</td>
      <td>0.000000e+00</td>
      <td>0.008378</td>
      <td>-0.008378</td>
      <td>0.008378</td>
      <td>0.351607</td>
    </tr>
    <tr>
      <th>1926</th>
      <td>topic 0</td>
      <td>0.000000e+00</td>
      <td>0.007768</td>
      <td>-0.007768</td>
      <td>0.007768</td>
      <td>0.343840</td>
    </tr>
    <tr>
      <th>2127</th>
      <td>words</td>
      <td>2.900000e+01</td>
      <td>0.007286</td>
      <td>-0.007286</td>
      <td>0.007286</td>
      <td>0.336554</td>
    </tr>
    <tr>
      <th>758</th>
      <td>is</td>
      <td>0.000000e+00</td>
      <td>0.006681</td>
      <td>-0.006681</td>
      <td>0.006681</td>
      <td>0.329874</td>
    </tr>
    <tr>
      <th>2133</th>
      <td>afn</td>
      <td>0.000000e+00</td>
      <td>0.006611</td>
      <td>-0.006611</td>
      <td>0.006611</td>
      <td>0.323263</td>
    </tr>
    <tr>
      <th>598</th>
      <td>good</td>
      <td>0.000000e+00</td>
      <td>0.006579</td>
      <td>-0.006579</td>
      <td>0.006579</td>
      <td>0.316683</td>
    </tr>
    <tr>
      <th>2128</th>
      <td>punc_count</td>
      <td>5.000000e+00</td>
      <td>0.006546</td>
      <td>-0.006546</td>
      <td>0.006546</td>
      <td>0.310137</td>
    </tr>
    <tr>
      <th>2129</th>
      <td>capital_count</td>
      <td>6.000000e+00</td>
      <td>-0.005595</td>
      <td>0.005595</td>
      <td>0.005595</td>
      <td>0.315732</td>
    </tr>
    <tr>
      <th>1927</th>
      <td>topic 1</td>
      <td>1.648459e-133</td>
      <td>0.004594</td>
      <td>-0.004594</td>
      <td>0.004594</td>
      <td>0.311137</td>
    </tr>
    <tr>
      <th>401</th>
      <td>do not</td>
      <td>0.000000e+00</td>
      <td>-0.003690</td>
      <td>0.003690</td>
      <td>0.003690</td>
      <td>0.314827</td>
    </tr>
    <tr>
      <th>823</th>
      <td>it wa</td>
      <td>2.425356e-01</td>
      <td>0.003568</td>
      <td>-0.003568</td>
      <td>0.003568</td>
      <td>0.311259</td>
    </tr>
    <tr>
      <th>1103</th>
      <td>only</td>
      <td>0.000000e+00</td>
      <td>-0.003497</td>
      <td>0.003497</td>
      <td>0.003497</td>
      <td>0.314757</td>
    </tr>
    <tr>
      <th>2130</th>
      <td>num_exclamation_marks</td>
      <td>0.000000e+00</td>
      <td>0.003416</td>
      <td>-0.003416</td>
      <td>0.003416</td>
      <td>0.311340</td>
    </tr>
    <tr>
      <th>1937</th>
      <td>topic 11</td>
      <td>0.000000e+00</td>
      <td>-0.003273</td>
      <td>0.003273</td>
      <td>0.003273</td>
      <td>0.314613</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>topic 73</td>
      <td>0.000000e+00</td>
      <td>0.003172</td>
      <td>-0.003172</td>
      <td>0.003172</td>
      <td>0.311441</td>
    </tr>
    <tr>
      <th>1661</th>
      <td>too</td>
      <td>0.000000e+00</td>
      <td>-0.003061</td>
      <td>0.003061</td>
      <td>0.003061</td>
      <td>0.314502</td>
    </tr>
    <tr>
      <th>793</th>
      <td>it</td>
      <td>2.425356e-01</td>
      <td>-0.002941</td>
      <td>0.002941</td>
      <td>0.002941</td>
      <td>0.317443</td>
    </tr>
    <tr>
      <th>1703</th>
      <td>use</td>
      <td>0.000000e+00</td>
      <td>-0.002820</td>
      <td>0.002820</td>
      <td>0.002820</td>
      <td>0.320264</td>
    </tr>
    <tr>
      <th>384</th>
      <td>did not</td>
      <td>0.000000e+00</td>
      <td>-0.002805</td>
      <td>0.002805</td>
      <td>0.002805</td>
      <td>0.323068</td>
    </tr>
    <tr>
      <th>400</th>
      <td>do</td>
      <td>0.000000e+00</td>
      <td>-0.002795</td>
      <td>0.002795</td>
      <td>0.002795</td>
      <td>0.325863</td>
    </tr>
    <tr>
      <th>1011</th>
      <td>nice</td>
      <td>0.000000e+00</td>
      <td>0.002774</td>
      <td>-0.002774</td>
      <td>0.002774</td>
      <td>0.323089</td>
    </tr>
    <tr>
      <th>163</th>
      <td>bad</td>
      <td>0.000000e+00</td>
      <td>-0.002717</td>
      <td>0.002717</td>
      <td>0.002717</td>
      <td>0.325806</td>
    </tr>
    <tr>
      <th>1932</th>
      <td>topic 6</td>
      <td>2.438449e-35</td>
      <td>0.002705</td>
      <td>-0.002705</td>
      <td>0.002705</td>
      <td>0.323101</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>--------------------
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
